{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"A Propos","text":"<p>Ce blog a pour objectif de partager mes exp\u00e9riences autour du cloud Azure et du DevOps.</p>"},{"location":"about/#biographie","title":"Biographie","text":"<p>Co-responsable du centre d'excellence Microsoft dans la communaut\u00e9 Atlantique de onepoint, je coordonne une \u00e9quipe de sp\u00e9cialistes sur les technologies Microsoft mais pas que... </p> <p>Nous apportons notre expertise et notre support \u00e0 nos clients sur les th\u00e9matiques :</p> <ul> <li>DevOps avec Azure DevOps, </li> <li>Cloud avec Azure, </li> <li>Modern Workspace avec Microsoft 365, </li> <li>Data. </li> </ul> <p>Nous concevons et nous r\u00e9alisons aussi des solutions applicatives innovantes autour du cloud, du DevOps, du collaboratif et de la data. </p> <p>Avec plus de 15 ans d'exp\u00e9rience, moi-m\u00eame, j'apporte mon savoir sur :</p> <ul> <li>l'architecture Cloud Azure, </li> <li>l'expertise FinOps Azure, </li> <li>l'expertise DevOps, </li> <li>l'architecture Data (ETL, Datahub), </li> <li>la conception et le d\u00e9veloppement d'application client lourd et web .net, </li> <li>l'agilit\u00e9, </li> <li>le lean et </li> <li>l'exploitation d'infrastructure OnPremise.</li> </ul> <p>Je partage mes connaissances au travers de diverses formations autour du cloud Azure et du DevOps.</p> <p>Enfin, je suis tr\u00e8s fier d'\u00eatre reconnu par Microsoft en tant que MVP (Most Valuable Professional).</p>"},{"location":"about/#mes-certifications","title":"Mes certifications","text":""},{"location":"about/#mes-talks","title":"Mes Talks","text":"<p>A venir :</p> <ul> <li>DevOpsDays Geneva (le 24-25 avril 2023) : Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> </ul> <p>Pass\u00e9s :</p> <ul> <li>AgiLeMans (le 2 f\u00e9vrier 2023) : Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> <li>Touraine Tech (du 19 au 20 Janvier 2023) : Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> <li>Agile Tour Grenoble (du 23 au 25 Novembre 2022) :  Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> <li>Agile Tour Grenoble (du 23 au 25 Novembre 2022) :  Au secours, le DevOps part en vrille !</li> <li>Devfest Strasbourg (18 Novembre 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>Agile Tour Nantes (3 Novembre 2022) : Et PAF, encore un PoC ! ... qu'on pousse en prod. \ud83d\ude44</li> <li>Agile Tour Montpellier (le 17 Octobre 2022) :  Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite. replay</li> <li>Volcamp (les 13 et 14 Octobre 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?!</li> <li>Breizhcamp (1er Juillet 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>Sunny Tech (30 Juin 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>Meetup onepoint (22 Juin 2022) : Au secours, le DevOps part en vrille !</li> <li>Azug Nantes (31 Mai 2022) : Pourquoi j\u2019ai mal \u00e0 la t\u00eate lorsqu\u2019il faut mettre en place l\u2019isolation r\u00e9seau avec Azure ?</li> <li>Cloud Sud 2022 (24 Mars 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?!</li> <li>Inauguration / 20 ans onepoint (17 Mars 2022) : Au secours, le DevOps part en vrille !</li> <li>France DevOps (08 Mars 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>SnowCamp 2022 (du 02 au 04 F\u00e9vrier 2022) : Un datahub dans Azure, Retour d'exp\u00e9rience sur les services manag\u00e9s</li> <li>Azug Nantes (24 Janvier 2022) : Azure Batch, le mal-aim\u00e9 ! replay</li> <li>Agile Tour Rennes 2021 : Au secours, le DevOps part en vrille !</li> <li>Agile Tour Paris 2021 : Au secours, le DevOps part en vrille !</li> <li>Agile Tour Montpellier 2021 : Au secours, le DevOps part en vrille ! replay</li> <li>CloudEst 2021 : Un datahub dans Azure, Retour d'exp\u00e9rience sur les services manag\u00e9s</li> <li>TADx 2021 (Novembre 2021) : Au secours, le DevOps part en vrille ! replay</li> <li>France DevOps (Juillet 2021) : Au secours, le DevOps part en vrille ! replay</li> <li>CloudOuest 2021 : Un datahub dans Azure, Retour d'exp\u00e9rience sur les services manag\u00e9s</li> <li>ReBuild 2019 (Nantes) - REX Services Manag\u00e9s Azure (Talk)</li> <li>MS Experience 2018 (Paris) - G\u00c9RER SON PARC CLOUD AVEC AZURE DEVOPS (Quickie)</li> <li>ReBuild 2018 (Nantes) - G\u00c9RER SON PARC CLOUD AVEC AZURE DEVOPS (Talk)</li> </ul>"},{"location":"about/#me-suivre-ou-reagir","title":"Me suivre ou r\u00e9agir !","text":"<ul> <li>LinkedIn</li> <li>Twitter</li> </ul>"},{"location":"articles/assatbac/ep01/","title":"Private Endpoint","text":"<p>Cela fait plusieurs mois que je ne publie plus d'articles. En effet, j'ai \u00e9t\u00e9 tr\u00e8s occup\u00e9. Mais, j'ai eu une id\u00e9e qui m'a trott\u00e9 dans la t\u00eate pendant plusieurs semaines. Au bout d'un moment, je me suis lanc\u00e9 !</p> <p>Et voil\u00e0 le r\u00e9sultat\u2026</p> <p>Il s'agit l\u00e0 du premier \u00e9pisode d'une longue (je l'esp\u00e8re) s\u00e9rie. Je me suis directement inspir\u00e9 des blogs que j'avais plaisir de parcourir il y'a quelques ann\u00e9es (celui de Marion Montaigne et celui du LHC).</p> <p>Je vous pr\u00e9sente Professeur Somlinton ! </p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","virtual network","architecture"]},{"location":"articles/assatbac/ep01/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>What is a private endpoint?</li> <li>Tu mourras moins b\u00eate (blog de Marion Montaigne)</li> <li>LHC-France (La BD du LHC)</li> <li>Ray Tomlinson (L'un des papa d'internet, source d'inspiration le narrateur)</li> </ul>","tags":["Azure","virtual network","architecture"]},{"location":"articles/assatbac/ep01/#remerciements","title":"Remerciements","text":"<ul> <li>Jean-Philippe SENON : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> <li>Charlie Bethuys : pour la relecture</li> <li>Stephane Deloison : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 10 F\u00e9vrier 2023</p>","tags":["Azure","virtual network","architecture"]},{"location":"articles/assatbac/ep02/","title":"Private Endpoint VS Vnet Integration","text":"<p>Aujourd'hui le Professeur Somlinton vous explique la diff\u00e9rence entre le private-endpoint et le vnet integration ! </p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","virtual network","architecture"]},{"location":"articles/assatbac/ep02/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>What is a private endpoint?</li> <li>Integrate your app with an Azure virtual network</li> <li>Using Private Endpoints for App Service apps</li> </ul>","tags":["Azure","virtual network","architecture"]},{"location":"articles/assatbac/ep02/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 20 F\u00e9vrier 2023</p>","tags":["Azure","virtual network","architecture"]},{"location":"articles/assatbac/ep03/","title":"SPN, SMI et UMI","text":"<p>Aujourd'hui le Professeur Somlinton vous explique la diff\u00e9rence entre le service principal name, le system-assigned managed identity et le user-assigned managed identity !</p> <p>Veuillez noter que les activit\u00e9s de Tony Parker \u00e0 Villard-de-Lans sont de la pure fiction et ne servent qu'\u00e0 expliquer le propos.</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","Active Directory","Identit\u00e9"]},{"location":"articles/assatbac/ep03/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>What are managed identities for Azure resources?</li> <li>Application and service principal objects in Azure Active Directory</li> </ul>","tags":["Azure","Active Directory","Identit\u00e9"]},{"location":"articles/assatbac/ep03/#remerciements","title":"Remerciements","text":"<ul> <li>Stephane Deloison : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 13 Mars 2023</p>","tags":["Azure","Active Directory","Identit\u00e9"]},{"location":"articles/assatbac/ep04/","title":"Cosmos DB, c'est comme l'orbe de Morag","text":"<p>Aujourd'hui le Professeur Somlinton vous rassure sur l'utilisation de Cosmos DB, l'un des services les plus puissant d'Azure.</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","Cosmos DB","FinOps"]},{"location":"articles/assatbac/ep04/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Request Units in Azure Cosmos DB</li> <li>Introduction to provisioned throughput in Azure Cosmos DB</li> <li>Create Azure Cosmos DB containers and databases with autoscale throughput</li> <li>Azure Cosmos DB serverless</li> </ul>","tags":["Azure","Cosmos DB","FinOps"]},{"location":"articles/assatbac/ep04/#remerciements","title":"Remerciements","text":"<ul> <li>Jean-Philippe SENON : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 27 Mars 2023</p>","tags":["Azure","Cosmos DB","FinOps"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/","title":"Private Endpoint, Service Endpoint, Dedicated Service, Service Tags & Firewall","text":"<p>Il m'arrive r\u00e9guli\u00e8rement de constater que les clients utilisant Azure sont un peu perdu lorsqu'il s'agit de mettre en place la s\u00e9curisation r\u00e9seau de leurs services manag\u00e9s. Et j'avoue qu'ils n'ont pas tort. Devant les nombreuses possibilit\u00e9s et exceptions propos\u00e9es par le cloud de Microsoft, comment ne pas \u00eatre paum\u00e9 !</p> <p>Je vous propose un petit cours de rattrapage sur le sujet de l'isolation r\u00e9seau des services manag\u00e9s Azure.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#private-endpoint-private-link","title":"Private Endpoint &amp; Private Link","text":"<p>Le m\u00e9canisme de Private Endpoint / Private Link peut s'apparenter \u00e0 celui d'un VPN. Il faut imaginer que cela est comparable \u00e0 votre client VPN que vous lancez lorsque vous \u00eates en t\u00e9l\u00e9-travail pour vous connecter sur le r\u00e9seau de votre employeur. Lorsque vous vous authentifiez sur votre logiciel VPN, votre carte r\u00e9seau virtuelle s'active et vous donne une adresse IP priv\u00e9e du r\u00e9seau de votre employeur. Sur Azure, vous pouvez comparer le Private Endpoint \u00e0 la carte r\u00e9seau virtuelle et votre Private Link au logiciel client-serveur VPN.</p> <p></p> <p>Concr\u00e8tement sur Azure, avec Private Endpoint / Private Link, vous allez pouvoir attribuer \u00e0 votre service manag\u00e9 une adresse IP priv\u00e9e dans le subnet de votre choix. Et vous allez pouvoir ainsi interagir avec votre service azure tout en restant d'un point de vue r\u00e9seau dans votre Virtual Network. Mais, cela n'est g\u00e9n\u00e9ralement pas suffisant si vous souhaitez prot\u00e9ger votre service manag\u00e9 de l'exterieur. Mettre en place un Private Endpoint ne limite pas l'acc\u00e8s de votre ressource \u00e0 votre subnet.</p> <p></p> <p>Dans l'exemple ci-dessus on constate que notre Event Hubs A bien qu'il ait un Private Endpoint dans le Subnet A est accessible depuis le Subnet B et internet.</p> <p>Si on souhaite restreindre son acc\u00e8s, il va falloir mettre en place des r\u00e8gles firewall.  Dans le cas d'un Private Endpoint / Private Link, la r\u00e8gle est tr\u00e8s simple :  <pre><code>Deny : All\n</code></pre></p> <p>En effet, il faut savoir que les r\u00e8gles firewall au niveau du service manag\u00e9 ne s'appliquent pas au Private Endpoint. </p> <p></p> <p>Avec cette r\u00e8gle firewall vous bloquez ainsi tous les autres acc\u00e8s possibles \u00e0 votre service manag\u00e9.</p> <p>Note</p> <p>Vous ne pouvez pas appliquer de r\u00e8gle firewall \u00e0 votre Private Endpoint en associant un Network Security Group \u00e0 la Network Interface li\u00e9 \u00e0 votre Private Endpoint.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#service-endpoint","title":"Service Endpoint","text":"<p>Le m\u00e9canisme de Service Endpoint vous permet d'acceder depuis votre Subnet via le backbone Azure \u00e0 vos services manag\u00e9s sans jamais passer par internet. En gros, Microsoft vous garanti que la communication restera interne au cloud Azure.</p> <p></p> <p>Dans l'exemple ci-dessus, en activant le Service Endpoint Microsoft.Storage sur le Subnet A, on s'assure que la communication passera uniquement sur le backbone Azure pour atteindre la ressource Storage Account A.</p> <p>Encore une fois, cela n'est pas suffisant si vous souhaitez isoler votre service manag\u00e9.</p> <ul> <li>Premi\u00e8rement, le Service Endpoint vous permet un acc\u00e8s s\u00e9curis\u00e9 via le backbone Azure \u00e0 l'ensemble des instances du service manag\u00e9 en question (Par exemple : l'ensemble des Storage Account). </li> <li>Ensuite, tout comme le Private Endpoint, cela ne limite pas l'acc\u00e8s de votre ressource \u00e0 un unique subnet. </li> </ul> <p></p> <p>S'il on souhaite isoler notre service manag\u00e9, il va falloir mettre en places des r\u00e8gles firewall.  Dans le cas d'un Service Endpoint, la r\u00e8gle est plut\u00f4t simple :  <pre><code>Allow : [Votre Subnet]\nDeny : All\n</code></pre></p> <p></p> <p>Dans l'exemple ci-dessus, nous avons uniquement autoris\u00e9 le Subnet A sur le Storage Account A et le Subnet B sur le Storage Account B.</p> <p>Attention, si votre service manag\u00e9 doit contacter une de vos ressources de votre Virtual Network, il le fera avec une adresse IP public. Ce qui vous obligera \u00e0 autoriser l'inbound trafic depuis une IP public.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#dedicated-service","title":"Dedicated service","text":"<p>Le m\u00e9canisme de Dedicated service consiste \u00e0 injecter dans un subnet un service manag\u00e9.</p> <p></p> <p>Par ce m\u00e9canisme, au moment de l'instanciation du service manag\u00e9, une adresse IP priv\u00e9e du subnet lui sera affect\u00e9. Ainsi, vous pouvez appeler ou \u00eatre appel\u00e9 par votre service manag\u00e9 avec une adresse IP priv\u00e9e et sans avoir recours \u00e0 l'utilisation d'un Private Endpoint / Private Link. L'exemple le plus connu sur Azure est la fonctionnalit\u00e9 Vnet integration de l'Application Service (Web App, Function App).</p> <p>Note</p> <p>Contrairement au Private Endpoint, vous n'aurez pas une adresse IP priv\u00e9e fixe.</p> <p></p> <p>Encore une fois, l'utilisation de Dedicated service n'implique pas que votre service ne sera pas joignable depuis internet ou un autre Virtual Network et ne pourra pas joindre un autre service en dehors de votre Virtual Network (Comme le montre le sch\u00e9ma ci-dessus). Il faudra mettre en place des r\u00e8gles firewall. La r\u00e8gle est plut\u00f4t simple :  <pre><code>Allow : [Votre Subnet]\nDeny : All\n</code></pre></p> <p></p> <p>Dans l'exemple ci-dessus, nous avons uniquement autoris\u00e9 le Subnet A1 sur la Web App A et le Subnet B1 sur le Web App B.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#service-tag","title":"Service Tag","text":"<p>Ce m\u00e9canisme permet de simplifier les r\u00e8gles firewall en apposant des \u00e9tiquettes sur des types de services manag\u00e9s et des r\u00e9gions azure. Imaginons que vous souhaitez bloquer tout le trafic sortant depuis votre Subnet sauf celui \u00e0 destination de votre storage account : Vous avez mis en place un Service Endpoint Microsoft.Storage. Pour r\u00e9aliser cela vous allez cr\u00e9er un Network Security Group dans lequel vous allez bloquer le trafic vers internet et autoriser le trafic vers tous les storage account, puis associer votre Network Security Group \u00e0 votre subnet.</p> <p></p> <p>Ci-dessous un exemple de configuration du Network Security Group :</p> <p></p> <p>Les Service Tag peuvent aussi \u00eatre utilis\u00e9 dans les r\u00e8gles firewall de nombreux services manag\u00e9s azure (Web App, Function App, ...)</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#conclusion","title":"Conclusion","text":"<p>L'utilisation du Private Endpoint / Private Link :</p> <ul> <li>est l\u00e9g\u00e8rement complexe \u00e0 mettre en place, </li> <li>est relativement \u00e9conomique (\u00e0 partir de 6,57 \u20ac / mois).</li> <li>est recommand\u00e9 en cas d'inbound/outbound trafic : De votre Virtual Network vers ou \u00e0 destination de votre service manag\u00e9.</li> </ul> <p>L'utilisation du Service Endpoint :</p> <ul> <li>est simple \u00e0 mettre en place, </li> <li>n'implique pas de frais suppl\u00e9mentaires.</li> <li>est recommand\u00e9 uniquement en cas d'outbound trafic : De votre Virtual Network vers votre service manag\u00e9.</li> </ul> <p>L'utilisation du Dedicated service :</p> <ul> <li>est simple \u00e0 mettre en place, </li> <li>est parfois on\u00e9reux (Application Service Environment, Integration Service Environnement, ...). </li> <li>est recommand\u00e9 en cas d'inbound/outbound trafic : De votre Virtual Network vers ou \u00e0 destination de votre service manag\u00e9.</li> </ul> <p>Comme vous pouvez le constatez chaque fonctionnalit\u00e9 de s\u00e9curisation r\u00e9seau a son utilit\u00e9. Et vous pouvez tr\u00e8s bien mixer celles-ci pour obtenir le niveau de s\u00e9curit\u00e9 souhait\u00e9.</p> <p></p> <p>Ci-dessus un exemple d'application web recevant des \u00e9v\u00e8nements provenant d'un event grid et stockant ceux-ci dans un Storage Account.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Int\u00e9grer des services Azure \u00e0 des r\u00e9seaux virtuels pour l\u2019isolement r\u00e9seau</li> <li>Configurer des restrictions d\u2019acc\u00e8s dans Azure App Service</li> <li>Configurer des pare-feux et des r\u00e9seaux virtuels dans Stockage Azure</li> </ul>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/01.azureClassroom.VnetEndpointFirewall/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>David Dubourg : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Quentin Joseph : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 13 Septembre 2021</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/","title":"Azure Batch, le mal-aim\u00e9","text":"<p>Avec l'\u00e9mergence des services manag\u00e9s de cloud-computing moderne propos\u00e9s sur Azure : AKS, ARO, Databricks,... et maintenant Azure Container Apps. On finit par oublier les anciens... L'un des services que Microsoft ne met plus vraiment en avant depuis un certain temps mais qui pour moi est digne d'int\u00e9r\u00eat est Azure Batch.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#azure-batch-cest-quoi","title":"Azure Batch : C'est quoi ?","text":"<p>Azure Batch est un service propos\u00e9 par Microsoft permettant d'ex\u00e9cuter des traitements sur une machine virtuelle. Vous pouvez choisir la puissance de calcul (la taille de la VM), mais aussi choisir entre Windows et Linux (ubuntu, debian, centOS,...).</p> <p>Et ce n'est pas tout ! </p> <p>Il propose aussi nativement :</p> <ul> <li>un service de scalabilit\u00e9 horizontal que vous pourrez customiser,</li> <li>un service de VM low-priority, qui vous permettra de diviser par 4 les co\u00fbts par rapport \u00e0 une VM classique,</li> <li>un gestionnaire de packages d'applications (Artefacts),</li> <li>un gestionnaire de t\u00e2ches avec l'historique des ex\u00e9cutions,</li> <li>un planificateur de t\u00e2ches,</li> <li>la possibilit\u00e9 d'int\u00e9grer les machines virtuelles dans un Virtual Network,</li> <li>la possibilit\u00e9 de charger les variables d'environnement depuis Azure KeyVault,</li> <li>la possibilit\u00e9 d'ex\u00e9cuter des conteneurs Windows et Linux.</li> </ul> <p>Et le mieux, c'est que ce service est GRATUIT ! Seules les machines virtuelles utilis\u00e9es sont payantes.</p> <p>Mais, dans quel cas j'aurais besoin d'Azure Batch ?</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#les-cas-dutilisation","title":"Les cas d'utilisation","text":"<p>Si vous pr\u00e9parez l'examen de certification Azure Architect vous avez d\u00fb tomber sur la question : \"Dans quel cas utiliser Azure Batch ?\"</p> <p>Microsoft indique dans sa documentation que ce service permet d'ex\u00e9cuter des traitements par lot de calculs haute performance. Pour le traitement d'image, de vid\u00e9o, de mod\u00e9lisation ou de projection complexe, par exemple.</p> <p>De mon point de vue, c'est un peu r\u00e9ducteur. Pour l'utiliser depuis des ann\u00e9es, ce service permet des usages beaucoup plus communs comme :</p> <ul> <li>l'ex\u00e9cution d'agents de build ou de d\u00e9ploiement \u00e9ph\u00e9m\u00e8re,</li> <li>le traitement d'op\u00e9rations sur des donn\u00e9es m\u00e9tier en mode batch.</li> </ul> <p>Pour faire simple, si vous avez des traitements d'une dur\u00e9e de plusieurs minutes et que vous n'avez pas forc\u00e9ment de contraintes de temps de r\u00e9ponse, vous pouvez envisager Azure Batch comme une solution.</p> <p>Je vous propose de nous focaliser sur un cas d'utilisation : les agents \u00e9ph\u00e9m\u00e8res.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#les-agents-ephemeres","title":"Les agents \u00e9ph\u00e9m\u00e8res","text":"<p>Si vous utilisez Azure DevOps Services (ou Github Entreprise), vous avez la possibilit\u00e9 de provisionner des agents Microsoft Hosted. Ces agents sont h\u00e9berg\u00e9s par Microsoft et sont disponibles \u00e0 la demande pour chaque Job. Et pour chaque Job, un agent \"tout propre\" est mis \u00e0 disposition. </p> <p>Ce m\u00e9canisme vous permet de r\u00e9aliser vos builds et vos d\u00e9ploiements sans induire de biais li\u00e9s \u00e0 l'environnement de l'agent (logiciels, variables d'environnement, reliquats d'un pr\u00e9c\u00e9dent builds, ...).</p> <p>L'inconv\u00e9nient majeur, c'est que celui-ci s'ex\u00e9cute sur le r\u00e9seau de Microsoft. Si vous souhaitez d\u00e9ployer une application dans votre SI isol\u00e9 d'un point de vue r\u00e9seau, vous devez autoriser les plages d'IP publiques utilis\u00e9es par Microsoft pour ces agents. Autant dire que votre RSSI (Responsable de la S\u00e9curit\u00e9 du Syst\u00e8me d'Information) ne vous le permettra jamais !</p> <p>Azure Batch peut vous permettre de r\u00e9soudre cet inconv\u00e9nient majeur.</p> <p>Note</p> <p>L'utilisation du service Azure Container Instance aurait pu \u00eatre un bonne solution. Mais certaines limitations au niveau de l'interconnexion avec Azure Registry l'emp\u00e8che de r\u00e9pondre pleinement au besoin d'isolation r\u00e9seau des d'agents \u00e9ph\u00e9m\u00e8res. </p> <p>Cf. Azure Container Registry et Azure Container Instance dans votre Vnet </p> <p>Pour cela, il nous faudra :</p> <ul> <li>Le service Azure Batch,</li> <li>Un pool de n\u0153uds Windows Server 2019 with container (pour les builds windows),</li> <li>Un pool de n\u0153uds Ubuntu Server with container (pour les builds linux), </li> <li>Un Virtual Network avec un subnet d\u00e9di\u00e9 \u00e0 nos 2 pools d'agents,</li> <li>Le service Azure Storage Queue pour transmettre les instructions de cr\u00e9ation d'agents,</li> <li>Le service Azure Container Registry pour h\u00e9berger les images utilis\u00e9es pour instancier les agents,</li> <li>Le service Azure Function pour d\u00e9clencher la cr\u00e9ation des agents,</li> <li>La solution Azure DevOps Services pour d\u00e9clencher les t\u00e2ches de build. </li> </ul> <p>L'architecture applicative est la suivante :</p> <p></p> <ul> <li>L'Azure Container Registery et l'Azure Batch Account sont restreints au r\u00e9seau Virtual network A via l'utilisation de private endpoint. </li> <li>L'Azure Function utilise le m\u00e9canisme de Vnet int\u00e9gration afin d'\u00eatre visible dans le Virtual network A (Il faut aussi penser \u00e0 mettre en place les r\u00e8gles firewall pour restreindre l'acc\u00e8s au Virtual network A uniquement).</li> <li>Les pools de n\u0153uds (Windows et Ubuntu) ex\u00e9cutent les machines virtuels dans le Virtual network A.</li> <li> <p>Pour \u00e9viter un flux entrant depuis Azure DevOps (sur internet) et notre Azure Function (isol\u00e9e), nous utilisons le service Azure Storage Queue en ayant pris soin de mettre en place les r\u00e8gles firewall afin de limiter l'acc\u00e8s : </p> </li> <li> <p>au Virtual network A pour l'Azure Function,</p> </li> <li>aux plages d'IP publiques d'Azure DevOps.</li> </ul> <p>Ainsi avec cette architecture nous limitons l'accessibilit\u00e9 des agents Azure DevOps \u00e0 :</p> <ul> <li>un flux sortant depuis l'Azure Function vers une Storage Queue (qui fera office de passe-plat)</li> <li>un flux sortant depuis les agents Azure DevOps (obligatoire \u00e0 minima pour enregistrer l'agent).</li> </ul> <p>Concr\u00e8tement voici le s\u00e9quencement qui va se produire pour la mise \u00e0 disposition d'un agent \u00e9ph\u00e9m\u00e8re :</p> <p></p> <ol> <li>La t\u00e2che agentless \"Invoke REST API\" du pipeline de build/deploiement Azure DevOps envoie un message dans la Storage Queue A pour demander un agent \u00e9ph\u00e9m\u00e8re,</li> <li>L'Azure Function consomme la file d'attente de la Storage Queue A,</li> <li>Pour chaque message, l'Azure Function cr\u00e9e une t\u00e2che dans Azure Batch Account,</li> <li>L'Azure Batch Account traite les t\u00e2ches et affecte la t\u00e2che au bon pool de n\u0153uds,</li> <li>Le pool de n\u0153uds instancie un conteneur \u00e0 partir de l'image pr\u00e9sente dans l'Azure Container Registry,</li> <li>Une fois le conteneur instanci\u00e9 et d\u00e9marr\u00e9, celui-ci s'enregistre aupr\u00e8s d'Azure DevOps pour faire savoir qu'il est disponible. Azure DevOps lui affecte alors un job en attente. </li> <li>Le job Azure DevOps s'ex\u00e9cute dans le Virtual Network A et peut communiquer avec le r\u00e9seau On Premise.</li> </ol> <p>Dans ce cas d'utilisation, on peut tr\u00e8s facilement utiliser la fonctionnalit\u00e9 des VM low-priority et ainsi r\u00e9duire au maximum les co\u00fbts de run de nos agents Azure DevOps. Il s'av\u00e9rera difficile de trouver une solution moins on\u00e9reuse et aussi s\u00e9curis\u00e9e.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#les-fonctionnalites","title":"Les fonctionnalit\u00e9s","text":"<p>Maintenant, voyons en d\u00e9tail les fonctionnalit\u00e9s d'Azure Batch.</p> <p></p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#le-gestionnaire-de-pool","title":"Le gestionnaire de pool","text":"<p>Le service Azure Batch Account vous permet de g\u00e9rer une multitude de pools. Un pool est un ensemble de VM dedicated ou low-priority ayant une configuration commune :</p> <ul> <li>type et taille de machine, </li> <li>OS de la VM,</li> <li>subnet,</li> <li>variables d'environnements,</li> <li>commande s'ex\u00e9cutant au d\u00e9marrage de chaque machine virtuelle,</li> <li>certificats,</li> <li>images des conteneurs \u00e0 pr\u00e9charger (vous permettra de r\u00e9duire de fa\u00e7on significative la dur\u00e9e d'instanciation du conteneur),</li> <li>nombre de t\u00e2ches pouvant s'executer en parall\u00e8le sur une m\u00eame machine virtuelle.</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#le-gestionnaire-dapplication","title":"Le gestionnaire d'application","text":"<p>Le service Azure Batch Account vous permet de g\u00e9rer les packages d'applications. Ainsi vous pouvez vous passer d'outils comme Azure DevOps Artifacts, Nexus ou Artifactory.  Le gestionnaire de packages est simple mais reste efficace avec 2 param\u00e8tres pour g\u00e9rer le r\u00e9f\u00e9rencement :</p> <ul> <li>Nom de l'application</li> <li>Version</li> </ul> <p>Attention</p> <p>Le gestionnaire d'application ne vous permet pas de g\u00e9rer vos images Docker.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#le-gestionnaire-de-certificat","title":"Le gestionnaire de certificat","text":"<p>Le service Azure Batch Account vous permet de g\u00e9rer aussi les certificats. Vous pouvez les mettre \u00e0 disposition de vos pools qui pourront les utiliser au moment de l'ex\u00e9cution des t\u00e2ches.</p> <p>Attention</p> <p>Azure Batch Account ne vous pr\u00e9viendra pas de l'expiration de vos certificats !</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#le-gestionnaire-de-job-et-de-taches","title":"Le gestionnaire de job et de t\u00e2ches","text":"<p>Le service Azure Batch Account vous permet de regrouper vos t\u00e2ches dans le cas o\u00f9 vous souhaitez ex\u00e9cuter sur un m\u00eame pool un ensemble de t\u00e2ches. Vous pouvez au sein de votre job d\u00e9finir :</p> <ul> <li>des variables d'environnement communes \u00e0 l'ensemble des t\u00e2ches,</li> <li>des commandes au d\u00e9marrage et \u00e0 la fin du job.</li> </ul> <p>Une t\u00e2che ne peut s'ex\u00e9cuter qu'au sein d'un job. S'il n'y a pas de disponibilit\u00e9 sur le pool utilis\u00e9 par le job, Azure Batch Account va mettre en attente la t\u00e2che. Pour ex\u00e9cuter votre t\u00e2che vous pouvez d\u00e9finir :</p> <ul> <li>une ligne de commande</li> <li>des variables d'environnement sp\u00e9cifique</li> <li>les applications du gestionnaire d'application \u00e0 charger lors de l'ex\u00e9cution de la t\u00e2che. </li> </ul> <p>Le service Azure Batch Account historise les ex\u00e9cutions des t\u00e2ches et des jobs. Mais, je vous recommande d'utiliser des outils comme Log Analytics pour tracer les logs d'ex\u00e9cution des t\u00e2ches, la recherche dans Azure Batch \u00e9tant fastidieuse.</p> <p>Note</p> <p>Log Analytics est un service manag\u00e9 d'Azure permettant de collecter et parcourir les logs de vos diff\u00e9rentes applications. Vous pouvez donc l'utiliser pour centraliser les logs de vos batchs, mais aussi de vos autres applications (Web, Mobile, Desktop, ...).</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#le-planificateur-de-taches","title":"Le planificateur de t\u00e2ches","text":"<p>Enfin, Azure Batch Account propose un planificateur de t\u00e2ches. Mais ce planificateur ne vous permettra de d\u00e9finir que la fr\u00e9quence d'ex\u00e9cution. Je vous recommande vivement de passer votre chemin et d'utiliser des services int\u00e9grant un planificateur complet bas\u00e9 sur un CRONtab par exemple.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#conclusion","title":"Conclusion","text":"<p>Pour conclure je vous propose de r\u00e9sumer les plus et les moins de ce service.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#les-plus","title":"Les plus","text":"<ul> <li>Le gestionnaire d'application qui vous \u00e9vitera d'avoir \u00e0 provisionner un autre service,</li> <li>Le gestionnaire de certificat qui vous simplifiera le d\u00e9ploiement de vos certificats sur vos VM,</li> <li>La prise en charge des OS Windows et Linux,</li> <li>La possibilit\u00e9 d'ex\u00e9cuter des conteneurs sur les OS Windows et Linux,</li> <li>L'int\u00e9gration Vnet compl\u00e8te qui vous permet d'ex\u00e9cuter vos batchs et conteneurs de fa\u00e7on enti\u00e8rement isol\u00e9e,</li> <li>La possibilit\u00e9 de provisionner des VM low-priority qui vous permettra une r\u00e9duction des co\u00fbts significative.</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#les-moins","title":"Les moins","text":"<ul> <li>Le planificateur de t\u00e2ches qui se limite \u00e0 la fr\u00e9quence d'ex\u00e9cution. Un CRONtab aurait \u00e9t\u00e9 le bienvenu,</li> <li>L'int\u00e9gration aux autres services manag\u00e9s Azure comme Logic Apps, Data Factory est inexistante ou trop peu exploitable. Vous serez souvent oblig\u00e9 d'utiliser une Azure Function pour palier \u00e0 ce manque,</li> <li>Le moteur de recherche de l'historique des jobs n'est pas assez abouti.</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#le-mot-de-la-fin","title":"Le mot de la fin","text":"<p>Si vous avez r\u00e9guli\u00e8rement besoin d'ex\u00e9cuter des traitements de plusieurs minutes sur le cloud, le service Azure Batch peut \u00eatre consid\u00e9r\u00e9 comme une v\u00e9ritable solution.</p> <p>De plus, si vous \u00eates en pleine migration Cloud et que dans votre SI OnPremise vous avez des traitements batchs en ligne de commande, le service Azure Batch peut-\u00eatre un v\u00e9ritable QuickWin. Il vous \u00e9vitera un refactoring de vos batchs pour les int\u00e9grer \u00e0 des services plus moderne comme Azure DataFactory.  </p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Batch</li> <li>Ephemeral Pipelines Agents</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/classroom/02.azureClassroom.batch/#remerciements","title":"Remerciements","text":"<ul> <li>Samy Mameri : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Etienne Louise : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> <li>Quentin Joseph : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 1er D\u00e9cembre 2021</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/","title":"Adopter une d\u00e9marche GitOps gr\u00e2ce \u00e0 Azure App Configuration (Partie 1)","text":"<p>Dans mon dernier talk \"GitOps, Continuous Delivery et les environnements : comment \u00e9viter l'enfer !\", un participant m'a fait remarquer qu'il serait bien de montrer concr\u00e8tement comment mettre en place une d\u00e9marche GitOps avec des outils modernes.</p> <p>Etant un adepte des services manag\u00e9s d'Azure, je vous propose donc d'\u00e9tudier comment mettre en place une d\u00e9marche GitOps avec Azure App Configuration.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#pourquoi-adopter-une-demarche-gitops","title":"Pourquoi adopter une d\u00e9marche GitOps ?","text":"<p>Commen\u00e7ons par un petit rappel. </p> <p>La d\u00e9marche GitOps est le r\u00e9sultat de la rencontre du monde des d\u00e9veloppeurs et du monde des administrateurs et exploitants. Cette rencontre s'est op\u00e9r\u00e9e au moment de la d\u00e9mocratisation de la d\u00e9marche DevOps. Les d\u00e9veloppeurs travaillant avec les administrateurs, les deux mondes (autrefois bien silot\u00e9s) se sont inspir\u00e9s mutuellement et l'un des r\u00e9sultats est la d\u00e9marche GitOps.</p> <p>Mais GitOps, c'est quoi ?</p> <p>La d\u00e9marche GitOps,  c'est simplement l'utilisation d'outils de gestion du code comme git pour g\u00e9rer les param\u00e8tres de configuration d'une application. Ces outils offrant les avantages suivants :</p> <ul> <li>Centralisation : gr\u00e2ce au serveur de repository,</li> <li>Historisation : gr\u00e2ce aux commits,</li> <li>Gouvernance : gr\u00e2ce au contr\u00f4le d'acc\u00e8s,</li> <li>Automatisation : gr\u00e2ce aux pipelines de CI/CD.</li> </ul> <p>Cela veut-il dire que c'est le nouveau standard ?</p> <p>Oui... et non. Cela va surtout d\u00e9pendre du contexte de votre application. Si vous g\u00e9rez une application monolithique, vous n'avez peut-\u00eatre pas besoin de mettre en place une d\u00e9marche GitOps. Vous pouvez peut-\u00eatre vous contenter de g\u00e9rer les param\u00e8tres de configuration de votre application directement dans votre pipeline. \"Keep it simple and stupide !\".</p> <p>Vous allez trouver l'int\u00e9r\u00eat de mettre en place une d\u00e9marche GitOps d\u00e8s que vous aurez \u00e0 g\u00e9rer une application distribu\u00e9e. En effet, dans vos param\u00e8tres de configuration, vous devrez g\u00e9rer des attributs communs aux composants de votre architecture (comme les chaines de connexion \u00e0 vos bases de donn\u00e9es) et des attributs qui ne sont pas li\u00e9s au d\u00e9ploiement de vos composants (comme les certificats). Ces param\u00e8tres seront g\u00e9r\u00e9 ind\u00e9pendamment de vos composants.</p> <p></p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#presentation-dazure-app-configuration","title":"Pr\u00e9sentation d'Azure App Configuration","text":"<p>Le service Azure App Configuration va vous permettre de mettre en place une d\u00e9marche GitOps sur Azure. En effet, ce service manag\u00e9 va permettre de g\u00e9rer et de distribuer vos param\u00e8tres de configuration \u00e0 vos applications.</p> <p>Microsoft propose pour ce service des SDK disponibles dans de nombreux langages : .NET, Java, Python, JavaScript, ...</p> <p>Vous allez donc pouvoir utiliser ce service pour distribuer votre configuration \u00e0 vos Function Apps, Web Apps, Container Instances, Kubernetes Services, ...</p> <p>Il existe 2 niveaux de tarification : Gratuit et Standard. Vous constaterez que le niveau Gratuit est peut-\u00eatre int\u00e9ressant mais uniquement pour des environnements hors-production. L'absence de SLA et les quotas ne sont tout simplement pas envisageables pour une application en production (\u00e0 moins d'avoir le go\u00fbt du risque).</p> <p>Note</p> <p>Pour en savoir plus, je vous invite \u00e0 consulter la documentation de Microsoft : ici </p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#larchitecture","title":"L'architecture","text":"<p>Tr\u00eave de blabla et rentrons directement dans le vif du sujet. Commen\u00e7ons par un petit sch\u00e9ma d'architecture. L'objectif est d'utiliser conjointement Azure DevOps et Azure App Configuration pour distribuer la configuration aux diff\u00e9rents \u00e9l\u00e9ments de notre application distribu\u00e9e.</p> <p></p> <p>Nous allons pousser la configuration depuis Azure DevOps vers Azure App Configuration et configurer nos diff\u00e9rents composants de notre architecture distribu\u00e9e pour aller r\u00e9cup\u00e9rer la configuration depuis ce dernier.</p> <p>Il est possible d'indiquer dans Azure App Configuration qu'un des param\u00e8tres est dans Azure Key vault. Votre application ira alors r\u00e9cup\u00e9rer directement la configuration dans le coffre-fort \u00e0 partir de la cl\u00e9 indiqu\u00e9e par Azure App Configuration.</p> <p>Il existe 2 modes de connexion \u00e0 Azure App Configuration :</p> <ul> <li>avec une cl\u00e9 d'acc\u00e8s,</li> <li>avec une identit\u00e9 manag\u00e9e (System Assigned ou User Assigned).</li> </ul> <p>Je vous recommande fortement d'utiliser la seconde solution; la premi\u00e8re ne devant \u00eatre utilis\u00e9e que si vous n'avez pas d'autre solution.</p> <p>Vous pouvez aussi isoler d'un point de vue r\u00e9seau ce service en utilisant un Private Endpoint. Mais dans ce cas-l\u00e0, il faudra veiller \u00e0 utiliser des Self-hosted agents Azure DevOps pour d\u00e9ployer votre configuration. Voici un exemple de sch\u00e9ma d'architecture avec une isolation r\u00e9seau :</p> <p></p> <p>Enfin, si vous souhaitez que vos composants soient notifi\u00e9s \u00e0 chaque modification de configuration, vous pouvez ajouter le service Event Grid System Topic.</p> <p></p> <p>Note</p> <p>Il n'est pas possible d'isoler d'un point de vue r\u00e9seau un Event Grid System Topic avec un Private Endpoint. Pour r\u00e9soudre ce probl\u00e8me, il faudra faire un \"petit trou\" via Service Tag pour autoriser le trafic provenant de votre Event Grid (cf. : mon article sur l'isolation r\u00e9seau).</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#limplementation-dans-vos-applications","title":"L'impl\u00e9mentation dans vos applications","text":"","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#configurer-vos-applications-net-pour-utiliser-azure-app-configuration","title":"Configurer vos applications .NET pour utiliser Azure App Configuration","text":"<p>Pour configurer vos applications .NET il va falloir ajouter dans votre projet le package nuget <code>Microsoft.Azure.AppConfiguration.AspNetCore</code> pour vos applications ASP.NET Core ou <code>Microsoft.Extensions.Configuration.AzureAppConfiguration</code> pour toutes vos autres applications .NET Core.</p> <p>Ensuite, il faut configurer le service. </p> <p>Voici un exemple de configuration simple de votre application ASP.NET core :</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\n\nbuilder.Host.ConfigureAppConfiguration(builder =&gt;\n{\n    var settings = builder.Build();\n    //Connect to your App Config Store\n    builder.AddAzureAppConfiguration(options =&gt;\n    {\n        options.Connect(new Uri(settings[\"AppConfig:Endpoint\"]), new ManagedIdentityCredential())\n    });\n    // ...\n}); \n</code></pre> <p>Dans cet exemple, nous utilisons l'identit\u00e9 manag\u00e9e pour authentifier l'application aupr\u00e8s du service Azure App Configuration. </p> <p>Enfin, Il faut donner le r\u00f4le App Configuration Data Reader (RBAC) au niveau de l'Azure App Configuration \u00e0 votre application ASP.NET core.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#rafraichir-la-configuration-en-mode-pull","title":"Rafraichir la configuration en mode \"Pull\"","text":"<p>Pouvoir charger la configuration de votre application depuis Azure App Configuration c'est bien. Mais proc\u00e9der \u00e0 un red\u00e9marrage de l'application pour charger la nouvelle configuration n'est pas toujours id\u00e9al. Le SDK d'Azure App Configuration permet de pallier \u00e0 ce probl\u00e8me en d\u00e9tectant la modification de la configuration et en rechargeant celle-ci automatiquement.</p> <p>Avant tout, il faut s'assurer que le middleware d'Azure App Configuration est configur\u00e9. Pour cela dans le <code>HostBuilder</code>, il faut ajouter le service via <code>AddAzureAppConfiguration</code>.</p> <pre><code>builder.Host.ConfigureAppConfiguration(builder =&gt;\n{\n    // ...   \n})\n.ConfigureServices(services =&gt;\n{\n    services.AddControllersWithViews();\n    services.AddAzureAppConfiguration();\n});\n</code></pre> <p>Puis activer le middleware au niveau de la <code>WebApplication</code> via <code>UseAzureAppConfiguration</code>.</p> <pre><code>var app = builder.Build();\napp.UseHttpsRedirection();\napp.UseAzureAppConfiguration();\n// ...\n</code></pre> <p>Puis, nous allons utiliser un param\u00e8tre \"sentinelle\" dans Azure App Configuration. A chaque changement de ce param\u00e8tre cela indiquera qu'il faut recharger la configuration.</p> <p>Voici un exemple :</p> <pre><code>builder.AddAzureAppConfiguration(options =&gt;\n{\n    options.Connect(new Uri(settings[\"AppConfig:Endpoint\"]), new ManagedIdentityCredential())\n        .ConfigureRefresh(refresh =&gt; refresh.Register(\"TestApp:Settings:Sentinel\", true);\n});\n// ...\n</code></pre> <p>Dans cet exemple, on va conditionner le rafraichissement de tous les param\u00e8tres \u00e0 la mise \u00e0 jour de <code>TestApp:Settings:Sentinel</code>. </p> <p>Ainsi notre application va contr\u00f4ler r\u00e9guli\u00e8rement la valeur de notre param\u00e8tre \"sentinelle\". Par d\u00e9faut la fr\u00e9quence est d\u00e9finie \u00e0 30 secondes. Mais vous pouvez d\u00e9finir vous-m\u00eame la fr\u00e9quence :</p> <pre><code>// ...    \nrefresh.Register(\"TestApp:Settings:Sentinel\", true).SetCacheExpiration(new TimeSpan(0, 0, 10))\n// ...\n</code></pre> <p>Dans cet exemple, on va controler le param\u00e8tre \"sentinelle\" toutes les 10 secondes.</p> <p>Attention</p> <p>Veillez \u00e0 ne pas d\u00e9finir une fr\u00e9quence trop \u00e9lev\u00e9e. En effet, si vous souhaitez vous assurer que votre configuration puisse \u00eatre rafraichie tr\u00e8s rapidement vous serez tent\u00e9 de r\u00e9duire \u00e0 une seconde ou encore moins. Mais il faut prendre en compte que chaque web app va faire cette v\u00e9rification de fa\u00e7on ind\u00e9pendante. En d\u00e9finissant \u00e0 1 seconde, vos composants vont interroger au moins 2,6 millions de fois par mois Azure App Configuration. Imaginons que vous ayez 10 composants dans votre architecture, cela monte alors \u00e0 26 millions de requ\u00eates. Vous allez alors avoir un impact non n\u00e9gligeable sur les co\u00fbts de votre service Azure App Configuration (~ 140 \u20ac / mois).</p> <p>Si vous voulez absolument avoir une solution qui prenne en compte quasi-instantan\u00e9ment votre nouvelle configuration, je vous conseille alors de rafraichir la configuration de votre application en mode \"Push\".</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#rafraichir-la-configuration-en-mode-push","title":"Rafraichir la configuration en mode \"Push\"","text":"<p>Le principe consiste \u00e0 ce que chaque modification apport\u00e9e sur votre configuration dans Azure App Configuration d\u00e9clenche une notification qui est captur\u00e9e par vos composants. Cette solution va utiliser un autre service : les Event Grid System Topic.</p> <p>Dans le cas d'un composant ASP.NET core, il va falloir :</p> <ol> <li>Cr\u00e9er un webhook capable de s'enregistrer aupr\u00e8s de l'Event Grid,</li> <li>Mettre en place le m\u00e9canisme de rafraichissement du param\u00e9trage.</li> </ol> <p>Commen\u00e7ons par le webhook. Pour cela, il faut ajouter dans notre projet le package nuget <code>Azure.Messaging.EventGrid</code>. Puis, cr\u00e9er un contr\u00f4leur d\u00e9di\u00e9 avec une m\u00e9thode POST. Comme ceci : </p> <pre><code>using Azure.Messaging.EventGrid;\nusing Azure.Messaging.EventGrid.SystemEvents;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace [yournamespace].Controllers\n{\n    [ApiController]\n    [Route(\"[controller]\")]\n    public class ConfigurationController : ControllerBase\n    {\n        [HttpPost]\n        public async Task&lt;IActionResult&gt; Post()\n        {\n            BinaryData events = await BinaryData.FromStreamAsync(Request.Body);\n            EventGridEvent[] eventGridEvents = EventGridEvent.ParseMany(events);\n\n            foreach (EventGridEvent eventGridEvent in eventGridEvents)\n            {\n                // Handle system events\n                if (eventGridEvent.TryGetSystemEventData(out object eventData))\n                {\n                    // Handle the subscription validation event\n                    if (eventData is SubscriptionValidationEventData subscriptionValidationEventData)\n                    {\n                        var responseData = new SubscriptionValidationResponse()\n                        {\n                            ValidationResponse = subscriptionValidationEventData.ValidationCode\n                        };\n                        return new OkObjectResult(responseData);\n                    }\n                    // Handle the app configuration keyvalue event\n                    else if (eventData is AppConfigurationKeyValueModifiedEventData || eventData is AppConfigurationKeyValueDeletedEventData)\n                    {\n                        // TO DO\n                    }\n                }\n            }\n            return new OkObjectResult(string.Empty);\n        }\n    }\n}\n</code></pre> <p>Nous sommes maintenant capables de capturer les \u00e9v\u00e8nements pouss\u00e9s par l'Event Grid. Il faut maintenant d\u00e9clencher le rafra\u00eechissement de la configuration. Pour cela, il faut cr\u00e9er une classe en charge de d\u00e9clencher le rafra\u00eechissement aupr\u00e8s du middleware d'Azure App Configuration. Voici un exemple :</p> <pre><code>using Microsoft.Extensions.Configuration.AzureAppConfiguration;\n\nnamespace [yournamespace]\n{\n    public class OnDemandConfigurationRefresher : IOnDemandConfigurationRefresher\n    {\n        private readonly List&lt;IConfigurationRefresher&gt; _configurationRefreshers = new List&lt;IConfigurationRefresher&gt;();\n\n        public OnDemandConfigurationRefresher(IConfiguration configuration)\n        {\n            var configurationRoot = configuration as IConfigurationRoot;\n\n            if (configurationRoot == null)\n            {\n                throw new InvalidOperationException(\"The 'IConfiguration' injected in OnDemandConfigurationRefresher is not an 'IConfigurationRoot', and needs to be as well.\");\n            }\n\n            foreach (var provider in configurationRoot.Providers)\n            {\n                if (provider is IConfigurationRefresher refresher)\n                {\n                    _configurationRefreshers.Add(refresher);\n                }\n            }\n        }\n\n        public void RefreshAllRegisteredKeysAsync(PushNotification pushNotification)\n        {\n            _configurationRefreshers.ForEach(r =&gt; r.ProcessPushNotification(pushNotification));\n        }\n    }\n}\n</code></pre> <p>Et ajouter cette classe en tant que service.</p> <pre><code>builder.Host.ConfigureAppConfiguration(builder =&gt;\n{\n    // ...   \n})\n.ConfigureServices(services =&gt;\n{\n    services.AddControllersWithViews();\n    services.AddAzureAppConfiguration();\n    services.AddScoped&lt;IOnDemandConfigurationRefresher, OnDemandConfigurationRefresher&gt;();\n});\n</code></pre> <p>Enfin, impl\u00e9menter le d\u00e9clenchement du rafraichissement depuis le webhook :</p> <pre><code>using Azure.Messaging.EventGrid;\nusing Azure.Messaging.EventGrid.SystemEvents;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Configuration.AzureAppConfiguration;\nusing Microsoft.Extensions.Configuration.AzureAppConfiguration.Extensions;\n\nnamespace [yournamespace].Controllers\n{\n    [ApiController]\n    [Route(\"[controller]\")]\n    public class ConfigurationController : ControllerBase\n    {\n        private readonly IOnDemandConfigurationRefresher _azureAppConfigurationRefresher;\n\n        public ConfigurationController(IOnDemandConfigurationRefresher azureAppConfigurationRefresher)\n        {\n            _configuration = configuration;\n            _azureAppConfigurationRefresher = azureAppConfigurationRefresher;\n        }\n\n        [HttpPost]\n        public async Task&lt;IActionResult&gt; Post()\n        {\n            BinaryData events = await BinaryData.FromStreamAsync(Request.Body);\n            EventGridEvent[] eventGridEvents = EventGridEvent.ParseMany(events);\n\n            foreach (EventGridEvent eventGridEvent in eventGridEvents)\n            {\n                // Handle system events\n                if (eventGridEvent.TryGetSystemEventData(out object eventData))\n                {\n                    // Handle the subscription validation event\n                    if (eventData is SubscriptionValidationEventData subscriptionValidationEventData)\n                    {\n                        var responseData = new SubscriptionValidationResponse()\n                        {\n                            ValidationResponse = subscriptionValidationEventData.ValidationCode\n                        };\n                        return new OkObjectResult(responseData);\n                    }\n                    // Handle the app configuration keyvalue event\n                    else if (eventData is AppConfigurationKeyValueModifiedEventData || eventData is AppConfigurationKeyValueDeletedEventData)\n                    {\n                        eventGridEvent.TryCreatePushNotification(out PushNotification pushNotification);\n                        _azureAppConfigurationRefresher.RefreshAllRegisteredKeysAsync(pushNotification);\n                    }\n                }\n            }\n            return new OkObjectResult(string.Empty);\n        }\n    }\n}\n</code></pre> <p>Et voil\u00e0 ! </p> <p>Vous pouvez ensuite augmenter l'expiration du cache \u00e0 un ou plusieurs jours : <code>SetCacheExpiration(TimeSpan.FromDays(10))</code>. </p> <p>Cette solution a un inconv\u00e9nient. Si au moment de votre modification de configuration votre composant n'est pas disponible, l'\u00e9v\u00e8nement ne sera pas captur\u00e9 et la configuration ne sera pas mise \u00e0 jour. Vous pouvez pallier ce probl\u00e8me en utilisant une file d'attente Service Bus entre votre Event Grid et votre Web app. Ainsi, votre composant pourra alors r\u00e9cup\u00e9rer la modification de la configuration d\u00e8s qu'il sera de nouveau disponible.</p> <p></p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#configurer-pour-utiliser-azure-app-configuration-avec-azure-key-vault","title":"Configurer pour utiliser Azure App Configuration avec Azure Key vault","text":"<p>Dans vos param\u00e8tres de configuration, il n'est pas rare de trouver des \u00e9l\u00e9ments sensibles comme des cl\u00e9s d'acc\u00e8s, des mots de passe, des chaines de connexion. Il est fortement recommand\u00e9 de prot\u00e9ger ces param\u00e8tres sensibles dans un coffre-fort. Azure App Configuration permet de r\u00e9f\u00e9rencer les param\u00e8tres sensibles de votre configuration et d'indiquer leur emplacement dans Azure Key vault. Ainsi votre application pourra facilement r\u00e9cup\u00e9rer la valeur du param\u00e8tre directement dans le coffre-fort. De plus, comme pour tous les autres param\u00e8tres de configuration, vous pourrez notifier vos composants d'une modification dans le coffre-fort.</p> <p>Pour cela c'est tr\u00e8s simple, il suffit de modifier le param\u00e9trage d'Azure App Configuration dans votre composant. Voici un exemple utilisant les identit\u00e9s manag\u00e9es :</p> <pre><code>builder.AddAzureAppConfiguration(options =&gt;\n{\n    options.Connect(new Uri(settings[\"AppConfig:Endpoint\"]), new ManagedIdentityCredential())\n        .ConfigureRefresh(refresh =&gt; refresh.Register(\"TestApp:Settings:Sentinel\", true)\n        .ConfigureKeyVault(kv =&gt; kv.SetCredential(new ManagedIdentityCredential()));\n});\n// ...\n</code></pre> <p>Note</p> <p>Il faut que votre application (via son identit\u00e9 manag\u00e9e) soit autoris\u00e9e \u00e0 r\u00e9cup\u00e9rer (GET) les valeurs dans Azure Key vault. </p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#conclusion","title":"Conclusion","text":"<p>Dans cette premi\u00e8re partie nous avons vu comment mettre en place Azure App Configuration avec nos applications.  Nous verrons dans la seconde partie, comment automatiser la mise \u00e0 jour de la configuration avec Azure DevOps.  </p> <p>A suivre...</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Microsoft : Azure App Configuration</li> <li>Azure App Configuration refresh on demand</li> </ul>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/01.gitops.AzureAppConfiguration/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture et la remarque qui m'a conduite \u00e0 publier cet article</li> <li>David Dubourg : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 25 Avril 2022.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/","title":"Adopter une d\u00e9marche GitOps gr\u00e2ce \u00e0 Azure App Configuration (Partie 2)","text":"<p>Dans la premi\u00e8re partie nous avons vu comment utiliser Azure App Configuration avec diff\u00e9rentes applications et contraintes : coffre-fort, push ou pull de la configuration. Dans cette seconde partie nous allons voir ensemble comment utiliser les repos git et les pipelines Azure DevOps pour g\u00e9rer et pousser la configuration vers Azure App Configuration.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#rappel-de-la-demarche-gitops","title":"Rappel de la d\u00e9marche GitOps","text":"<p>La d\u00e9marche GitOps consiste \u00e0 g\u00e9rer la configuration des applications en utilisant un gestionnaire de source comme git. git offre l'avantage de fournir un historique des modifications gr\u00e2ce aux commits et de pouvoir automatiser le d\u00e9ploiement de la configuration gr\u00e2ce aux pipelines de CI/CD.</p> <p>Chaque modification de configuration produit un commit git. Celui-ci d\u00e9clenche un pipeline qui va se charger de d\u00e9ployer la configuration.</p> <p>A cela, on va pouvoir ajouter le branching model (TBD, Gitflow, github flow, ...) et le semantic versioning, pour conditionner le d\u00e9ploiement de la configuration.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#larchitecture-rappel","title":"L'architecture (rappel)","text":"<p>L'objectif est d'utiliser conjointement Azure DevOps et Azure App Configuration pour distribuer la configuration aux diff\u00e9rents \u00e9l\u00e9ments de notre application distribu\u00e9e.</p> <p></p> <p>Nous allons pousser la configuration depuis Azure DevOps vers Azure App Configuration et configurer nos diff\u00e9rents composants de notre architecture distribu\u00e9e pour aller r\u00e9cup\u00e9rer la configuration depuis ce dernier.</p> <p>Si vous isolez d'un point de vue r\u00e9seau Azure App Configuration en utilisant un Private Endpoint, il faudra veiller \u00e0 utiliser des Self-hosted agents Azure DevOps pour d\u00e9ployer votre configuration (cf.mon article). Voici un exemple de sch\u00e9ma d'architecture avec une isolation r\u00e9seau :</p> <p></p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#limplementation-azure-devops","title":"L'impl\u00e9mentation Azure DevOps","text":"","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#creer-la-connexion-azure-devops-azure","title":"Cr\u00e9er la connexion Azure DevOps &lt;-&gt; Azure","text":"<p>Si vous utilisez d\u00e9j\u00e0 Azure DevOps pour d\u00e9ployer vos applications sur Azure cela veut dire que vous avez tr\u00e8s certainement d\u00e9j\u00e0 configur\u00e9 un service connection dans votre projet. Dans ce cas, il faudra juste noter le Service Principal Id. Sinon, vous pouvez suivre la proc\u00e9dure d\u00e9crite ici.</p> <p>Une fois votre service connection op\u00e9rationnel, il va falloir lui donner l'autorisation de g\u00e9rer la configuration de votre Azure App Configuration. Pour cela, dans Azure, ajouter le r\u00f4le App Configuration Data Owner (RBAC) au niveau de l'Azure App Configuration.</p> <p></p> <p>Azure DevOps peut maintenant g\u00e9rer votre configuration pour vous.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#gerer-votre-configuration","title":"G\u00e9rer votre configuration","text":"<p>Votre configuration va devoir \u00eatre g\u00e9r\u00e9 dans des fichiers Json ou Yaml.</p> <p>Note</p> <p>Je vous recommande l'utilisation du format Json. En effet, ce format est bien plus facile \u00e0 g\u00e9rer avec les t\u00e2ches Azure DevOps que le format Yaml .</p> <p>Afin de simplifier la gestion, je vous conseille de s\u00e9parer votre configuration dans diff\u00e9rents fichiers :</p> <ul> <li>un fichier pour les param\u00e8tres \"classiques\",</li> <li>un fichier pour les Feature flags,</li> <li>un fichier pour les r\u00e9f\u00e9rences \u00e0 votre Azure Keyvault.</li> </ul> <p>Commen\u00e7ons par le fichier de param\u00e8tres \"classiques\". Rien de plus simple. Pour chaque cl\u00e9, vous allez d\u00e9finir la valeur. Par exemple en yaml vous aurez :</p> <pre><code>TestApp:Settings:Param1: ValueOfParam1\nTestApp:Settings:Param2: ValueOfParam2\nAll:Settings:Param3: ValueOfParam3\n</code></pre> <p>Pour le fichier contenant les Features flags, cela sera un peux plus compliquer. Pour chaque Feature flags, vous allez devoir d\u00e9finir un noeud contenant les param\u00e8tres id, enabled et optionnellement description et conditions. Et la cl\u00e9 doit commencer par <code>.appconfig.featureflag/</code>.</p> <p>Ci-dessous un exemple en json pour changer ;-) :</p> <pre><code>{ \n   \".appconfig.featureflag/flag001\": {\n        \"id\": \"Flag001\",\n        \"enabled\": true\n   }, \n   \".appconfig.featureflag/flag002\": {\n        \"id\": \"Flag002\",\n        \"enabled\": true,\n        \"conditions\": {\n            \"client_filters\": [\n                {\n                    \"name\": \"Microsoft.TimeWindow\",\n                    \"parameters\": {\n                        \"Start\": \"Thu, 19 May 2022 22:00:00 GMT\",\n                        \"End\": \"Sat, 21 May 2022 22:00:00 GMT\"\n                    }\n                }\n            ]\n        }        \n   },         \n   \".appconfig.featureflag/flag003\": {\n        \"id\": \"Flag003\",\n        \"description\": \"Lorem ipsum dolor sit amet\",\n        \"enabled\": true,\n        \"conditions\": {\n            \"client_filters\": [\n                {\n                    \"name\": \"Microsoft.Targeting\",\n                    \"parameters\": {\n                        \"Audience\": {\n                            \"Users\": [],\n                            \"Groups\": [\n                                {\n                                    \"Name\": \"groupA\",\n                                    \"RolloutPercentage\": 0\n                                },\n                                {\n                                    \"Name\": \"groupB\",\n                                    \"RolloutPercentage\": 100\n                                }\n                            ],\n                            \"DefaultRolloutPercentage\": 50\n                        }\n                    }\n                }\n            ]\n        }\n   }   \n}\n</code></pre> <p>Enfin pour le fichier des r\u00e9f\u00e9rences \u00e0 votre Azure Keyvault, vous allez devoir d\u00e9finir un noeud contenant le param\u00e8tre uri avec l'url d'acc\u00e8s \u00e0 votre secret. Par exemple (en json) :</p> <pre><code>{\n    \"TestApp:Settings:Secret1\": {\n        \"uri\":\"https://[YourKeyVaultName].vault.azure.net/secrets/Secret1\"\n    },\n    \"TestApp:Settings:Secret2\": {\n        \"uri\":\"https://[YourKeyVaultName].vault.azure.net/secrets/Secret2\"\n    },\n    \"TestApp:Settings:Secret3\": {\n        \"uri\":\"https://[YourKeyVaultName].vault.azure.net/secrets/Secret3\"\n    }\n}\n</code></pre> <p>Reste plus qu'\u00e0 pousser ces diff\u00e9rents fichiers sur un repo. git d\u00e9di\u00e9.</p> <p>Pour g\u00e9rer tout cela il va falloir automatiser le d\u00e9ploiement et surtout g\u00e9rer le param\u00e8tre \"sentinelle\" capable de d'indiquer aux applications que la configuration a chang\u00e9 ! (cf. Rafraichir la configuration en mode \"Pull\")</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#sematique-versioning-et-sentinelle","title":"S\u00e9matique versioning et sentinelle.","text":"<p>Notre param\u00e8tre \"sentinelle\" doit indiquer une modification de la configuration afin de forcer le rafraichissement de celle-ci au niveau des applications. Pour cela, pourquoi ne pas utiliser le semantique versioning ?</p> <p>Nous allons executer un petit script qui va ajouter dans notre fichier de configuration \"classique\" un param\u00e8tre \"sentinelle\". Celui-ci sera valu\u00e9e avec la version voulue.</p> <p>Ci-dessous un exemple de script powershell qui va modifier le fichier yaml afin d'ajouter le param\u00e8tre <code>TestApp:Settings:Sentinel</code> :</p> <pre><code># Arguments that get passed to the script when running it\nparam (\n    [Parameter(Position=1)]\n    $yamlFile,\n    [Parameter(Position=2)]\n    $version\n)\n\n# Install and import the `powershell-yaml` module\n# Install module has a -Force -Verbose -Scope CurrentUser arguments which might be necessary in your CI/CD environment to install the module\nInstall-Module -Name powershell-yaml -Force -Verbose -Scope CurrentUser\nImport-Module powershell-yaml\n\n# LoadYml function that will read YML file and deserialize it\nfunction LoadYml {\n    param (\n        $FileName\n    )\n    # Load file content to a string array containing all YML file lines\n    [string[]]$fileContent = Get-Content $FileName\n    $content = ''\n    # Convert a string array to a string\n    foreach ($line in $fileContent) { $content = $content + \"`n\" + $line }\n    # Deserialize a string to the PowerShell object\n    $yml = ConvertFrom-YAML $content\n    # return the object\n    Write-Output $yml\n}\n\n# WriteYml function that writes the YML content to a file\nfunction WriteYml {\n    param (\n        $FileName,\n        $Content\n    )\n    #Serialize a PowerShell object to string\n    $result = ConvertTo-YAML $Content\n    #write to a file\n    Set-Content -Path $FileName -Value $result\n}\n\n# Loading yml, setting new values and writing it back to disk\n$yml = LoadYml $yamlFile\n$yml.'TestApp:Settings:Sentinel' = $version\nWriteYml $yamlFile $yml\n</code></pre> <p>Lorsque je mets en place des pipelines de CI/CD, j'appr\u00e9cie tout particuli\u00e8rement l'utilisation d'outils comme GitVersion. Cet utilitaire va vous permettre de g\u00e9rer votre sematic versioning \u00e0 partir de votre historique git : vos commits, vos tags, vos branches.</p> <p>Pour cela, vous allez devoir ajouter un fichier GitVersion.yml dans votre repo. git. Ce fichier va d\u00e9finir comment d\u00e9duire la version \u00e0 partir de votre historique.</p> <p>Voici un exemple simple avec le Trunk Based Development :</p> <pre><code>mode: ContinuousDeployment\nassembly-versioning-scheme: MajorMinorPatch\ntag-prefix: '[vV]'\ncontinuous-delivery-fallback-tag: ci\nmajor-version-bump-message: '\\+semver:\\s?(breaking|major)'\nminor-version-bump-message: '\\+semver:\\s?(feature|minor)'\npatch-version-bump-message: '\\+semver:\\s?(fix|patch)'\nlegacy-semver-padding: 5\nbuild-metadata-padding: 5\ncommits-since-version-source-padding: 5\ncommit-message-incrementing: Enabled\nbranches:\n  master:\n    mode: ContinuousDeployment\n    tag: unstable\n    increment: Minor\n    prevent-increment-of-merged-branch-version: true\n    track-merge-target: false\n  release:\n    regex: releases?[/-]\n    increment: Patch\n    tag: stable\n    prevent-increment-of-merged-branch-version: true\n    track-merge-target: false\n</code></pre> <p>Il ne reste plus qu'\u00e0 automatiser le d\u00e9ploiement de la configuration.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#le-pipeline-cicd","title":"Le pipeline CI/CD","text":"<p>Commen\u00e7ons, par la CI. Contrairement \u00e0 ce que l'on pourrait croire, l'int\u00e9gration continue va \u00eatre utile pour :</p> <ul> <li>D\u00e9finir la valeur du param\u00e8tre \"sentinelle\",</li> <li>Empaqueter la configuration afin de pouvoir reproduire cette configuration.</li> </ul> <p></p> <p>Et dans le cas d'un multi-stage pipeline Azure DevOps, voil\u00e0 ce que cela peut donner :</p> <pre><code>stages:\n- stage: Prepare\n  displayName: Prepare\n  jobs:  \n  - job: PrepareConfiguration\n    displayName: Prepare configuration\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    # T\u00e9l\u00e9charge gitversion (s'il n'existe pas)\n    - task: gittools.gittools.setup-gitversion-task.gitversion/setup@0\n      displayName: gitversion/setup\n      inputs:\n        versionSpec: '5.*'\n    # D\u00e9finit la version\n    - task: gittools.gittools.execute-gitversion-task.gitversion/execute@0\n      displayName: gitversion/execute\n      inputs:\n        useConfigFile: true\n        configFilePath: GitVersion.yml\n    # D\u00e9finit le param\u00e8tre sentinelle\n    - task: PowerShell@2\n      displayName: setSentinelVersion\n      inputs:\n        filePath: tools/setSentinel.ps1\n        arguments: '-yamlFile configuration.yml -version $(GitVersion.FullSemVer)'\n    # Copie la configuration \u00e0 ins\u00e9rer dans l'artefact\n    - task: CopyFiles@2\n      displayName: 'Copy Files to: $(Build.ArtifactStagingDirectory)'\n      inputs:\n        Contents: config*.yml\n        TargetFolder: '$(Build.ArtifactStagingDirectory)'\n    # Publie l'artefact\n    - task: PublishBuildArtifacts@1\n      displayName: 'Publish Artifact: drop'\n</code></pre> <p>Une fois notre livrable de configuration pr\u00eat, il ne reste plus qu'\u00e0 le d\u00e9ployer sur Azure App Configuration. Vous pouvez facilement le faire avec la t\u00e2che <code>AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3</code>. </p> <p>Le souci avec cette t\u00e2che, c'est qu'elle ne peut pas d\u00e9ployer toutes les configurations en une seule fois. Il faut r\u00e9aliser le d\u00e9ploiement par type de param\u00e8tre en passant une valeur distincte au param\u00e8tre <code>ContentType</code> :</p> <ul> <li>Pour les r\u00e9f\u00e9rences au coffre-fort : <code>application/vnd.microsoft.appconfig.keyvaultref+json;charset=utf-8</code> </li> <li>Pour les features flags : <code>application/vnd.microsoft.appconfig.ff+json;charset=utf-8</code></li> </ul> <p></p> <p>Et dans le cas d'un multi-stage pipeline Azure Devops, cela peut donner :</p> <pre><code>- stage: Deploy\n  displayName: Deploy\n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: YOUR_ENVIRONMENT\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          #  Publie les r\u00e9f\u00e9rences \u00e0 votre Azure Keyvault \n          - task: AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3\n            displayName: 'Azure App Configuration KeyVault'\n            inputs:\n              azureSubscription: ${{variables.azureSubscription}}\n              AppConfigurationEndpoint: ${{variables.AppConfigurationEndpoint}}\n              ConfigurationFile: $(Pipeline.Workspace)/drop/configurationKeyVault.yml\n              Separator: .\n              Depth: '1'\n              ContentType: 'application/vnd.microsoft.appconfig.keyvaultref+json;charset=utf-8'\n          # Publie les features flags \n          - task: AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3\n            displayName: 'Azure App Configuration Feature Flags'\n            inputs:\n              azureSubscription: ${{variables.azureSubscription}}\n              AppConfigurationEndpoint: ${{variables.AppConfigurationEndpoint}}\n              ConfigurationFile: $(Pipeline.Workspace)/drop/configurationFeatureFlags.yml\n              Separator: .\n              Depth: '1'\n              ContentType: 'application/vnd.microsoft.appconfig.ff+json;charset=utf-8'\n          # Publie la configuration \"classique\" \n          - task: AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3\n            displayName: 'Azure App Configuration'\n            inputs:\n              azureSubscription: ${{variables.azureSubscription}}\n              AppConfigurationEndpoint: ${{variables.AppConfigurationEndpoint}}\n              ConfigurationFile: $(Pipeline.Workspace)/drop/configuration.yml\n              Separator: .\n              Depth: '1'\n</code></pre> <p>Note</p> <p>Les param\u00e8tres <code>azureSubscription</code> et <code>AppConfigurationEndpoint</code> correspondent respectivement au service connection configur\u00e9 sur votre projet Azure DevOps et \u00e0 l'url de votre service Azure App Configuration.  </p> <p>Maintenant nous avons notre repo. git et notre pipeline CI/CD qui nous permet de d\u00e9ployer la configuration.</p> <p>FIN !</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#conclusion","title":"Conclusion","text":"<p>Attendez un peu...</p> <p>Nos configurations seront certainement diff\u00e9rentes en fonction de nos environnements.  Comment g\u00e9rer ces configurations distinctes ? La modification de la configuration de l'environnement de recette n'a pas \u00e0 impacter la configuration de l'environnement d'int\u00e9gration ou de production. Cela veut-il dire que je dois mettre cela dans des fichiers distincts ? dans des repos distincts ? ou m\u00eame ailleurs ?</p> <p>Nous aborderons dans la troisi\u00e8me partie la gestion de la configuration par environnement.</p> <p>A suivre...</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Microsoft : Azure App Configuration</li> <li>Azure DevOps : Cr\u00e9er une connexion de service</li> <li>GitVersion</li> <li>Envoyer des param\u00e8tres vers App Configuration avec Azure Pipelines</li> </ul>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/02.gitops.AzureAppConfiguration/#remerciements","title":"Remerciements","text":"<ul> <li>Oussama Mouchrit : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 03 Mai 2022.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/","title":"Adopter une d\u00e9marche GitOps gr\u00e2ce \u00e0 Azure App Configuration (Partie 3)","text":"<p>Dans la seconde partie nous avons vu comment utiliser les repos git et les pipelines Azure DevOps pour g\u00e9rer et pousser la configuration vers Azure App Configuration. Mais nos configurations seront certainement diff\u00e9rentes en fonction de nos environnements. Comment g\u00e9rer ces configurations distinctes ? La modification de la configuration de l'environnement de recette n'a pas \u00e0 impacter la configuration de l'environnement d'int\u00e9gration ou de production. Cela veut-il dire que je dois mettre cela dans des fichiers distincts ? dans des repos distincts ? ou m\u00eame ailleurs ?</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#gerer-votre-configuration-denvironnement","title":"G\u00e9rer votre configuration d'environnement","text":"<p>Avant, il faut se poser quelques questions :</p> <ul> <li>Est-ce que vous avez besoin d'avoir un historique de la configuration sp\u00e9cifique \u00e0 chacun de vos environnements ?</li> <li>Combien de param\u00e8tres d'environnement (en dehors des param\u00e8tres sensibles) vous allez devoir g\u00e9rer ?</li> <li>Quel est la fr\u00e9quence de vos mises \u00e0 jour d'environnement ?</li> </ul> <p>Si vous avez de nombreux param\u00e8tres d'environnement, l'utilisation d'un fichier de configuration par environnement dans votre repo. git est probablement la solution.</p> <p>Si vous pr\u00e9voyez de modifier votre configuration d'environnement r\u00e9guli\u00e8rement, peut-\u00eatre que des repos par environnement est une bonne solution.</p> <p>Cela va vraiment d\u00e9pendre de votre situation. Je vais quand m\u00eame vous proposer de d\u00e9crire quelques solutions qui peuvent \u00eatre mises en place avec Azure DevOps.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#gerer-votre-configuration-denvironnement-avec-les-libraries-azure-devops","title":"G\u00e9rer votre configuration d'environnement avec les libraries Azure DevOps.","text":"<p>Si vous n'avez pas besoin de l'historique de vos configurations d'environnement, les libraries Azure DevOps sont suffisantes.</p> <p></p> <p>Utilis\u00e9 conjointement dans votre pipeline CD avec une t\u00e2che du type <code>replacetokens</code>, vous pourrez alors surcharger votre configuration commune par les sp\u00e9cificit\u00e9s de vos environnements.</p> <p>Par exemple, si vous d\u00e9finissez dans une libraire Azure DevOps les param\u00e8tres :</p> <ul> <li>NB_NODES : Nombre de n\u0153uds de votre cluster,</li> <li>ALLOW_ANONYMOUS_ACCESS : Top indiquant si la webApp est accessible sans authentification,</li> <li>SUPER_ADMIN_USER : Identit\u00e9 du super administrateur du cluster. </li> </ul> <p>En utilisant, la t\u00e2che <code>replacetokens</code>, vous aurez un fichier de configuration dans votre repo git de ce type :</p> <pre><code>TestApp:Settings:Param1: ValueOfParam1\nTestApp:Settings:Param2: ValueOfParam2\nAll:Settings:Param3: ValueOfParam3\nCluster:Settings:NbNodes: #{NB_NODES}#\nWebApp:Settings:AllowAnonymousAccess: #{ALLOW_ANONYMOUS_ACCESS}#\nCluster:Settings:SuperAdmin: #{SUPER_ADMIN_USER}#\n</code></pre> <p>L'inconv\u00e9nient c'est que vous aurez un autre r\u00e9f\u00e9rentiel de configuration \u00e0 g\u00e9rer. Ce n'est pas l'id\u00e9al en termes de maintenabilit\u00e9.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#gerer-votre-configuration-denvironnement-dans-des-dossiers-distincts","title":"G\u00e9rer votre configuration d'environnement dans des dossiers distincts.","text":"<p>Dans ce cas, si vous avez de nombreux param\u00e8tres d'environnement, l'utilisation d'un fichier de configuration par environnement dans votre repo. git est peut-\u00eatre la solution.</p> <p></p> <p>Reprenons notre exemple avec les param\u00e8tres :</p> <ul> <li>NB_NODES : Nombre de n\u0153uds de votre cluster,</li> <li>ALLOW_ANONYMOUS_ACCESS : Top indiquant si la webApp est accessible sans authentification,</li> <li>SUPER_ADMIN_USER : Identit\u00e9 du super administrateur du cluster. </li> </ul> <p>Vous aurez :</p> <ul> <li>un fichier config.json contenant les param\u00e8tres de configuration commun contenant :     <pre><code>{\n    \"TestApp:Settings:Param1\": \"ValueOfParam1\",\n    \"TestApp:Settings:Param2\": \"ValueOfParam2\",\n    \"All:Settings:Param3\": \"ValueOfParam3\",\n    \"Cluster:Settings:NbNodes\": 2,\n    \"WebApp:Settings:AllowAnonymousAccess\": true,\n    \"Cluster:Settings:SuperAdmin\": null\n}\n</code></pre></li> <li>un fichier config.dev.json contenant les param\u00e8tres de configuration sp\u00e9cifique \u00e0 l'environnement de DEV,     <pre><code>{\n    \"Cluster:Settings:SuperAdmin\": \"admin_dev@test.fr\"\n}    \n</code></pre></li> <li>un fichier config.uat.json contenant les param\u00e8tres de configuration sp\u00e9cifique \u00e0 l'environnement de UAT,      <pre><code>{\n    \"WebApp:Settings:AllowAnonymousAccess\": false,\n    \"Cluster:Settings:SuperAdmin\": \"admin_uat@test.fr\"\n}\n</code></pre></li> <li>un fichier config.prd.json contenant les param\u00e8tres de configuration sp\u00e9cifique \u00e0 l'environnement de PROD.     <pre><code>{  \n    \"Cluster:Settings:NbNodes\": 5,\n    \"WebApp:Settings:AllowAnonymousAccess\": false,\n    \"Cluster:Settings:SuperAdmin\": \"admin_prd@test.fr\"\n}\n</code></pre></li> </ul> <p>Ensuite en utilisant ce script powershell vous pourrez fusionner les fichiers afin d'avoir un fichier de configuration complet :</p> <pre><code># Arguments that get passed to the script when running it\nparam (\n    [Parameter(Position=1)]\n    $jsonSrcFile,\n    [Parameter(Position=2)]\n    $jsonEnvFile\n)\n\nInstall-Module -Name JoinModule -Force -Verbose -Scope CurrentUser\n\n# LoadJson function that will read Json file and deserialize it\nfunction LoadJson {\n    param (\n        $FileName\n    )\n    # Load file content to a string array containing all Json file lines\n    [string[]]$fileContent = Get-Content $FileName\n    $content = ''\n    # Convert a string array to a string\n    foreach ($line in $fileContent) { $content = $content + \"`n\" + $line }\n    # Deserialize a string to the PowerShell object\n    $json = ConvertFrom-Json $content\n    # return the object\n    Write-Output $json\n}\n\n# WriteJson function that writes the Json content to a file\nfunction WriteJson {\n    param (\n        $FileName,\n        $Content\n    )\n    #Serialize a PowerShell object to string\n    $result = ConvertTo-Json $Content\n    #write to a file\n    Set-Content -Path $FileName -Value $result\n}\n\nfunction MergeObject {\n    param (\n        $1,\n        $2\n    )\n\n    $Merged = $1 | Merge $2\n\n    Write-Output $Merged;\n}\n\n# Loading json, setting new values and writing it back to disk\n$jsonSrc = LoadJson $jsonSrcFile\n$jsonEnv = LoadJson $jsonEnvFile\n$merged = MergeObject $jsonSrc $jsonEnv \nWriteJson $jsonEnvFile $merged\n</code></pre> <p>L'incov\u00e9nient, c'est que si vous faites une modification dans l'un des fichiers de configuration d'environnement cela provoquera un incr\u00e9ment de version pour tous les environnements. Par exemple, si votre configuration est actuellement en version <code>1.0.0</code> et que vous r\u00e9alisez une modification suite \u00e0 un probl\u00e8me de param\u00e9trage sur la configuration d'UAT, vous allez incr\u00e9menter en version <code>1.0.1</code> pour tous vos environnements m\u00eame si la configuration \u00e9tait correcte en production. </p> <p>De plus, vous ne pourrez pas appliquer une gouvernance permettant de limiter la modification de votre environnement de production \u00e0 une population d'utilisateur restreint. On veut certainement permettre \u00e0 notre \u00e9quipe de modifier rapidement la configuration en DEV mais pas faire de m\u00eame en PROD.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#gerer-votre-configuration-denvironnement-avec-des-repos-distincts","title":"G\u00e9rer votre configuration d'environnement avec des repos distincts","text":"<p>Si vous souhaitez suivre ind\u00e9pendamment les modifications de vos environnements et limiter l'acc\u00e8s aux configurations de vos environnements, il faut peut-\u00eatre r\u00e9partir la configuration de vos environnements sur des repos distincts.</p> <p></p> <p>Si l'on reprend l'exemple ci-dessus avec 3 environnements DEV, UAT et PROD, il faudra 4 repos git de configuration. </p> <ul> <li>Un pour la configuration commun aux environnments,</li> <li>Un pour la configuration sp\u00e9cifique \u00e0 l'environnement de DEV,</li> <li>Un pour la configuration sp\u00e9cifique \u00e0 l'environnement de UAT,</li> <li>Un pour la configuration sp\u00e9cifique \u00e0 l'environnement de PROD.</li> </ul> <p>Le gros inconv\u00e9nient de cette solution, c'est que cette m\u00e9thode multiple rapidement le nombre repository. Ce qui va apporter de la complexit\u00e9 \u00e0 votre projet Azure DevOps.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-denvironnement","title":"D\u00e9ployer votre configuration d'environnement","text":"<p>Maintenant que l'on a une vague id\u00e9e de comment on veut g\u00e9rer notre configuration, il faut \u00eatre en capacit\u00e9 de la d\u00e9ployer correctement et au bon moment. Il faut se poser la question suivante : A quel moment je dois modifier la configuration sur mon environnement ?</p> <p>De mon point de vue il y a 2 cas totalement diff\u00e9rents qui vont n\u00e9cessiter de modifier votre configuration :</p> <ul> <li> <p>Lorsque l'on apporte une modification \u00e0 l'application : </p> <ul> <li>Evolution de l'application,</li> <li>Correction du comportement de l'application</li> </ul> </li> <li> <p>Lorsque l'on apporte une modification \u00e0 votre environnement :</p> <ul> <li>Renouvellement d'un certificat ou d'un mot de passe,</li> <li>Modification d'un param\u00e8tre technique,</li> <li>Activation d\u2019une fonctionnalit\u00e9 d\u00e9j\u00e0 d\u00e9ploy\u00e9e (Feature flag),</li> <li>...</li> </ul> </li> </ul> <p>Votre pipeline de d\u00e9ploiement de votre configuration doit \u00eatre adapt\u00e9 \u00e0 ces 2 cas.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-denvironnement-suite-a-une-modification-applicative","title":"D\u00e9ployer votre configuration d'environnement suite \u00e0 une modification applicative.","text":"<p>Dans le cas o\u00f9 vous apportez une \u00e9volution applicative vous allez vouloir tester/v\u00e9rifier votre configuration sur des environnements hors production avant de d\u00e9ployer celle-ci en production. Il faut vous calquer sur les pipelines de vos composants applicatifs.</p> <p>Par exemple, si votre application est h\u00e9berg\u00e9e sur trois environnements : DEV, UAT et PROD, vous devez avoir un pipeline de CI/CD qui va ressembler \u00e0 cela :</p> <p></p> <p>Votre pipeline yaml Azure DevOps avec un branching model TBD ressemblera \u00e0 \u00e7a :</p> <pre><code>trigger:\n- main\n- release/*\n\nstages:\n- stage: Prepare\n  displayName: Prepare\n  jobs:  \n  - job: PrepareConfiguration\n    displayName: Prepare configuration\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    # \n    # Define steps to prepare configuration for each environnments\n    #\n    # Publie l'artefact\n    - task: PublishBuildArtifacts@1\n      displayName: 'Publish Artifact: drop'\n- stage: DeployDEV\n  displayName: Deploy DEV\n  dependsOn: Prepare  \n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: DEV\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for DEV environnment\n            #\n- stage: DeployUAT\n  displayName: Deploy UAT\n  dependsOn: DeployDEV\n  condition: and(succeeded(), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'))\n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: UAT\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for UAT environnment\n            #\n- stage: DeployPRD\n  displayName: Deploy PROD\n  dependsOn: DeployUAT\n  condition: and(succeeded(), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'))\n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: PRD\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for PROD environnment\n            #\n</code></pre> <p>Ainsi, vous vous assurez que votre configuration sera test\u00e9e et valid\u00e9e sur vos environnements hors production avant de d\u00e9ployer votre configuration en production.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-pour-modifier-un-environnement","title":"D\u00e9ployer votre configuration pour modifier un environnement.","text":"<p>Mais lorsque vous souhaitez modifier votre configuration apr\u00e8s un \u00e9v\u00e8nement propre \u00e0 votre environnement et non li\u00e9 \u00e0 une modification de votre application, vous n'avez dans ce cas pas besoin de valider votre configuration sur d'autres environnements. Votre besoin de d\u00e9ploiement est sp\u00e9cifique \u00e0 un environnement. Pourquoi red\u00e9ployer une configuration en DEV lorsque l'on a uniquement besoin de modifier la configuration en UAT ou en PROD ?</p> <p>Dans ce cas, une solution consiste \u00e0 cr\u00e9er un pipeline sp\u00e9cifique pour chaque environnement en plus du pr\u00e9c\u00e9dent.</p> <p></p> <p>Maintenant, reprenons nos 3 m\u00e9thodes pour g\u00e9rer notre configuration et voyons comment appliquer cette approche \u00e0 chacune d'elles.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-en-utilisant-azure-devops-library","title":"D\u00e9ployer votre configuration en utilisant Azure DevOps Library","text":"<p>Malheureusement, aujourd'hui avec Azure DevOps, il n'existe pas de moyen simple et enti\u00e8rement int\u00e9gr\u00e9 pour d\u00e9clencher un pipeline suite \u00e0 la modification d'une librairie. Si vous souhaitez quand m\u00eame le faire, il faudra passer par la case d\u00e9veloppement et utiliser les diff\u00e9rentes API d'Azure DevOps. Vous devrez d\u00e9velopper une Azure Function avec un TimeTrigger pour v\u00e9rifier r\u00e9guli\u00e8rement s'il y a eu une mise \u00e0 jour sur les librairies et d\u00e9clencher votre pipeline.</p> <p>Vous en conviendrez, l'utilisation des Azure DevOps Libraries n'est pas tr\u00e8s adapt\u00e9e pour une utilisation avec des pipelines sp\u00e9cifiques par environnement. </p> <p>Note</p> <p>Si vous \u00eates tous de m\u00eame motiv\u00e9 pour faire cela, voici les api Azure DevOps qu'il faudra utiliser :</p> <ul> <li>Azure DevOps API : Get Variables Groups,</li> <li>Azure DevOps API : Run Pipeline</li> </ul>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-en-utilisant-des-dossiers-dans-votre-repository-git","title":"D\u00e9ployer votre configuration en utilisant des dossiers dans votre repository git","text":"<p>Si vous avez fait le choix d'utiliser des dossiers et des fichiers distincts pour chaque environnement dans votre repositiory git, la mise en \u0153uvre sera beaucoup plus facile. En effet, vous pouvez pr\u00e9ciser dans votre pipeline les dossiers \u00e0 inclure ou \u00e0 exclure du d\u00e9clencheur. Donc, si vous modifiez votre configuration pour un unique environnement seuls les fichiers dans le dossier correspondant \u00e0 votre environnement seront modifi\u00e9s.</p> <p>Votre pipeline sp\u00e9cifique \u00e0 chaque environnement ressemblera \u00e0 \u00e7a :</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n  paths :\n    include :\n    - YOUR_ENV/*\n\nstages:\n- stage: Prepare\n  displayName: Prepare\n  jobs:  \n  - job: PrepareConfiguration\n    displayName: Prepare configuration\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    # \n    # Define steps to prepare configuration for each environnments\n    #\n    # Publie l'artefact\n    - task: PublishBuildArtifacts@1\n      displayName: 'Publish Artifact: drop'\n- stage: Deploy\n  displayName: Deploy YOUR_ENV\n  dependsOn: Prepare  \n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: YOUR_ENV\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for DEV environnment\n            #\n</code></pre> <p>Et pour ne pas d\u00e9clencher le pipeline de configuration commun aux environnements, il faudra modifier celui-ci pour exclure le d\u00e9clenchement au moment d'un modification sp\u00e9cifique \u00e0 un environnement. Soit :</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n  paths :\n    exclude :\n    - YOUR_ENV/*\n</code></pre>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-en-utilisant-des-repository-git","title":"D\u00e9ployer votre configuration en utilisant des repository git","text":"<p>Si vous avez choisi d'utiliser des repository git distincts pour g\u00e9rer la configuration de chaque environnement, la solution est encore plus simple, il vous suffira de d\u00e9finir votre pipeline sp\u00e9cifique dans chacun de vos repos.</p> <p></p> <p>Pour chacun des pipelines sp\u00e9cifiques, il faudra penser \u00e0 r\u00e9f\u00e9rencer le repo. contenant votre configuration commune. Pour cela, il faudra rajouter dans votre pipeline yaml :</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n\nresources:\n  repositories:\n  - repository: common\n    type: git\n    name: YOUR_COMMON_REPOSITORY_NAME\n</code></pre> <p>Et pour votre pipeline commun, il faudra penser \u00e0 r\u00e9f\u00e9rencer les repos contenant les configurations sp\u00e9cifiques aux environnements. Par exemple :</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n\nresources:\n  repositories:\n  - repository: DEV\n    type: git\n    name: YOUR_DEV_REPOSITORY_NAME\n  - repository: UAT\n    type: git\n    name: YOUR_UAT_REPOSITORY_NAME\n  - repository: PROD\n    type: git\n    name: YOUR_PROD_REPOSITORY_NAME\n</code></pre>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#conclusion","title":"Conclusion","text":"<p>Voici la preuve que l'on peut facilement adopter une d\u00e9marche GitOps gr\u00e2ce au duo Azure App Configuration et Azure DevOps. Vous avez pu constater que tout n'est pas parfait. Il aurait \u00e9t\u00e9 appr\u00e9ciable de pouvoir d\u00e9clencher un pipeline suite \u00e0 la modification d'une library Azure DevOps. Peut-\u00eatre que cette fonctionnalit\u00e9 sera disponible dans les prochaines releases d'Azure DevOps. D'ailleurs, comment cela se passe-t-il avec l'autre produit concurrent d'Azure DevOps mais aussi propri\u00e9t\u00e9 de Microsoft : Github ?</p> <p>Nous verrons cela dans la quatri\u00e8me partie.</p> <p>A suivre...</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Azure DevOps : YAML schema reference for Azure Pipelines</li> </ul>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/gitops/03.gitops.AzureAppConfiguration/#remerciements","title":"Remerciements","text":"<p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 25 Mai 2022.</p>","tags":["DevOps","GitOps","CI/CD","development","Azure","PaaS"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/","title":"Permettre l'adoption de Fabric gr\u00e2ce \u00e0 Lemniscat (Partie 1)","text":"<p>Dans ma soci\u00e9t\u00e9, je m'occupe, entre autres, de mettre \u00e0 disposition de mes coll\u00e8gues des espaces Azure (des groupes de ressources) dans lesquels ils peuvent d\u00e9couvrir les diff\u00e9rents services Azure, tester des configurations Azure, etc. R\u00e9cemment, avec la sortie de Microsoft Fabric, j'ai constat\u00e9 que j'avais de plus en plus de demandes pour mettre \u00e0 disposition des espaces Azure avec Microsoft Fabric.</p> <p>Le probl\u00e8me, c'est que dans ma soci\u00e9t\u00e9, nous avons un tenant d\u00e9di\u00e9 pour toutes ces exp\u00e9rimentations. Mes coll\u00e8gues sont donc invit\u00e9s sur ce tenant pour pouvoir acc\u00e9der aux ressources Azure. Et pour le moment, Microsoft Fabric ne permet pas aux utilisateurs invit\u00e9s d'utiliser le service.</p> <p>Je devais donc syst\u00e9matiquement leur cr\u00e9er un compte sp\u00e9cifique sur le tenant pour leur permettre de tester Microsoft Fabric. Cela me prenait du temps et je ne trouvais pas cela tr\u00e8s pratique.</p> <p>En parall\u00e8le, j'ai initi\u00e9 un nouveau framework open source nomm\u00e9 Lemniscat. Ce framework permet de cr\u00e9er et de maintenir des produits orient\u00e9s DevOps. Pour faire simple, ce framework est une sorte de \"Terraform de Terraform\" qui permet de construire des produits qui prennent en compte les diff\u00e9rents aspects d'une d\u00e9marche DevOps, orient\u00e9e d'un point de vue consommateur du service.</p> <p>Revenons \u00e0 notre cas de Microsoft Fabric. Ce service est super int\u00e9ressant car il offre une exp\u00e9rience unifi\u00e9e des m\u00e9tiers autour de la data, de l'ingestion \u00e0 la restitution en passant par la transformation, le machine learning, etc. C'est un service qui permet de faire de la data engineering, de la data science, du BI, etc. Bref, c'est un service qui peut int\u00e9resser beaucoup de monde.</p> <p>Mais en tant qu'utilisateur de ce service, j'ai besoin de quoi, finalement ?</p> <ul> <li>D'une capacit\u00e9 Fabric que je peux instancier sur Azure.</li> <li>D'un acc\u00e8s \u00e0 cette capacit\u00e9 pour pouvoir l'utiliser.</li> <li>D'un environnement de travail pour pouvoir utiliser cette capacit\u00e9 (le Workspace Fabric).</li> <li>D'un d\u00e9p\u00f4t git pour pouvoir stocker mes artefacts de travail (mes notebooks, par exemple).</li> </ul> <p>Bref, pour offrir une exp\u00e9rience digne de ce nom \u00e0 mes coll\u00e8gues, je dois leur mettre \u00e0 disposition tout cela. Et c'est l\u00e0 que Lemniscat intervient.</p> <p>Dans cet article, je vais vous montrer comment j'ai pu mettre en place une capacit\u00e9 Fabric sur Azure et donner les droits sur cette capacit\u00e9 \u00e0 mes coll\u00e8gues en utilisant Lemniscat.</p> <p>Note</p> <p>Dans cet article, je ne vais pas entrer dans les d\u00e9tails de Lemniscat. Si vous souhaitez en savoir plus sur Lemniscat, je vous invite \u00e0 consulter la documentation.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#utilisons-terraform-pour-deployer-une-capacite-fabric","title":"Utilisons terraform pour d\u00e9ployer une capacit\u00e9 Fabric","text":"<p>Parce que c'est simple et que c'est un outil que tout le monde conna\u00eet, j'ai d\u00e9cid\u00e9 d'utiliser Terraform pour d\u00e9ployer une capacit\u00e9 Fabric sur Azure. Cependant, rapidement, je suis confront\u00e9 \u00e0 un probl\u00e8me : il n'existe pas encore de module Terraform pour d\u00e9ployer une capacit\u00e9 Fabric sur Azure. Heureusement, j'ai trouv\u00e9 un exemple de terraform qui permet de le faire. Ce n'est pas id\u00e9al, car il est bas\u00e9 sur <code>azapi</code>, mais cela fera l'affaire pour le moment.</p> <p>Dans cet exemple, je constate qu'il est pr\u00e9vu uniquement pour autoriser un seul administrateur par capacit\u00e9 Fabric. Or, d\u00e9sormais, il est possible de d\u00e9finir plusieurs administrateurs par capacit\u00e9. Ce n'est pas grave, nous allons effectuer une petite modification pour permettre \u00e0 plusieurs de mes coll\u00e8gues d'utiliser la m\u00eame capacit\u00e9 Fabric.</p> <p>main.tf <pre><code>resource \"azapi_resource\" \"fab_capacity\" {\n  type                      = \"Microsoft.Fabric/capacities@2022-07-01-preview\"\n  name                      = var.basename\n  parent_id                 = var.resource_group_id\n  location                  = var.location\n  schema_validation_enabled = false\n\n  body = jsonencode({\n    properties = {\n      administration = {\n        members = var.admins_email\n      }\n    }\n    sku = {\n      name = var.sku,\n      tier = \"Fabric\"\n    }\n  })\n  tags = var.tags\n}\n</code></pre></p> <p>variables.tf <pre><code>variable \"location\" {\n  type        = string\n  description = \"Location of the resource group.\"\n}\n\nvariable \"tags\" {\n  type        = map(string)\n  default     = {}\n  description = \"A mapping of tags which should be assigned to the deployed resource.\"\n}\n\nvariable \"sku\" {\n  type        = string\n  default     = \"F2\"\n  description = \"SKU name\"\n}\n\nvariable \"admins_email\" {\n  type        = list(string)\n  description = \"Fabric administrators email\"\n}\n</code></pre></p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#ajoutons-la-creation-de-nos-comptes-utilisateurs","title":"Ajoutons la cr\u00e9ation de nos comptes utilisateurs","text":"<p>Maintenant que nous avons notre capacit\u00e9 Fabric, il nous faut cr\u00e9er les comptes utilisateurs qui pourront l'utiliser.</p> <p>Note</p> <p>Pour le moment, Microsoft Fabric ne permet pas l'utilisation d'utilisateurs invit\u00e9s. Ainsi, les utilisateurs doivent \u00eatre dans le tenant Azure pour pouvoir y acc\u00e9der.</p> <p>Il faut donc que je cr\u00e9e des comptes \u00e0 la vol\u00e9e pour mes coll\u00e8gues. Encore une fois, je vais utiliser Terraform pour cela.</p> <p>De plus, il est n\u00e9cessaire que je g\u00e9n\u00e8re un mot de passe temporaire pour chaque utilisateur. Pour ce faire, je vais utiliser un module Terraform qui me permettra de g\u00e9n\u00e9rer un mot de passe al\u00e9atoire. <pre><code>resource \"random_password\" \"password\" {\n  length             = var.length\n  special            = var.special\n  override_special   = var.overrideSpecial \n}\n</code></pre></p> <p>Une fois que j'ai g\u00e9n\u00e9r\u00e9 le mot de passe, je vais cr\u00e9er un compte utilisateur pour chacun des utilisateurs. <pre><code>resource \"azuread_user\" \"account\" {\n  for_each              = { for u in var.users : u.login =&gt; u }\n  user_principal_name   = \"${each.key}.${var.FABRICNAME}@${var.domainName}\"\n  display_name          = each.value.name\n  mail_nickname         = each.key\n  force_password_change = true\n  password              = module.adminPassword[each.key].password\n\n  lifecycle {\n    ignore_changes      = [usage_location]\n  }\n}\n</code></pre></p> <p>Lorsque l'on cr\u00e9e un compte utilisateur, il est n\u00e9cessaire que l'utilisateur change son mot de passe \u00e0 la premi\u00e8re connexion. C'est pourquoi j'ai ajout\u00e9 <code>force_password_change = true</code>.</p> <p>Warning</p> <p>D\u00e8s que notre utilisateur va se connecte \u00e0 Fabric, l'attribut <code>usage_location</code> sera mis \u00e0 jour. C'est pourquoi j'ai ajout\u00e9 <code>ignore_changes = [usage_location]</code> dans le bloc <code>lifecycle</code>. En effet, cet attribut ne peut pas \u00eatre remis \u00e0 <code>null</code> (voir : https://registry.terraform.io/providers/hashicorp/azuread/latest/docs/resources/user#usage_location).</p> <p>Donc, maintenant nous avons notre capacit\u00e9 Fabric et nos utilisateurs.</p> <p>Cependant, si nous voulons offrir une exp\u00e9rience optimale \u00e0 nos coll\u00e8gues, il nous faut \u00e9galement cr\u00e9er un environnement de travail pour eux (le Workspace Fabric) et un r\u00e9f\u00e9rentiel Git pour stocker leur travail.</p> <p>Malheureusement, il n'existe pas de module Terraform et <code>azapi</code> ne pourra pas nous venir en aide. Nous devons trouver une autre solution.</p> <p>C'est une constatation que j'ai faite \u00e0 maintes reprises. Il y a des choses que l'on peut r\u00e9aliser avec Terraform et d'autres non. C'est l\u00e0 que Lemniscat entre en jeu.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#lemniscat-pour-ochestrer-tout-cela","title":"Lemniscat pour ochestrer tout cela","text":"<p>Lemniscat est un framework qui permet de cr\u00e9er et de maintenir des produits orient\u00e9s DevOps. Il permet de concevoir des produits qui prennent en compte les diff\u00e9rents aspects d'une d\u00e9marche DevOps, orient\u00e9e du point de vue du consommateur du service.</p> <p>Lemniscat fonctionne \u00e0 partir d'un manifeste qui d\u00e9crit le produit. Ce manifeste d\u00e9crit comment le produit doit \u00eatre instanci\u00e9, mais aussi comment il doit \u00eatre d\u00e9truit. Ce dernier point est particuli\u00e8rement pratique dans mon cas. En effet, je souhaite permettre \u00e0 mes coll\u00e8gues de d\u00e9couvrir Microsoft Fabric, mais je ne veux pas qu'ils laissent leur capacit\u00e9 ind\u00e9finiment active. Nous disposons tout de m\u00eame d'un budget limit\u00e9 et il est important que le plus grand nombre de mes coll\u00e8gues puissent profiter d'Azure. Avec Lemniscat, je peux d\u00e9finir la proc\u00e9dure de destruction du produit.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#initialisation-du-manfest-lemniscat","title":"Initialisation du manfest Lemniscat","text":"<p>Nous allons nous concentrer dans cet article sur la cr\u00e9ation de la capacit\u00e9 Fabric et des utilisateurs. Nous aborderons dans un prochain article la cr\u00e9ation du Workspace Fabric et du d\u00e9p\u00f4t Git. Dans le framework Lemniscat, cela correspond \u00e0 la capacit\u00e9 operate.</p> <p>Voici le manifeste Lemniscat pour la capacit\u00e9 Fabric et les utilisateurs : <pre><code>capabilities:\n  code: null\n  build: null\n  test: null\n  release: null\n  deploy: null\n  operate:\n    solutions: \n    - solution: Azure\n      tasks:\n        &lt;ici nous cr\u00e9rons les op\u00e9rations permettant de cr\u00e9er les compte utilisateurs et la capacit\u00e9 Fabric&gt;\n\nrequirements:\n  - name: lemniscat.plugin.terraform\n    version: 0.2.5\n  - name: lemniscat.plugin.filetransform\n    version: 0.2.1\n</code></pre></p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#configuration-du-fichier-tfvars","title":"Configuration du fichier Tfvars","text":"<p>J'utilise Backstage pour offrir une exp\u00e9rience optimale. J'ai donc cr\u00e9\u00e9 un formulaire qui permet de demander une capacit\u00e9 Fabric. Je demande \u00e0 mes coll\u00e8gues quelques informations :</p> <ul> <li>Le nom de la capacit\u00e9 Fabric : <code>appName</code></li> <li>La puissance de la capacit\u00e9 Fabric : <code>skuName</code></li> <li>La liste des utilisateurs \u00e0 cr\u00e9er et qui seront Administrateurs de la capacit\u00e9 Fabric : <code>users</code></li> <li>La dur\u00e9e de vie de la capacit\u00e9 Fabric : <code>delayBeforeCleanUp</code></li> </ul> <p>Ces param\u00e8tres vont \u00eatre renseign\u00e9s dans un fichier tfvars que j'utiliserai ensuite avec Terraform. Pour cela, je vais utiliser la t\u00e2che <code>filetransform</code> de Lemniscat pour compl\u00e9ter le fichier tfvars.</p> <pre><code>- task: filetransform\n  displayName: 'Set tfvars'\n  steps:\n    - pre\n    - pre-clean\n  parameters:\n    folderPath: ${{ product.tfVarsPath }}\n    fileType: json\n    targetFiles: \"*.tfvars.json\"\n</code></pre> <p>Une fois cette t\u00e2che ex\u00e9cut\u00e9e, j'ai mon fichier tfvars pr\u00eat \u00e0 \u00eatre utilis\u00e9 par Terraform. Par exemple :</p> <pre><code>{\n  \"appName\": \"myFabric\",\n  \"skuName\": \"F2\",\n  \"users\": [\n    {\n      \"name\": \"John Doe\",\n      \"login\": \"john.doe\",\n    },\n    {\n      \"name\": \"Jane Doe\",\n      \"login\": \"jane.doe\",\n    }\n  ],\n  \"delayBeforeCleanUp\": \"1h\"\n}\n</code></pre>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#creation-de-la-capacite-fabric-et-des-utilisateurs","title":"Cr\u00e9ation de la capacit\u00e9 Fabric et des utilisateurs","text":"<p>Pour cr\u00e9er la capacit\u00e9 Fabric et les utilisateurs, je vais utiliser le plugin terraform de Lemniscat. Pour initialiser Terraform, je vais utiliser l'action <code>init</code>.</p> <pre><code>- task: terraform\n  displayName: 'Terraform init'\n  steps:\n    - pre\n    - run\n    - pre-clean\n    - run-clean\n  parameters:\n    action: init\n    tfPath: ${{ product.tfPath }}\n    backend:\n      backend_type: azurerm\n      storage_account_name: ${{ nc.workspace.stName }}\n      container_name: tfstates\n      key: ${{ productInstanceName }}.${{ rgTags.product_name }}.tfstate\n</code></pre> <p>Ensuite, je vais utiliser l'action <code>plan</code> pour v\u00e9rifier que tout est correct, et notamment v\u00e9rifier que les param\u00e8tres d'entr\u00e9e sont corrects.</p> <pre><code>- task: terraform\n  displayName: 'Terraform plan'\n  steps:\n    - pre\n  parameters:\n    action: plan\n    tfPath: ${{ product.tfPath }}\n    tfVarFile: ${{ product.tfVarsPath }}/${{ product.tfVarsFile }}\n    tfplanFile: ${{ product.tfPath }}/terrafom.tfplan\n</code></pre> <p>Enfin, je vais utiliser l'action <code>apply</code> pour d\u00e9ployer la capacit\u00e9 Fabric et les utilisateurs. <pre><code>- task: terraform\n  displayName: 'Terraform apply'\n  steps:\n    - run\n  parameters:\n    action: apply\n    tfPath: ${{ product.tfPath }}\n    tfplanFile: ${{ product.tfPath }}/terrafom.tfplan\n</code></pre></p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#destruction-de-la-capacite-fabric-et-des-utilisateurs","title":"Destruction de la capacit\u00e9 Fabric et des utilisateurs","text":"<p>Une fois que la capacit\u00e9 Fabric et les utilisateurs ont \u00e9t\u00e9 cr\u00e9\u00e9s, il faut penser \u00e0 les d\u00e9truire (je rappelle que mes coll\u00e8gues ont besoin temporairement de cette capacit\u00e9 Fabric). Pour cela, je vais utiliser l'action <code>destroy</code> du plugin terraform.</p> <pre><code>- task: terraform\n  displayName: 'Terraform destroy'\n  steps:\n    - run-clean\n  parameters:\n    action: destroy\n    tfPath: ${{ product.tfPath }}\n    tfVarFile: ${{ product.tfVarsPath }}/${{ product.tfVarsFile }}\n</code></pre>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#conclusion","title":"Conclusion","text":"<p>Forc\u00e9ment, vous allez me dire que je me complique la vie. J'aurais tout simplement pu utiliser Terraform pour tout faire. Et vous avez raison.</p> <p>Mais comme je l'indiquais au d\u00e9but de cet article, j'ai aussi besoin de cr\u00e9er un environnement de travail (le Workspace Fabric) et un d\u00e9p\u00f4t Git.</p> <p>Dans le prochain article, je vous montrerai comment avec Lemniscat j'ai pu cr\u00e9er un environnement de travail et un d\u00e9p\u00f4t Git pour permettre \u00e0 mes coll\u00e8gues conserver leur travail.</p> <p>\u00c0 suivre...</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/lemniscat/01.lemniscat.microsoftfabric/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Sample terraform pour Microsoft Fabric</li> <li>Documentation terraform : azuread_user, limitation usage_location</li> <li>Documentation du framework Lemniscat</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 30 Mars 2024.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"articles/devops/vrille/","title":"Au secours, le DevOps part en vrille !","text":"<p>Cela fait maintenant des ann\u00e9es que je travaille avec la d\u00e9marche DevOps. Je parle bien de la d\u00e9marche, car tout comme l'agilit\u00e9, le DevOps ne se limite pas \u00e0 de l'outillage ou \u00e0 des m\u00e9thodes. L'objectif du DevOps est de faire sauter les silos entre le Build et le Run des applications. Il s'agit d'une solution permettant \u00e0 l'agilit\u00e9 d'\u00eatre plus efficace.</p> <p>Mais dans le cas d'un projet d'application microservice complexe, la mise en place et surtout le maintient d'une d\u00e9marche DevOps est bien plus complexe. On arrive aux limites du DevOps tel que l'on peut l'apprendre dans la literrature. </p> <p>Mais alors, le DevOps a ses limites et ne peut donc pas s'appliquer partout ? NON. Il faut juste reprendre un peu de hauteur, comprendre la d\u00e9marche et trouver les solutions qui permettent de passer au-del\u00e0 des limites.</p> <p>Dans cette s\u00e9rie nous aborderons :</p> <ul> <li>le pourquoi arrive-t-on aux limites, </li> <li>le comment passe-t-on au-del\u00e0 des limites,</li> <li>et enfin, pour que cela ne reste pas que de la th\u00e9orie, une preuve que l'on peut aller plus loin.</li> </ul>"},{"location":"articles/devops/vrille/#partie-1-pourquoi-arrive-t-on-aux-limites-du-devops","title":"Partie 1 : Pourquoi arrive-t-on aux limites du DevOps ?","text":"<ul> <li>Chapitre 1 : L'agilit\u00e9</li> <li>Chapitre 2 : Le DevOps</li> <li>Chapitre 3 : L'entropie</li> </ul>"},{"location":"articles/devops/vrille/#partie-2-comment-passe-t-on-au-dela-des-limites","title":"Partie 2 : Comment passe-t-on au-del\u00e0 des limites ?","text":"<ul> <li>Chapitre 1 : La machine \u00e0 \u00e9tat</li> <li>Chapitre 2 : Le build</li> <li>Chapitre 3 : Le d\u00e9ploiement</li> </ul>"},{"location":"articles/devops/vrille/#partie-3-cest-possible-la-preuve","title":"Partie 3 : C'est possible, la preuve !","text":"<ul> <li>La preuve, conclusion</li> </ul>"},{"location":"articles/devops/vrille/01.pourquoi.agilite/","title":"Chapitre 1 : L'agilit\u00e9","text":"","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/01.pourquoi.agilite/#lagilite","title":"L'agilit\u00e9","text":"<p>Bien que l'agilit\u00e9 ne soit pas un pr\u00e9-requis au DevOps et vice-versa, l'un et l'autre sont bien plus efficaces s'ils sont utilis\u00e9s conjointement.</p> <p>Imaginons que nous avons un nouveau projet d'application bas\u00e9 sur une architecture microservice plut\u00f4t complexe. Ce projet est conduit avec la m\u00e9thode agile. Nous d\u00e9finissons les r\u00e8gles suivantes :</p> <ol> <li>Les it\u00e9rations ont une dur\u00e9e de 3 semaines,</li> <li>La recette fonctionnelle doit \u00eatre faite par une \u00e9quipe m\u00e9tier ind\u00e9pendante de l'\u00e9quipe de r\u00e9alisation,</li> <li>Les tests d\u2019int\u00e9gration sont inclus dans le Definition Of Done de l\u2019\u00e9quipe de r\u00e9alisation,</li> <li>Les d\u00e9lais doivent \u00eatre r\u00e9duit au maximum.</li> </ol> <p>Les 2 derniers points pouvant \u00eatre r\u00e9solus par le DevOps, cette d\u00e9marche apparait comme \u00e9vidente. Mais dans le cas o\u00f9 nous avons plusieurs dizaines de microservices, le DevOps n'est pas si simple que cela \u00e0 mettre en oeuvre.</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/01.pourquoi.agilite/#lagilite-et-le-devops","title":"L'agilit\u00e9 et le DevOps","text":"<p>Reprenons notre exemple avec des it\u00e9rations de 3 semaines et imaginons le cycle de vie de nos UserStory.</p> <p>La premi\u00e8re \u00e9tape consiste \u00e0 Groomer nos UserStory afin que l'\u00e9quipe puisse engager sereinement celles-ci dans le sprint.</p> <p></p> <p>Cela veut aussi dire que nos UserStory doivent \u00e0 minima \u00eatre Groom\u00e9es un sprint avant d'\u00eatre engag\u00e9es par l'\u00e9quipe de r\u00e9alisation.</p> <p></p> <p>Les tests d'int\u00e9gration \u00e9tant inclus dans le Definition Of Done de l'\u00e9quipe de r\u00e9alisation, cela veut donc dire que durant l'it\u00e9ration l'\u00e9quipe devra \u00e0 minima d\u00e9ployer une fois sur un environnement d'int\u00e9gration (dans notre cas, nomm\u00e9 DEV) pour chaque UserStory.</p> <p></p> <p>A la fin de l'it\u00e9ration l'\u00e9quipe de r\u00e9alisation va pr\u00e9senter son travail ; l'ensemble des UserStory r\u00e9alis\u00e9es (la d\u00e9mo.). Suite \u00e0 cette pr\u00e9sentation et apr\u00e8s validation des UserStory, l'\u00e9quipe va pouvoir proc\u00e9der au d\u00e9ploiement sur l'environnement de recette fonctionnelle (dans notre cas, nomm\u00e9 UAT).</p> <p></p> <p>Si durant la recette m\u00e9tier de notre UserStory un bug bloquant est d\u00e9tect\u00e9, alors il faudra proc\u00e9der \u00e0 un hotfix. Donc \u00e0 minima nous aurons un d\u00e9ploiement en UAT par sprint. Une fois la recette m\u00e9tier r\u00e9alis\u00e9e et l'ensemble des UserStory valid\u00e9es par notre \u00e9quipe m\u00e9tier, l'\u00e9quipe peut donc proc\u00e9der au d\u00e9ploiement en production.</p> <p></p> <p>Ainsi on peut constater :</p> <ul> <li>qu'il nous faut environ 9 semaines entre le moment ou l'on a groom\u00e9 notre UserStory et le moment ou celle-ci est disponible en production. Certes, en imaginant un grooming efficace et une recette m\u00e9tier rapide, on peut r\u00e9duire \u00e0 4 ou 5 semaines. Cela reste fictionnel !</li> <li>qu'il faudra multiplier les d\u00e9ploiements durant tout le cycle. Et pour peu que nos UserStory impactent plusieurs microservices, c'est autant de d\u00e9ploiements de microservices qu'il faudra r\u00e9aliser une ou plusieurs fois pour chaque environnement.</li> </ul>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/01.pourquoi.agilite/#les-features-flags","title":"Les features flags","text":"<p>L'utilisation de feature flag peut \u00eatre un tr\u00e8s bon moyen pour r\u00e9soudre notre probl\u00e9matique de d\u00e9lai. En effet, on peut imaginer que les UserStory soient d\u00e9ploy\u00e9es au fil de l'eau de leurs r\u00e9alisations et sans attendre la fin de l'it\u00e9ration sur les environnements de recette m\u00e9tier (UAT) et de production.</p> <p></p> <p>On peut m\u00eame imaginer de se passer de nos environnements de recette int\u00e9gration (DEV) et m\u00e9tier (UAT) et de d\u00e9ployer directement en production en mode partiellement cach\u00e9 (limit\u00e9 \u00e0 l'\u00e9quipe de r\u00e9alisation et de recette m\u00e9tier). </p> <p>L'utilisation de feature flag implique que nos microservices qui impl\u00e9mentent nos UserStory doivent permettre d'activer ou de d\u00e9sactiver \u00e0 tout moment la nouvelle fonctionnalit\u00e9 (ou de permettre d'\u00e9xecuter en m\u00eame temps plusieurs versions d'un m\u00eame microservice). Cela entraine plus de complexit\u00e9 au niveau de l'impl\u00e9mentation et/ou de l'infractructure. Certes, il existe des frameworks permettant de simplifier l'impl\u00e9mentation et des services PaaS permettant de simplifier l'infrastructure.  Mais dans certains cas, l'utilisation de features flags est presque impossible \u00e0 mettre en place ou entra\u00eene une complexit\u00e9 technique et architecturale accrue. Par exemple :</p> <ul> <li>Les Workflows : Comment passer d'une version \u00e0 l'autre d'un design de workflow pour une m\u00eame instance ?</li> <li>Les ETL : Comment maintenir plusieurs versions d'une m\u00eame transformation de donn\u00e9es ? En multipliant les destinations ?</li> <li>Les Infrastructures : Comment maintenir plusieurs versions d'une infrastructure sur un m\u00eame environnement ? En multipliant les environnements ?</li> </ul>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/01.pourquoi.agilite/#en-resume","title":"En r\u00e9sum\u00e9","text":"<p>Bien que les feature flag permettent en partie de r\u00e9soudre nos probl\u00e9matiques, elles ne sont pas \u00e0 elles seules la r\u00e9ponse \u00e0 notre probl\u00e9matique de mise en place du DevOps dans une architecture microservice complexe. Tr\u00e8s souvent, pour des raisons \u00e9conomiques \u00e9videntes, les feature flags sont mises de cot\u00e9.</p> <p>Ne pouvant pas forc\u00e9ment r\u00e9duire encore plus nos d\u00e9lais, il faudra donc se concentrer sur la multitude des d\u00e9ploiements \u00e0 r\u00e9aliser (en automatique) en veillant \u00e0 ne pas oublier une partie !</p> <p>Nous verrons dans le prochain chapitre que la d\u00e9marche DevOps peut elle aussi apporter au projet son lot de probl\u00e9matiques.</p> <p>A suivre...</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/01.pourquoi.agilite/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Martin Fowler - Feature Toggles (aka Feature Flags)</li> </ul>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/01.pourquoi.agilite/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 04 Octobre 2021</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/","title":"Chapitre 2 : Le DevOps","text":"","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#le-devops","title":"Le DevOps","text":"<p>La d\u00e9marche DevOps, comme on peut la comprendre dans la litt\u00e9rature trouve ses limites dans des projets microservices complexes.</p> <p>Imaginons que nous avons un nouveau projet d'application bas\u00e9 sur une architecture microservice plut\u00f4t complexe. Ce projet souhaite avoir une d\u00e9marche Full DevOps.</p> <p>Info</p> <p>J'utilise r\u00e9guli\u00e8rement le terme Full DevOps pour indiquer qu'il n'y a aucun livrable du projet qui ne soit pas int\u00e9gr\u00e9 enti\u00e8rement dans la d\u00e9marche DevOps. Cela inclus donc les d\u00e9marches GitOps, DevSecOps, Dev{andMore}Ops, MLOps, DataOps, xOps, ...</p> <p>Note</p> <p>Dans la suite de cet article, je vais utiliser r\u00e9guli\u00e8rement le terme de composant pour repr\u00e9senter l'ensemble des \u00e9l\u00e9ments \u00e0 d\u00e9ployer (infrastructure, microservices, ...).</p> <p>Nous d\u00e9finissons les r\u00e8gles suivantes :</p> <ol> <li>L\u2019infrastructure, le code, la documentation : Tout doit \u00eatre d\u00e9ploy\u00e9 automatiquement =&gt; Full DevOps</li> <li>En cas de souci lors du d\u00e9ploiement d\u2019un composant, ceux d\u00e9pendants doivent \u00eatre bloqu\u00e9s.</li> <li>Ne d\u00e9ployer en UAT que ce qui a \u00e9t\u00e9 valid\u00e9 en DEV.</li> <li>Ne d\u00e9ployer en PROD que ce qui a \u00e9t\u00e9 valid\u00e9 en UAT.</li> <li>Utiliser le branching model Trunk-Based Development.</li> </ol>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#linfrastructure-le-code-la-documentation-tout-doit-etre-deploye-automatiquement","title":"L\u2019infrastructure, le code, la documentation : Tout doit \u00eatre d\u00e9ploy\u00e9 automatiquement.","text":"<p>Comme je suis un \"fana.\" d'Azure, on va imaginer que notre projet de microservices doit \u00eatre d\u00e9ploy\u00e9 sur des services manag\u00e9s Azure. Il faudra donc d\u00e9ployer cette infrastructure pour pouvoir ensuite d\u00e9ployer nos microservices. Notre \u00e9quipe produisant aussi de la documentation (sp\u00e9cifications, sch\u00e9ma d'architecture, ...), on souhaite avoir une d\u00e9marche DevOps pour mettre \u00e0 jour notre documentation sur un portail.</p> <p></p> <p>Pour arriver \u00e0 cette fin nous allons nous appuyer sur les repository git.</p> <ul> <li>Notre infrastructure sera d\u00e9crite en InfraAsCode avec Terraform, Bicep ou ARM json.</li> <li>Le code de nos librairies sera r\u00e9parti dans des repository en fonction de son utilisation. Il n'est pas pertinent de mettre dans un repository \u00e0 part le code d'une librairie qui n'est destin\u00e9e qu'\u00e0 un seul microservice.</li> <li>Le code de nos microservices (application web, batch, services, ...) sera r\u00e9parti dans des repository.</li> </ul> <p>Dans chacun de ces repository nous aurons le code (InfraAsCode ou code \"classique\"), mais aussi la documentation d\u00e9crite en DocAsCode avec Markdown, AsciiDoc ou reStructuredText.</p> <p>Enfin pour chaque repository nous allons mettre en place un pipeline de CI/CD afin d'automatiser la compilation, la validation et le d\u00e9ploiement \u00e0 chaque commit.</p> <p></p> <p>Note</p> <p>Je ne parle pas ici de PipelineAsCode. Cette pratique que je recommande fortement dans la d\u00e9marche DevOps permet de d\u00e9crire le fonctionnement de notre pipeline de CI/CD. Personnellement, je conseille de n'avoir qu'un seul pipeline par repository et que celui-ci soit d\u00e9pos\u00e9 \u00e0 la racine. Cela permet de rapidement comprendre ce qui va \u00eatre d\u00e9clench\u00e9 lors d'un commit-push sans avoir la mauvaise surprise d'avoir d\u00e9clench\u00e9 un pipeline non d\u00e9sir\u00e9.</p> <p>Jusqu'ici, tout va bien.</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#les-dependances","title":"Les d\u00e9pendances","text":"<p>Le premier souci que l'on peut rencontrer se trouve au niveau du build. En effet, une librairie cr\u00e9\u00e9e dans le cadre d'un projet et pens\u00e9e pour \u00eatre utilis\u00e9e par plusieurs microservices ou par d'autres librairies aura son propre repository. Ce qui implique que des microservices et des librairies peuvent d\u00e9pendre de librairies. On ne pourra pas compiler un microservice si les librairies qui sont utilis\u00e9es par celui-ci ne sont pas disponibles.</p> <p>C'est ce que j'appelle : la d\u00e9pendance de compilation. </p> <p>Example</p> <ul> <li>La Lib2 utilise la Lib1,</li> <li>Le Batch1 utilise la Lib1,</li> <li>Les WebService1, WebService2 et Batch2 utilisent la Lib2 </li> </ul> <p>Afin de garantir la robustesse de la solution, je veux m'assurer qu'une \u00e9volution sur une librairie ne va pas provoquer une r\u00e9gression sur les librairies et les microservices qui d\u00e9pendent d'elle. Dans les pipelines de mes microservices je vais donc mettre en place un trigger sur le succ\u00e8s du build de ma librairie.</p> <p>Example</p> <p>La Lib2 est mise \u00e0 jour. Les WebService1, WebService2 et Batch2 qui utilisent la Lib2 doivent \u00eatre recompil\u00e9s et test\u00e9s afin de v\u00e9rifier la non-r\u00e9gression. </p> <p>Le second souci que l'on peut rencontrer se trouve au niveau du d\u00e9ploiement. En effet, pour d\u00e9ployer un microservice il parait \u00e9vident que son infrastructure doit \u00eatre d\u00e9ploy\u00e9 avant. Il peut aussi \u00eatre n\u00e9cessaire qu'un autre microservice soit d\u00e9ploy\u00e9 pour qu'un microservice soit op\u00e9rationnel (dans le cas des workflows par exemple).</p> <p>C'est ce que j'appelle : la d\u00e9pendance de d\u00e9ploiement.</p> <p>Example</p> <ul> <li>Les batchs et les webservices n\u00e9cessitent que l'infrastructure soit d\u00e9ploy\u00e9e.</li> <li>Le WebService2 pour fonctionner n\u00e9cessite que le WebService1 soit d\u00e9ploy\u00e9.  </li> </ul> <p>Encore une fois, afin de garantir la robustesse de la solution, je veux m'assurer que s'il y a un souci lors de d\u00e9ploiement d'un composant, que l'ensemble des composants qui en d\u00e9pendent et qui n\u00e9cessites d'\u00eatre d\u00e9ploy\u00e9s ne le soient pas.</p> <p>Example</p> <p>Le d\u00e9ploiement du WebService1 est en erreur, le WebService2 qui n\u00e9cessite d'\u00eatre d\u00e9ploy\u00e9 doit \u00eatre bloqu\u00e9.  </p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#le-cycle-de-mise-en-production","title":"Le cycle de mise en production","text":"<p>J'aime \u00e0 penser que les cr\u00e9ateurs du logo DevOps, le fameux symbole infini ou le 8 allong\u00e9 n'ont pas choisi ce logo de fa\u00e7on anodine. En effet, ils auraient pu choisir un cercle. Mais non...</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#la-boucle-de-rejet","title":"La boucle de rejet","text":"<p>La boucle de rejet consiste \u00e0 rejeter tous d\u00e9veloppements r\u00e9alis\u00e9s qui ne correspondent pas aux standards de qualit\u00e9 d\u00e9finis par l'\u00e9quipe. Ce qui veut dire qu'\u00e0 la sortie de la phase Test de notre boucle DevOps, en cas d'\u00e9chec, il faut passer directement \u00e0 la phase Plan pour corriger l'anomalie.</p> <p></p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#la-boucle-de-succes","title":"La boucle de succ\u00e8s","text":"<p>La boucle de succ\u00e8s consiste \u00e0 d\u00e9ployer sur l'environnement suivant le composant valid\u00e9 sur l'environnement actuel. Ce qui implique qu'\u00e0 la sortie de la phase Monitor de notre boucle DevOps en cas de succ\u00e8s (les tests d'int\u00e9gration, de performance ou fonctionnel sont concluant), on peut passer directement \u00e0 la phase Deploy pour proc\u00e9der au d\u00e9ploiement du composant sur l'environnement suivant.</p> <p></p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#ne-deployer-que-ce-qui-a-ete-valide","title":"Ne d\u00e9ployer que ce qui a \u00e9t\u00e9 valid\u00e9","text":"<p>Reprenons notre cycle Agile avec les diff\u00e9rentes phases de validation sur les environnements d'int\u00e9gration puis de recette m\u00e9tier.</p> <ul> <li>Pendant le sprint, chaque UserStory sera d\u00e9ploy\u00e9 sur l'environnement d'int\u00e9gration (DEV) afin de valider en continue les tests d'int\u00e9gration.</li> </ul> <p></p> <ul> <li>En fin de sprint, \u00e0 la suite de la d\u00e9mo. et de la validation des UserStory, les d\u00e9veloppements sont d\u00e9ploy\u00e9s sur l'environnement de recette m\u00e9tier (UAT).</li> </ul> <p></p> <ul> <li>A la fin de la recette m\u00e9tier, les d\u00e9veloppements sont d\u00e9ploy\u00e9s sur l'environnement de production.</li> </ul> <p></p> <p>On constate ainsi que l'on ne d\u00e9ploie que ce qui a \u00e9t\u00e9 valid\u00e9 sans pour autant repasser par les phases Plan, Code, Build et Test. On utilise \"la boucle de succ\u00e8s\". </p> <p>Note</p> <p>L'utilisation de feature flag nous permettra dans certain cas d'\u00e9viter un d\u00e9ploiement, mais ce n'est pas pour autant qu'il n'y aura pas de phase dans notre pipeline. Il faudra pr\u00e9voir \u00e0 la place du d\u00e9ploiement l'activation ou la d\u00e9sactivation de telle ou telle feature.</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#le-trunk-based-development","title":"Le Trunk-Based Development","text":"<p>Le Trunk-Based Development est un branching model git tr\u00e8s pl\u00e9biscit\u00e9 dans la communaut\u00e9 DevOps. Il a l'int\u00e9r\u00eat d'\u00eatre simple \u00e0 g\u00e9rer gr\u00e2ce \u00e0 son unique branche de d\u00e9veloppement et compatible avec le maintien op\u00e9rationnel de plusieurs versions techniques d'un composant, du fait de ses branches de release.</p> <p>Note</p> <p>Les branches de feature sont autoris\u00e9es mais doivent \u00eatre tr\u00e8s courtes dans le temps.</p> <p>Dans le cadre de notre cycle Agile, \u00e0 la fin de chaque sprint, nous allons tirer une branche de release pour chacune des librairies et chacun des composants qui ont \u00e9volu\u00e9 durant le sprint et qui ont \u00e9t\u00e9 valid\u00e9s durant la d\u00e9mo.</p> <p>Rappel des r\u00e8gles Agile du chapitre 1</p> <ol> <li>Les it\u00e9rations ont une dur\u00e9e de 3 semaines,</li> <li>La recette fonctionnelle doit \u00eatre faite par une \u00e9quipe m\u00e9tier ind\u00e9pendante de l'\u00e9quipe de r\u00e9alisation,</li> <li>Les tests d\u2019int\u00e9gration sont inclus dans le Definition Of Done de l\u2019\u00e9quipe de r\u00e9alisation,</li> <li>Les d\u00e9lais doivent \u00eatre r\u00e9duits au maximum.</li> </ol> <p>Ces branches de release vont contenir le code \"sanctuaris\u00e9\". Le code contenu dans ces branches a pass\u00e9 l'int\u00e9gralit\u00e9 des tests, des mesures de qualit\u00e9s et de s\u00e9curit\u00e9 impos\u00e9s par l'\u00e9quipe. Le code est stable.</p> <p></p> <p>C'est depuis la branche master, main ou trunk contenant le code en cours de d\u00e9veloppement que nos d\u00e9ploiements sur l'environnement d'int\u00e9gration (DEV) seront r\u00e9alis\u00e9s. Comme ce qui est en cours de d\u00e9veloppement est potentiellement instable, nous devons emp\u00eacher que ce qui est produit sur cette branche puisse \u00eatre d\u00e9ploy\u00e9 sur les environnements de recette m\u00e9tier ou de production.</p> <p>Et c'est depuis les branches de release que le code qui a \u00e9t\u00e9 pr\u00e9alablement valid\u00e9 (qualit\u00e9, s\u00e9curit\u00e9, fiabilit\u00e9, int\u00e9grit\u00e9, maintenabilit\u00e9, ...) et dit stable va pouvoir \u00eatre d\u00e9ploy\u00e9 sur les environnements de recette m\u00e9tier (UAT), puis de production. Si durant la recette m\u00e9tier (ou pire, en production), nous constatons une anomalie, celle-ci pourra \u00eatre corrig\u00e9e avec un Hotfix en utilisant des cherry-pick. Et pour garantir que ce qui est d\u00e9ploy\u00e9 en production est toujours fiable, \u00e0 chaque fois, le composant doit \u00eatre d\u00e9ploy\u00e9 et test\u00e9 auparavant sur les environnements d'int\u00e9gration, puis de recette m\u00e9tier.</p> <p></p> <p>Nous devons appliquer cette m\u00e9thodologie pour chaque repository (et donc chaque composant) de notre solution.</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#en-resume","title":"En r\u00e9sum\u00e9","text":"<p>Les d\u00e9pendances de compilations ou de d\u00e9ploiement, le cycle de mise en production et le branching model sont des facteurs cl\u00e9s de la mise en place d'une d\u00e9marche DevOps. Il est tr\u00e8s important lors de l'initialisation de votre projet de bien cadrer ces \u00e9l\u00e9ments qui peuvent parfois \u00eatre tr\u00e8s complexes \u00e0 r\u00e9ajuster en cours de route.</p> <p>Nous verrons dans le prochain chapitre un sujet que j'affectionne tout particuli\u00e8rement : \"L'entropie des syst\u00e8mes\". Et nous verrons que la d\u00e9marche DevOps n'\u00e9chappe pas \u00e0 la formule de Boltzmann.</p> <p>A suivre...</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/02.pourquoi.devops/#remerciements","title":"Remerciements","text":"<ul> <li>Samy Mameri : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 13 Octobre 2021</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/","title":"Chapitre 3 : L'entropie","text":"","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#lentropie","title":"L'entropie","text":"<p>Comme pour tout, le temps fait son \u0153uvre. La d\u00e9marche DevOps n'y \u00e9chappe pas. Vous pouvez avoir une d\u00e9marche tr\u00e8s aboutie, au bout de plusieurs mois ou plusieurs ann\u00e9es, celle-ci aura naturellement du plomb dans l'aile.</p> <p>Reprenons notre projet d'application bas\u00e9 sur une architecture microservice plut\u00f4t complexe. Ce type d'application (souvent c\u0153ur m\u00e9tier) est vou\u00e9 \u00e0 \u00e9voluer r\u00e9guli\u00e8rement avec des nouvelles fonctionnalit\u00e9s, mais aussi des plus anciennes qu'il faut d\u00e9commissionner. Le choix d'une architecture microservice permet de simplifier l'ajout et le d\u00e9commissionnement de fonctionnalit\u00e9s en r\u00e9duisant le p\u00e9rim\u00e8tre de l'impact. Mais avec le temps, cela peut s'av\u00e9rer complexe \u00e0 g\u00e9rer au niveau de la d\u00e9marche DevOps.</p> <p>Sprint 0 \u00e0 3</p> <ol> <li>Durant le Sprint 0 l'\u00e9quipe initialise l'infrastructure permettant d'h\u00e9berger notre solution. A la fin de ce sprint, elle livre l'Infra (v1.0). </li> <li>Ensuite, au Sprint 1 l'\u00e9quipe r\u00e9alise les 2 premiers microservices web Web1 (v1.0) et Web2 (v1.0) et apporte d\u00e9j\u00e0 une petite \u00e9volution \u00e0 l'infrastructure Infra (v1.1). </li> <li>Puis, au Sprint 2 l'\u00e9quipe r\u00e9alise un microservice batch Batch1 (v1.0). Elle constate que certains d\u00e9veloppements r\u00e9alis\u00e9s pour le microservice Web1 peuvent \u00eatre r\u00e9utilis\u00e9s pour le Batch1. L'\u00e9quipe d\u00e9cide de cr\u00e9er une libraire contenant le code commun et de faire \u00e9voluer le microservice Web1 pour utiliser cette librairie. A la fin du sprint l'\u00e9quipe livre : Lib1 (v1.0), Batch1 (v1.0) et Web1 (v1.1). </li> <li>Et, au Sprint 3 avec le feedback des premiers utilisateurs, l'\u00e9quipe constate que le microservice Web2 n'est pas utilis\u00e9 et n'apporte rien \u00e0 la solution. Elle d\u00e9cide de d\u00e9commissionner celui-ci et de le remplacer par un autre microservice Batch2 (v1.0). Une faille de s\u00e9curit\u00e9 web ayant \u00e9t\u00e9 identifi\u00e9e sur la solution, l'\u00e9quipe d\u00e9cide de corriger celle-ci en modifiant l'infrastructure Infra (v1.2) et le microservice Web1 (v1.2). </li> </ol> <p>Vous pouvez constater que l'agilit\u00e9 et la d\u00e9marche DevOps permettent une tr\u00e8s grande flexibilit\u00e9-\u00e9volutivit\u00e9. Mais lorsque notre projet s'\u00e9tale sur des dizaines de sprints, cela peut vite d\u00e9router l'\u00e9quipe qui a besoin d'un minimum de stabilit\u00e9 pour maitriser l'int\u00e9gralit\u00e9 du code de la solution.</p> <p>Imaginons que notre \u00e9quipe arrive au Sprint 63 (Oui ! Pour le vivre actuellement chez un client, cela arrive). Il n'est pas compliqu\u00e9 d'imaginer qu'au bout de 63 it\u00e9rations notre application qui est maintenant compos\u00e9 d'une trentaines de microservices, a v\u00e9cue des milliers de builds et de d\u00e9ploiements. A chaque fin de sprint, il y a eu un nombre variables mais globalement croissant d'ajouts, d'\u00e9volutions ou de d\u00e9commissionements de microservices. Ces changements successifs vont avoir un impact d\u00e9l\u00e9t\u00e8re sur la d\u00e9marche DevOps. C'es l'entropie du DevOps !</p> <p></p> <p>Posez-vous la question</p> <p>Est-ce que je suis capable de red\u00e9ployer from scratch mon application \u00e0 l'\u00e9tat ou elle \u00e9tait il y a 4 ou 5 it\u00e9rations ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#le-cocktail-agilite-devops-entropie","title":"Le cocktail Agilit\u00e9 + DevOps + Entropie !","text":"<p>On constate que l'agilit\u00e9, la d\u00e9marche DevOps et le temps (l'entropie) apportent chacun leur lot de probl\u00e9matiques. Mais si l'on additionne tout cela, on obtient un cocktail difficile \u00e0 dig\u00e9rer.</p> <p>Sprint X</p> <p>La UserStory X dans le Sprint X impacte la librairie Lib2. L'\u00e9quipe proc\u00e9de \u00e0 l'\u00e9volution sur le tronc (on est en TBD). Suite \u00e0 la d\u00e9mo. celle-ci cr\u00e9e une nouvelle branche de release pour relivrer la librairie. </p> <p>Pour assurer la r\u00e9silience de la solution, on veut reconstruire l'ensemble des microservices utilisant cette librairie : Web1 et Web2 (d\u00e9pendance de build). L'\u00e9quipe doit relancer le pipeline de CI/CD des microservices \u00e0 partir de leur derni\u00e8re branche de release. </p> <p>Finalement, la UserStory X d\u00e9clenche la cr\u00e9ation d'une nouvelle version de la Lib2, mais aussi le red\u00e9ploiement de l'ensemble des microservices utilisant la libairie : Web1 et Web2. </p> <p>Sprint X+1</p> <p>Durant le Sprint suivant, la UserStory Y consiste \u00e0 cr\u00e9er un nouveau microservice Web3. Et pour h\u00e9berger ce nouveau microservice nous allons devoir mettre \u00e0 jour notre infrastructure (par exemple, instancier une nouvelle Azure WebApp). L'\u00e9quipe : </p> <ul> <li>cr\u00e9e une nouveau repository qui contiendra le code de notre microservice Web3.</li> <li>r\u00e9alise une \u00e9volution sur le tronc du repository de l'infrastructure.</li> </ul> <p>Apr\u00e8s la d\u00e9mo., l'\u00e9quipe cr\u00e9e une nouvelle branche de release pour livrer le microservice Web3 et l'\u00e9volution de l'infrastructure. Afin de pouvoir d\u00e9ployer le nouveau microservice elle doit aussi avoir au pr\u00e9alable d\u00e9ployer la mise \u00e0 jour de l'infrastructure (d\u00e9pendance de d\u00e9ploiement).</p> <p>Durant ce Sprint, l'\u00e9quipe de recette m\u00e9tier d\u00e9tecte une anomalie sur le service Web1 li\u00e9 \u00e0 la derni\u00e8re \u00e9volution de la Lib2, l'\u00e9quipe doit donc faire un hotfix sur le Web1. Elle proc\u00e8de \u00e0 la correction sur le tronc du repository. Puis une fois valid\u00e9e sur l'environnement d'int\u00e9gration, l'\u00e9quipe proc\u00e8de \u00e0 un cherry-pick des commits de correction sur la branche de release correspondant \u00e0 la version \u00e0 relivrer. Encore une fois il faut proc\u00e9der \u00e0 une validation sur l'environnement d'int\u00e9gration afin de s'assurer qu'il n'y a pas eu de regression, avant de pouvoir d\u00e9ployer sur l'environnement de recette m\u00e9tier. </p> <p>Suis-je capable de red\u00e9ployer from scratch mon application \u00e0 l'\u00e9tat du Sprint X ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#le-phenomene-daccumulation","title":"Le ph\u00e9nom\u00e8ne d'accumulation","text":"<p>Il y a pire encore... Reprenons l'exemple au-dessus de l'anomalie d\u00e9tect\u00e9e. L'\u00e9quipe de r\u00e9alisation ayant beaucoup de repository \u00e0 g\u00e9rer (Et m\u00eame si celle-ci maitrise parfaitement tout son code et sa d\u00e9marche) met plusieurs jours pour relivrer le hotfix en recette m\u00e9tier. L'\u00e9quipe m\u00e9tier va vouloir proc\u00e9der \u00e0 nouveau \u00e0 la recette, puis constate qu'elle arrive en fin de Sprint et d\u00e9cide donc de d\u00e9caler la recette de cette UserStory au Sprint suivant. On arrive l\u00e0 devant un dilemme : </p> <ol> <li>Doit-on livrer tous nos composants sauf celui-ci en production ? Ou, </li> <li>Doit-on conditionner la mise en production \u00e0 la validation de cette UserStory et donc d\u00e9caler la mise en production au Sprint suivant ?</li> </ol> <p>Dans certains cas, vous pourrez choisir l'option 1 et donc limiter le ph\u00e9nom\u00e8ne d'accumulation \u00e0 un seul composant. Mais dans d'autres cas, vous serez oblig\u00e9 de choisir l'option 2.</p> <p></p> <p>Les features flags</p> <p>L'utilisation de feature flags vous permet d'\u00e9viter ce ph\u00e9nom\u00e8ne.</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#conclusion","title":"Conclusion","text":"","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#1-le-nombre-de-deploiements","title":"1. Le nombre de d\u00e9ploiements","text":"<p>Plus l\u2019\u00e9quipe a la capacit\u00e9\u00a0de produire des UserStory dans un sprint plus le nombre de d\u00e9ploiement est important. Lorsque l\u2019on a plusieurs dizaines de microservices, comment s\u2019assurer qu\u2019aucune mise \u00e0 jour n\u2019a \u00e9t\u00e9 oubli\u00e9e ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#2-les-dependances","title":"2. Les d\u00e9pendances","text":"<p>Les composants d\u2019une architecture microservice pr\u00e9sentent des d\u00e9pendances. Mais lorsque l'on a des dizaines de d\u00e9pendances de builds, comment s\u2019assurer que chaque composant utilise la bonne version de celles-ci ? Lorsque l'on a des dizaines de d\u00e9pendances de d\u00e9ploiements, comment stopper tous les processus de mise \u00e0 jour des d\u00e9pendances en cas d\u2019\u00e9chec de d\u00e9ploiement d\u2019un composant ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#3-la-gestion-des-repository-git","title":"3. La gestion des repository Git","text":"<p>Si chaque composant et chaque libraire a son propre repository git, le projet d'application peut rapidement cumuler plusieurs dizaines de repository. Lors d'une mise en recette m\u00e9tier, comment s\u2019assurer que toutes les \u00e9volutions et corrections apport\u00e9es dans le Sprint vont \u00eatre embarqu\u00e9es par la cr\u00e9ation d'une branche sur les repository impact\u00e9s et uniquement ces derniers ? Comment maintenir le model branching sur tous les repository ? Comment maintenir le semantic versioning ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#4-les-cycles-de-recette","title":"4. Les cycles de recette","text":"<p>Les recettes m\u00e9tiers sont r\u00e9alis\u00e9es apr\u00e8s la d\u00e9mo. du sprint sur un environnement de validation par une \u00e9quipe de test. Comment s\u2019assurer que les r\u00e9alisations sont pouss\u00e9es rapidement et correctement (les points 1, 2 et 3) afin de permettre \u00e0 la recette de se passer dans les meilleures conditions ? En cas d'anomalie d\u00e9tect\u00e9es par l'\u00e9quipe de recette, comment relivrer rapidement le correctif afin de ne pas bloquer le cycle des recettes ?</p> <p>Mais alors, comment lutter contre l\u2019entropie tout en maintenant une m\u00e9thodologie agile soutenable ?</p> <p>Dans la prochaine partie, je vous pr\u00e9senterais une solution que j'ai \u00e9labor\u00e9 pour r\u00e9pondre \u00e0 ces probl\u00e9matiques en mettant en place des techniques, bas\u00e9es sur des concepts simples et \u00e9prouv\u00e9s tel que la machine \u00e0 \u00e9tat et les manifestes.</p> <p>A suivre...</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/03.pourquoi.entropie/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 26 Octobre 2021</p>","tags":["DevOps","Agile","Entropie"]},{"location":"articles/devops/vrille/04.comment.machineetat/","title":"Chapitre 1 : La machine \u00e0 \u00e9tat","text":"<p>Nous avons pu constater dans la premi\u00e8re partie qu'il y avait de multiples moyens pour faire \"partir en vrille\" la d\u00e9marche DevOps. Pour avoir \u00e9t\u00e9 confront\u00e9 \u00e0 ces probl\u00e9matiques, j'ai cherch\u00e9 un bon moment quel serait le meilleur moyen pour r\u00e9soudre ces diff\u00e9rents probl\u00e8mes. </p> <p>La solution est arriv\u00e9e lors d'une discussion en voiture avec un de mes coll\u00e8gues de travail. Je lui parlais de mes soucis de mise en UAT et de mise en PROD. Que j'avais pourtant mis en place une d\u00e9marche DevOps dans les r\u00e8gles de l'art mais que pourtant il me fallait facilement une journ\u00e9e pour r\u00e9aliser mes mises en UAT ou en PROD. </p> <p>Mon coll\u00e8gue me r\u00e9pond : \"T'as essay\u00e9 d'utiliser une machine \u00e0 \u00e9tat ?\"</p> <p>EUREKA !</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/04.comment.machineetat/#la-machine-a-etat","title":"La machine \u00e0 \u00e9tat","text":"<p>Voici un bref exemple d'une machine \u00e0 \u00e9tat :</p> <p>Imaginons que nous souhaitions d\u00e9finir le fonctionnement d'un film sur notre lecteur BluRay.  Le film \u00e0 3 \u00e9tats :</p> <ul> <li>Arr\u00eat\u00e9</li> <li>En cours (de lecture)</li> <li>En pause</li> </ul> <p>Pour passer d'un \u00e9tat \u00e0 un autre nous avons des actions :</p> <ul> <li>Lancer le film</li> <li>Stopper le film</li> <li>Mettre en pause</li> <li>Reprendre le film</li> </ul> <p>Nous repr\u00e9senterons alors notre machine \u00e0 \u00e9tat sous la forme du sch\u00e9ma ci-dessous.</p> <p></p> <p>La mod\u00e9lisation d'un syst\u00e8me sous forme d'une machine \u00e0 \u00e9tat permet de simplifier la compr\u00e9hension des diff\u00e9rents moyens possibles pour passer d'un \u00e9tat \u00e0 un autre.</p> <p>Ce que l'on n'a pas repr\u00e9sent\u00e9 ici mais qui est essentiel, c'est le d\u00e9clencheur. Dans le cas de notre film BluRay, ce sera le fait que l'utilisateur appuie sur tel ou tel bouton de sa t\u00e9l\u00e9commande.  Pour notre lecteur BluRay, nous aurons les d\u00e9clencheurs :</p> <ul> <li>Appuie sur Play</li> <li>Appuie sur Pause</li> <li>Appuie sur Stop</li> </ul> <p></p> <p>Appliquons maintenant cette mod\u00e9lisation \u00e0 notre d\u00e9marche DevOps. Ind\u00e9pendamment des microservices qui composent notre application, celle-ci \u00e0 ses propres \u00e9tats :</p> <ul> <li>Build\u00e9 : l'application est compil\u00e9e et livr\u00e9e mais pas encore d\u00e9ploy\u00e9e,</li> <li>D\u00e9ploy\u00e9 en DEV : l'application est d\u00e9ploy\u00e9e sur l'environnement d'int\u00e9gration,</li> <li>D\u00e9ploy\u00e9 en UAT : l'application est d\u00e9ploy\u00e9e sur l'environnement de recette m\u00e9tier,</li> <li>D\u00e9ploy\u00e9 en PROD : l'application est d\u00e9ploy\u00e9e en PROD</li> </ul> <p>Pour passer d'un \u00e9tat \u00e0 l'autre nous aurons les actions suivantes :</p> <ul> <li>Ex\u00e9cuter le build</li> <li>D\u00e9ployer en DEV</li> <li>D\u00e9ployer en UAT</li> <li>D\u00e9ployer en PROD</li> </ul> <p></p> <p>Certes l'exemple ci-dessus nous montre une machine \u00e0 \u00e9tat tr\u00e8s lin\u00e9aire. Mais ce qui va nous int\u00e9resser particuli\u00e8rement dans la notre ce sont les d\u00e9clencheurs et les conditions.</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/04.comment.machineetat/#letat-builde","title":"L'\u00e9tat \"Build\u00e9\"","text":"<p>Chaque composant \u00e0 son propre cycle DevOps et chacun peut influer sur le comportement global de l'application. Si l'\u00e9quipe d\u00e9cide de r\u00e9aliser une modification sur une librairie utilis\u00e9 par plusieurs composants, son build doit d\u00e9clencher le re-build de composants d\u00e9pendants (d\u00e9pendance de compilation). Ce qui veut dire que l'\u00e9v\u00e8nement d\u00e9clencheur au niveau du pipeline DevOps de la librairie sera le commit-push et en cas de succ\u00e8s du build de la librairie, ce sera celui-ci l'\u00e9v\u00e8nement d\u00e9clencheur des composants.</p> <p>Au niveau de l'application on consid\u00e9rera que l'application est build\u00e9e \u00e0 partir du moment o\u00f9 la librairie et tous les composants d\u00e9pendants seront build\u00e9s. Pour passer \u00e0 l'\u00e9tat \"Build\u00e9\", on a :</p> <ul> <li>Un \u00e9v\u00e8nement d\u00e9clencheur : Le commit sur le repo de la librairie,</li> <li>Une condition : Le succ\u00e8s du build de la librairie et des composants d\u00e9pendants.</li> </ul> <p>Evolution sur une librairie</p> <p>Au cours de mon sprint l'\u00e9quipe r\u00e9alise une \u00e9volution sur la libraire Lib1. Celle-ci est utilis\u00e9e par le composant Batch1. </p> <p>L'\u00e9v\u00e8nement d\u00e9clencheur est le commit sur le repo et la condition est le succ\u00e8s du build de notre librairie et de notre batch. </p> <p>Notre librairie \u00e9tant embarqu\u00e9e dans notre batch au moment de la compilation, celle-ci ne sera pas un livrable \u00e0 d\u00e9ployer.</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/04.comment.machineetat/#les-etats-deploye","title":"Les \u00e9tats \"D\u00e9ploy\u00e9\"","text":"<p>Pour pouvoir d\u00e9ployer notre composant sur un environnement, il faut au pr\u00e9alable s'assurer que l'environnement soit pr\u00eat \u00e0 l'accueillir (d\u00e9pendance de d\u00e9ploiement) :</p> <ul> <li>l'infra. est disponible, </li> <li>les composants avec lesquels il va communiquer sont op\u00e9rationnels.</li> </ul> <p>Il peut y avoir de multiples \u00e9v\u00e8nements d\u00e9clencheurs pour passer de notre \u00e9tat \"Build\u00e9\" \u00e0 notre \u00e9tat \"D\u00e9ploy\u00e9\" :</p> <ul> <li>Le fait d'\u00eatre dans l'\u00e9tat \"Build\u00e9\" : On parlera ici de d\u00e9ploiement automatique ou de continuous deployment.</li> <li>L'approbation par une ou plusieurs personnes.</li> <li> <p>La validation d'un ou plusieurs crit\u00e8res :</p> <ul> <li>UserStory \u00e0 l'\u00e9tat livr\u00e9e,</li> <li>Health Check,</li> <li>...</li> </ul> </li> </ul> <p>En termes de condition, on veillera \u00e0 s'assurer que les d\u00e9pendances de d\u00e9ploiement sont respect\u00e9es.</p> <p>Evolution sur une librairie et d\u00e9ploiement en DEV</p> <p>Reprenons notre exemple pr\u00e9c\u00e9dent. </p> <p>Notre composant Batch1 pour pouvoir fonctionner n\u00e9cessite que l'infrastructure soit d\u00e9ploy\u00e9e.</p> <p>Le fait que notre application soit \u00e0 l'\u00e9tat \"Build\u00e9\" est l'\u00e9v\u00e8nement d\u00e9clencheur pour proc\u00e9der au d\u00e9ploiement de notre Batch1 (D\u00e9ploiement continu). </p> <p>Les conditions pour passer d'un \u00e9tat \"D\u00e9ploy\u00e9\" \u00e0 un autre identique seront les m\u00eames peu importe l'environnement.</p> <p>Evolution sur une librairie et d\u00e9ploiement en UAT et en PROD</p> <p>Notre composant Batch1 pour pouvoir fonctionner en UAT ou en PROD n\u00e9cessite que l'infrastructure soit d\u00e9ploy\u00e9e (notre condition).</p> <p>L'\u00e9v\u00e8nement d\u00e9clencheur pour passer \u00e0 l'\u00e9tat d\u00e9ploy\u00e9 en UAT est la validation de notre d\u00e9mo. en fin de sprint.</p> <p>L'\u00e9v\u00e8nement d\u00e9clencheur pour passer \u00e0 l'\u00e9tat d\u00e9ploy\u00e9 en PROD est la validation de notre application \u00e0 la fin de la recette m\u00e9tier. </p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/04.comment.machineetat/#conclusion","title":"Conclusion","text":"<p>En prenant un peu de recul on s'aper\u00e7oit que notre machine \u00e0 \u00e9tat reprend les codes de notre cycle DevOps.</p> <p></p> <p>Ce qui veut dire que l'on a un cycle DevOps au niveau de notre application. Ce cycle doit pouvoir piloter les pipelines DevOps de tous nos composants et librairies. Il doit aussi s'assurer que les conditions (d\u00e9pendances de build et de d\u00e9ploiement) sont respect\u00e9es.</p> <p>Dans le prochain article nous verrons en d\u00e9tail comment mettre en place les conditions et les actions n\u00e9cessaires au pilotage des builds.</p> <p>A suivre... </p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/04.comment.machineetat/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/04.comment.machineetat/#remerciements","title":"Remerciements","text":"<ul> <li>Nicolas Giraud : pour l'id\u00e9e de la machine \u00e0 \u00e9tat</li> <li>Michael Maillot : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 08 Novembre 2021</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/","title":"Chapitre 2 : Le build","text":"<p>Maintenant que nous avons conceptualis\u00e9 le principe de machine \u00e0 \u00e9tat dans un \"meta\" pipeline CI/CD, comment faire pour que le build de nos diff\u00e9rents composants puisse \u00eatre g\u00e9r\u00e9 de fa\u00e7on harmonieuse ?</p> <p>Comment faire pour s'assurer qu'une \u00e9volution sur une librairie va entrainer syst\u00e9matiquement la recompilation de composants utilisant cette librairie ?</p> <p>Comment faire pour ne recompiler que ce qu'il y a besoin de recompiler ?</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#la-conceptualisation-du-processus-de-build","title":"La conceptualisation du processus de build","text":"<p>Pour commencer, il nous faut un r\u00e9f\u00e9rentiel de build. </p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#le-referentiel-de-build","title":"Le r\u00e9f\u00e9rentiel de build","text":"<p>Ce r\u00e9f\u00e9rentiel aura pour unique but d'identifier chaque composant de notre application, avec :</p> <ul> <li>le nom du repository Git</li> <li>la derni\u00e8re version,</li> <li>l'id du commit Git li\u00e9 \u00e0 la derni\u00e8re version,</li> <li>les d\u00e9pendances du composant</li> </ul> <p>exemple</p> <p>Imaginons 2 librairies : Lib1 et Lib2. Lib2 d\u00e9pend de Lib1.</p> <p>Voici ce que pourrait donner notre r\u00e9f\u00e9rentiel au format yaml :</p> <pre><code>components:\n- name: lib1\n  version: 1.0\n  commit: 0123456789ab\n- name: lib2\n  version: 1.0\n  commit: 123456789abc\n  dependencies: \n  - lib1\n</code></pre> <p>Ce r\u00e9f\u00e9rentiel va \u00e9voluer au fur et \u00e0 mesure des it\u00e9rations pour correspondre exactement \u00e0 l'\u00e9tat souhait\u00e9 de tous les composants de l'application. Et pour permettre une historisation des \u00e9volutions au fur et \u00e0 mesure des it\u00e9rations, quoi de mieux qu'un repository Git. On va donc mettre notre r\u00e9f\u00e9rentiel de build dans un repo. que l'on va nommer \"meta\".</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#le-processus-de-build","title":"Le processus de build","text":"<p>Imaginons que j'apporte une modification sur mon r\u00e9f\u00e9rentiel de build, cela implique que j'ai ajout\u00e9, modifi\u00e9 ou supprim\u00e9 un ou plusieurs composants de mon application. Pour ne pas prendre de risque je vais donc parcourir chaque composant d\u00e9clar\u00e9 dans mon r\u00e9f\u00e9rentiel et pour chacun, v\u00e9rifier :</p> <ul> <li>s'il a d\u00e9j\u00e0 \u00e9t\u00e9 build\u00e9 : il n'y aura donc rien \u00e0 faire,</li> <li>s'il y a une mise \u00e0 jour : il faudra d\u00e9clencher le build du composant,</li> <li>s'il y a eu une mise \u00e0 jour d'une des d\u00e9pendances : il faudra red\u00e9clencher le build du composant,</li> <li>s'il y a eu un \u00e9chec d'une d\u00e9pendance : il ne faudra pas lancer le build.</li> </ul> <p>C'est comme un arbre o\u00f9 chaque composant correspond \u00e0 un noeud.</p> <p>exemple</p> <p>Imaginons que durant notre sprint nous ayons fait \u00e9voluer nos composants B, D, G et H.  Ci-dessous l'arbre de d\u00e9pendances correspondant : </p> <p>Lors de l'ex\u00e9cution de notre \"meta\" pipeline pour passer notre application \u00e0 l'\u00e9tat build\u00e9, il faudra :</p> <ul> <li>Ignorer les composants A et C,</li> <li>Compiler les composant B, D, G et H,</li> <li>Recompiler les composants E, F, I, J et K qui ont vu leurs d\u00e9pendances \u00e9voluer (v\u00e9rification de la non-r\u00e9gression)</li> </ul> <p>Si durant le processus, le composant H est en \u00e9chec (erreur remont\u00e9e lors de la compilation ou de l'ex\u00e9cution des tests unitaires), alors il faudra veiller \u00e0 stopper le processus et ne pas builder les composants d\u00e9pendants. Le composant K est donc bloqu\u00e9 par son pr\u00e9d\u00e9cesseur le composant H.</p> <p>Notre build applicatif peut se repr\u00e9senter sous la forme du processus ci-dessous : </p> <p></p> <p>Le processus va parcourir le r\u00e9f\u00e9rentiel de build en commen\u00e7ant par ceux qui n'ont pas de d\u00e9pendance, puis par ceux qui d\u00e9pendent de ces premiers, et ainsi de suite. </p> <p>Note</p> <p>Je vous recommande d'utiliser des processus parall\u00e8les pour parcourir l'arbre.</p> <p>exemple</p> <p>Si on reprend notre exemple ci-dessus, on aura par ordre de passage :</p> <ol> <li>A</li> <li>B et C</li> <li>D, E, F, G et H</li> <li>I, J, K</li> </ol> <p>Pour chaque composant,</p> <ol> <li>on v\u00e9rifie si celui-ci a d\u00e9j\u00e0 \u00e9t\u00e9 correctement build\u00e9 (commit d\u00e9j\u00e0 build\u00e9).</li> </ol> <p>Note</p> <p>Il existe une multitude de raisons, autres que le code en lui-m\u00eame, d'\u00e9chec d'un build. Par exemple : </p> <ul> <li>La saturation du disque dur de l'agent de build, </li> <li>L'indisponibilit\u00e9 d'un service utilis\u00e9 durant le build (sonarqube, artifactory, ...).</li> </ul> <p>Il faut pr\u00e9voir la possibilit\u00e9 de relancer le build en \u00e9chec ult\u00e9rieurement.</p> <ol> <li>si oui, on v\u00e9rifie que ses d\u00e9pendances n'ont pas \u00e9volu\u00e9.</li> <li>si c'est le cas, on passe au composant suivant. Sinon, on d\u00e9clenche le build.</li> <li>si celui-ci n'a pas d\u00e9j\u00e0 \u00e9t\u00e9 correctement build\u00e9, on d\u00e9clenche le build.</li> <li>on attend la fin du build et on r\u00e9cup\u00e8re le r\u00e9sultat.</li> <li>si le build est OK, on passe au composant suivant.</li> <li>si le build est KO, on stoppe le build des composants d\u00e9pendants.</li> </ol> <p>Une fois le r\u00e9f\u00e9rentiel totalement parcouru, on peut d\u00e9terminer l'\u00e9tat de notre application. Si tous les composants ont \u00e9t\u00e9 correctement build\u00e9s, alors on peut consid\u00e9rer que notre application est correctement build\u00e9e.</p> <p>Ainsi nous pouvons passer l'\u00e9tat de notre application \u00e0 \"Build\u00e9\".</p> <p></p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#le-pilotage-des-repositories-git","title":"Le pilotage des repositories Git","text":"<p>Cependant, pour pouvoir d\u00e9clencher le build de nos diff\u00e9rents composants, il va falloir piloter les repositories Git de chacun des composants.</p> <p>Par exemple, en fin de sprint et suite \u00e0 la validation par le client de la d\u00e9mo., je vais vouloir builder une version stable de l'ensemble des composants de l'application avec pour objectif de d\u00e9ployer les \u00e9volutions de l'application jusqu'en production. </p> <ul> <li>Si je suis en Trunk Based Developement, je vais vouloir cr\u00e9er des branches de release et poser des tags sur les repositories de mes composants.</li> <li>Si je suis en Github Flow, je vais vouloir poser des tags sur la branche main sur les repositories de mes composants.</li> </ul> <p>Dans le d\u00e9tail, l'\u00e9tape de d\u00e9clenchement du build va se d\u00e9composer comme ceci :</p> <p></p> <p>Nous devons d\u00e9clencher le pipeline CI/CD de nos composants pour pouvoir d\u00e9clencher nos builds !</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#le-pilotage-des-pipelines-de-cicd","title":"Le pilotage des pipelines de CI/CD","text":"<p>Mais pour pouvoir ensuite faire avancer les pipelines CI/CD de nos diff\u00e9rents composants, il va falloir identifier exactement les pipelines correspondants aux builds de ces derniers. Notre phase de Build doit donc g\u00e9n\u00e9rer un fichier manifeste permettant d'identifier les pipelines de chaque composant.</p> <p></p> <p>exemple</p> <p>Voici notre manifeste au format yaml :</p> <pre><code>components:\n  - name: web1\n    pipelineId: id1\n  - name: web2\n    pipelineId: id2\n  - name: infra\n    pipelineId: id3\n  - name: batch1\n    pipelineId: id4\n</code></pre>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#conclusion","title":"Conclusion","text":"<p>Nous avons vu dans ce chapitre comment g\u00e9rer le build des composants d'une application. Cette phase de notre \"meta\" pipeline va nous mettre \u00e0 disposition un manifeste qui nous permettra dans un second temps de piloter le d\u00e9ploiement de nos diff\u00e9rents composants. Nous verrons cela dans le prochain chapitre.</p> <p>A suivre... </p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/05.comment.build/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 08 D\u00e9cembre 2021</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/","title":"Chapitre 3 : Le d\u00e9ploiement","text":"<p>Maintenant que nous avons r\u00e9ussi \u00e0 builder notre application, comment faire pour d\u00e9ployer tous ses composants (infra., microservices,...) correctement ?</p> <p>Comment faire pour stopper le processus de d\u00e9ploiement applicatif si le d\u00e9ploiement d'un des composants \u00e9choue ?</p> <p>Comment s'assurer de pouvoir faire un rollback de l'application avec seulement les composants impact\u00e9s ?</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#la-conceptualisation-du-processus-de-deploiement","title":"La conceptualisation du processus de d\u00e9ploiement","text":"<p>Pour commencer, il nous faut un r\u00e9f\u00e9rentiel de d\u00e9ploiement. </p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#le-referentiel-de-deploiement","title":"Le r\u00e9f\u00e9rentiel de d\u00e9ploiement","text":"<p>Ce r\u00e9f\u00e9rentiel aura pour but d'identifier chacun des composants \u00e0 d\u00e9ployer de notre application, avec :</p> <ul> <li>le nom du composant (du repository Git)</li> <li>les d\u00e9pendances du composant</li> </ul> <p>exemple</p> <p>Imaginons 2 applications web : WebFront et WebBack. WebFront d\u00e9pend de WebBack. Et tous les deux d\u00e9pendent de l'infra qui va les h\u00e9berger. </p> <p>Voici ce que pourrait donner notre r\u00e9f\u00e9rentiel au format yaml :</p> <pre><code>components:\n- name: webfront\n  dependencies:\n  - webback\n- name: webback\n  dependencies: \n  - infra\n</code></pre> <p>Ce r\u00e9f\u00e9rentiel va \u00e9voluer au fur et \u00e0 mesure des it\u00e9rations pour d\u00e9ployer ou d\u00e9commissionner les composants de l'application. Et donc nous allons mettre notre r\u00e9f\u00e9rentiel de d\u00e9ploiement dans le m\u00eame repository que notre r\u00e9f\u00e9rentiel de build.</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#le-processus-de-deploiement","title":"Le processus de d\u00e9ploiement","text":"<p>Imaginons qu'il y ai une mise \u00e0 jour du r\u00e9f\u00e9rentiel de build. Cela implique qu'il y a eu une mise \u00e0 jour d'un composant. Le processus de build va g\u00e9n\u00e9rer un nouveau manifeste avec l'ensemble des pipelines de CI/CD de chaque composant. A partir de ce manifeste, pour chaque environnement et chaque composant, il faut d\u00e9terminer :</p> <ul> <li>s'il n'est pas n\u00e9cessaire de le d\u00e9ployer (dans le cas d'une librairie par exemple) : il n'y aura donc rien \u00e0 faire,</li> <li>s'il a d\u00e9j\u00e0 \u00e9t\u00e9 d\u00e9ploy\u00e9 : il n'y aura rien \u00e0 faire aussi,</li> <li>s'il y a une mise \u00e0 jour \u00e0 d\u00e9ployer : il faudra d\u00e9clencher le d\u00e9ploiement du composant,</li> <li>s'il y a eu une erreur lors du d\u00e9ploiement d'une d\u00e9pendance : il ne faudra pas lancer le d\u00e9ploiement.</li> </ul> <p>Encore une fois, comme pour le processus de build, c'est comme un arbre o\u00f9 chaque composant correspond \u00e0 un n\u0153ud.</p> <p>exemple</p> <p>Imaginons que durant notre sprint nous ayons fait \u00e9voluer nos composants B, D, G.  Ci-dessous les arbres de d\u00e9pendances correspondants : </p> <p>Lors de l'ex\u00e9cution de notre meta-pipeline pour passer notre application \u00e0 l'\u00e9tat build\u00e9, le manifeste indique que des pipelines CI/CD ont \u00e9t\u00e9 d\u00e9clench\u00e9s pour les composants B, D, G mais aussi pour les composants E, F, I, J et K. Ensuite pour passer notre application \u00e0 l'\u00e9tat d\u00e9ploy\u00e9e sur notre environnement, il faudra :</p> <ul> <li>Ignorer les composants A, B, C, D, E, F, G et H qui n'ont pas besoin d'\u00eatre d\u00e9ploy\u00e9s,</li> <li>Ignorer les composants L et M qui ont \u00e9t\u00e9 d\u00e9j\u00e0 d\u00e9ploy\u00e9s,</li> <li>D\u00e9ployer les composants D, I, K et J.</li> </ul> <p>Si le d\u00e9ploiement du composant K est en \u00e9chec, alors il faudra veiller \u00e0 stopper le processus et ne pas d\u00e9ployer les composants d\u00e9pendants. Le composant J sera donc bloqu\u00e9 par son pr\u00e9d\u00e9cesseur le composant K.</p> <p>Notre d\u00e9ploiement applicatif peut se repr\u00e9senter sous la forme du processus ci-dessous : </p> <p></p> <p>Le processus va parcourir le r\u00e9f\u00e9rentiel de d\u00e9ploiement en commen\u00e7ant par ceux qui n'ont pas de d\u00e9pendance, puis par ceux qui d\u00e9pendent de ces premiers, et ainsi de suite. </p> <p>Note</p> <p>Je vous recommande d'utiliser des processus parall\u00e8les pour parcourir l'arbre.</p> <p>exemple</p> <p>Si on reprend notre exemple ci-dessus, on aura par ordre de passage :</p> <ol> <li>L</li> <li>D, I et K</li> <li>M et J</li> </ol> <p>Pour chaque composant,</p> <ol> <li>on recherche le composant dans le manifeste pour obtenir le pipeline associ\u00e9,</li> <li>on v\u00e9rifie si celui-ci a d\u00e9j\u00e0 \u00e9t\u00e9 correctement d\u00e9ploy\u00e9 (d\u00e9termin\u00e9 par l'\u00e9tat du pipeline).</li> </ol> <p>Note</p> <p>Comme il est possible que le d\u00e9ploiement du composant ne se passe pas correctement, il faut pr\u00e9voir la possibilit\u00e9 de relancer le d\u00e9ploiement en \u00e9chec ult\u00e9rieurement.</p> <ol> <li>si oui, on passe au composant suivant,</li> <li>si non, on d\u00e9clenche le d\u00e9ploiement du composant.</li> <li>on attend la fin du d\u00e9ploiement et on r\u00e9cup\u00e8re le r\u00e9sultat.</li> <li>si le d\u00e9ploiement est OK, on passe au composant suivant.</li> <li>si le d\u00e9ploiement est KO, on stoppe le d\u00e9ploiement des composants d\u00e9pendants.</li> </ol> <p>Une fois le r\u00e9f\u00e9rentiel totalement parcouru, on peut d\u00e9terminer l'\u00e9tat de notre application. Si tous les composants ont \u00e9t\u00e9 correctement d\u00e9ploy\u00e9s, alors on peut consid\u00e9rer que notre application est correctement d\u00e9ploy\u00e9e.</p> <p>Imaginons que nous ayons 3 environnements : DEV, UAT et PROD. Avec ce processus, nous pourrons passer notre application de l'\u00e9tat \"Build\u00e9\" \u00e0 \"D\u00e9ploy\u00e9 en DEV\".</p> <p></p> <p>Et le passage aux \u00e9tats \"D\u00e9ploy\u00e9 en UAT\" et \"D\u00e9ploy\u00e9 en PROD\" suivront le m\u00eame processus.</p> <p></p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#leffet-inattendu","title":"L'effet inattendu","text":"<p>Afin de pouvoir d\u00e9ployer nos composants, nous devons en plus des r\u00e9f\u00e9rentiels de build et de d\u00e9ploiement g\u00e9n\u00e9rer un manifeste afin d'identifier de fa\u00e7on unique les instances de pipeline de chacun des composants.</p> <p>A chaque fois que nous ex\u00e9cutons notre meta-pipeline, nous avons un nouveau manifeste qui est g\u00e9n\u00e9r\u00e9 au passage \u00e0 l'\u00e9tat build\u00e9 de notre application. </p> <p></p> <p>Le manifeste est une image exacte de notre application avec pour chacun des pipelines de CI/CD des composants :</p> <ul> <li>l'artifact contenant le code,</li> <li>la configuration pour chaque environnement.</li> </ul> <p>Coupl\u00e9 \u00e0 nos 2 r\u00e9f\u00e9rentiels qui d\u00e9crivent :</p> <ul> <li>la fa\u00e7on dont on doit builder les composants (r\u00e9f\u00e9rentiel de build),</li> <li>la fa\u00e7on dont on doit d\u00e9ployer tous les composants (r\u00e9f\u00e9rentiel de d\u00e9ploiement),</li> </ul> <p>Cela revient \u00e0 dire que l'on est en capacit\u00e9 de reconstruire notre application from scratch en d\u00e9ployant les composants dans le bon ordre et avec les bons param\u00e8tres d'environnement. Cela va simplifier et s\u00e9curiser grandement les op\u00e9rations de rollback.</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#conclusion","title":"Conclusion","text":"<p>L'utilisation conjointe du manifeste et du r\u00e9f\u00e9rentiel de d\u00e9pendance de d\u00e9ploiement, nous permet d'assurer le d\u00e9ploiment de tous les composants de notre architecture micro-service en limitant les risques d'oublis ou d'\u00e9checs en cascade. </p> <p>De plus, le manifeste g\u00e9n\u00e9r\u00e9 durant la phase de build de notre meta-pipeline nous permet aussi de red\u00e9ployer rapidement notre architecture micro-service \u00e0 l'\u00e9tat exacte d'une version pr\u00e9c\u00e9dente de notre application.</p> <p>Tout \u00e7a est beau mais reste purement th\u00e9orique. Pour prouver la valeur de notre id\u00e9e, je vous pr\u00e9senterais dans la prochaine et derni\u00e8re partie :</p> <ul> <li>notre impl\u00e9mentation,</li> <li>notre exp\u00e9rimentation et </li> <li>nos retours d'exp\u00e9riences. </li> </ul> <p>A suivre...</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/06.comment.deploy/#remerciements","title":"Remerciements","text":"<ul> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 04 Janvier 2022</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/","title":"C'est possible, la preuve !","text":"<p>Durant la premi\u00e8re partie nous avons d\u00e9taill\u00e9 comment nous pouvions atteindre les limites du DevOps et faire partir en vrille notre d\u00e9marche. Ensuite, dans la seconde partie, je vous ai expos\u00e9 une id\u00e9e qui permettrait de passer au-del\u00e0 des limites.  Dans cette troisi\u00e8me partie d'un unique chapitre, je vais vous pr\u00e9senter l'impl\u00e9mentation concr\u00e8te de notre id\u00e9e.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#limplementation","title":"L'impl\u00e9mentation","text":"","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#nos-objectifs-au-travers-de-limplementation-de-notre-idee","title":"Nos objectifs au travers de l'impl\u00e9mentation de notre id\u00e9e","text":"<p>Avant de foncer t\u00eate baiss\u00e9e dans la r\u00e9alisation de notre id\u00e9e, il faut prendre un peu de recul et se poser les bonnes questions. Que doit apporter notre solution ?</p> <p>Notre solution doit permettre \u00e0 l'\u00e9quipe projet de :</p> <ul> <li>conserver un rythme et des c\u00e9r\u00e9monies agiles,</li> <li>simplifier le processus de d\u00e9ploiement,</li> <li>garantir la qualit\u00e9 des composants dans le temps.</li> </ul> <p>Notre solution doit offrir au client la possibilit\u00e9 de :</p> <ul> <li>r\u00e9duire le d\u00e9lai entre l\u2019approbation et le Go Live,</li> <li>intervenir rapidement en cas de panne,</li> <li>garantir la qualit\u00e9 de l'application dans le temps.</li> </ul>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#ce-que-lon-ne-veut-pas","title":"Ce que l'on ne veut pas","text":"<p>Il est \u00e9vident que chaque client, chaque entreprise, chaque projet a sa propre organisation. Notre solution ne doit pas imposer une organisation sp\u00e9cifique. Cela irait \u00e0 l'encontre de l'agilit\u00e9 et de la d\u00e9marche DevOps.</p> <p>Notre solution ne doit pas contraindre :</p> <ul> <li>\u00e0 un Branching Model. Notre solution doit \u00eatre compatible avec les processus Gitflow, GithubFlow, Trunk Based Development ou custom.</li> <li>\u00e0 un processus de mise en production. Chaque entreprise ayant son propre processus de delivery applicatif avec ses environnements propres hors production, notre solution doit s'adapter \u00e0 l'organisation et non l'inverse.</li> <li>\u00e0 un Semantic Versioning. Notre solution doit autoriser n'importe quel type de Semantic Versioning : SemVer1.0, SemVer2.0, ...  </li> <li>\u00e0 un environnement technique. Chaque SI d'entreprise a son propre \u00e9cosyst\u00e8me avec ses OS, ses framewoks, ses solutions d'h\u00e9bergement (Cloud, OnPremise, ...). Notre solution ne doit pas imposer un h\u00e9bergeur cloud par exemple.</li> </ul> <p>Au final, notre solution doit \u00eatre le plus \"agnostique\" possible.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#le-choix-de-la-plateforme-de-production-logicielle","title":"Le choix de la plateforme de production logicielle","text":"<p>Une fois cela dit, notre solution doit quand m\u00eame s'ancrer \u00e0 une solution de production logicielle. Ayant une grande affinit\u00e9 et une bonne connaissance de la stack de Microsoft, mon choix s'est port\u00e9 rapidement sur Azure DevOps Services, l'usine logicielle SaaS de Microsoft.</p> <p>Azure DevOps Services offre l'avantage de pouvoir int\u00e9grer vos propres extensions (ou celles d\u00e9j\u00e0 disponibles sur le Marketplace). Vous pouvez :</p> <ul> <li>r\u00e9aliser vos extensions web pour augmenter les fonctionnalit\u00e9s des interfaces Azure DevOps en react,</li> <li>d\u00e9velopper  en powershell ou en node.js vos extensions de t\u00e2ches pour augmenter les fonctionnalit\u00e9s de vos pipelines de CI/CD,</li> <li>d\u00e9finir vos propres connexions afin de s\u00e9curiser et de simplifier les communications entre Azure DevOps et vos services.  </li> </ul> <p>Dans notre cas, nous avons r\u00e9alis\u00e9 2 extensions :</p> <ul> <li> <p>Une extension Web pour simplifier la mise \u00e0 jour des r\u00e9f\u00e9rentiels de build (cf. Partie 2 - Chapitre 2) et de d\u00e9ploiement (cf. Partie 2 - Chapitre 3) en :</p> <ul> <li>parcourant l\u2019ensemble des repos,</li> <li>identifiant les repos ayant \u00e9volu\u00e9s en un coup d\u2019\u0153il,</li> <li>s\u00e9lectionnant les repos devant int\u00e9gr\u00e9s,</li> <li>d\u00e9finissant la version de chaque composant</li> </ul> </li> <li> <p>Une extension Task pour simplifier l'orchestration des builds et des d\u00e9ploiements dans notre meta-pipeline en :</p> <ul> <li>s\u2019int\u00e9grant dans un pipeline CI/CD Azure DevOps, </li> <li>g\u00e9rant le semantic versioning d\u00e9fini dans notre r\u00e9f\u00e9rentiel de build,</li> <li>prenant en compte le Branching Model du projet,</li> <li>g\u00e9rant les d\u00e9pendances de build,</li> <li>pilotant les approbations manuelles ou automatiques,</li> <li>g\u00e9rant les d\u00e9pendances de d\u00e9ploiement.</li> </ul> </li> </ul>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#lextension-web","title":"L'extension Web","text":"<p>Voici la cin\u00e9matique imagin\u00e9e dans Azure DevOps pour notre utilisateur :</p> <p></p> <p>En arrivant sur l'extension web, 2 onglets lui permettent : </p> <ul> <li>de visualiser l'ensemble des repositories git du projet,</li> <li>d'acc\u00e9der aux param\u00e8tres de la solution.</li> </ul> <p>L'onglet \"param\u00e9trage\" va permettre \u00e0 notre utilisateur de pouvoir configurer la solution afin de r\u00e9pondre aux diff\u00e9rentes organisations projets.</p> <p></p> <ol> <li>S\u00e9lection du repository git contenant les r\u00e9f\u00e9rentiels de build et de d\u00e9ploiement,</li> <li>S\u00e9lection de la branche utilis\u00e9e pour mettre \u00e0 jour les r\u00e9f\u00e9rentiels de build et de d\u00e9ploiement,</li> <li>Chemin complet du fichier yaml contenant le r\u00e9f\u00e9rentiel de build,</li> <li>Chemin complet du fichier yaml contenant le r\u00e9f\u00e9rentiel de d\u00e9ploiement,</li> <li>Nom des branches des composants de l'application depuis lesquelles les pipelines seront d\u00e9clench\u00e9es,</li> <li>Indique s'il faut identifier les commits qui ont \u00e9t\u00e9 cherrypick\u00e9s pour les exclure de la recherche d'\u00e9volution d'un composant (par exemple, dans le cas du Trunk Based Development, les cherrypick sont utilis\u00e9s pour r\u00e9aliser des hotfix),</li> <li>Indique si vous souhaitez cr\u00e9er un tag lorsque vous r\u00e9alisez une mont\u00e9e de version de votre composant. Si oui, vous pourrez personnaliser votre tag, l'instruction \"{v}\" correspondant \u00e0 votre num\u00e9ro de version. Par exemple, si vous d\u00e9finissez \"v{v}\" et que le num\u00e9ro de version est \"1.0.1\" alors votre tag sera \"v1.0.1\".</li> <li>Indique si vous souhaitez cr\u00e9er une branche lorsque vous r\u00e9alisez une mont\u00e9e de version de votre composant. Si oui, vous pourrez personnaliser votre branche. Par exemple, si vous saisissez release/{v}, alors le num\u00e9ro de version sera pr\u00e9fix\u00e9 de \"release/\" dans votre branche.</li> <li>Indique si vous souhaitez r\u00e9aliser un merge sur une branche lorsque vous r\u00e9alisez une mont\u00e9e de version de votre composant. Si oui, indiquer le nom de la branche vers laquelle vous souhaitez r\u00e9aliser votre merge.</li> </ol> <p>Exemple</p> <p>Si l'\u00e9quipe utilise le gitflow, alors il faudra r\u00e9aliser la configuration suivante : <pre><code>Pick commit from : \"main\"\nFind cherrypick : d\u00e9coch\u00e9\nAutomatically create a new tag : coch\u00e9\nAutomatically create a new branch : d\u00e9coch\u00e9\nAutomatically merge with branch : d\u00e9coch\u00e9\n</code></pre></p> <p>L'onglet de visualisation des repositories git permet de visualiser l'ensemble des repos de votre application et d'avoir un aper\u00e7u instantan\u00e9 des composants n\u00e9cessitant une mont\u00e9e de version. </p> <p></p> <p>En fonction du param\u00e9trage, le syst\u00e8me va d\u00e9terminer automatiquement s'il y'a eu des mises \u00e0 jour (des nouveaux commits) sur le repository du composant. </p> <p>L'utilisateur a le dernier mot et peut d\u00e9cider d'embarquer le composant en cochant la case et en saisissant un num\u00e9ro de version.</p> <p>Par d\u00e9faut, l'extension va prendre le dernier commit de la branche, mais il est possible de le s\u00e9lectionner en allant sur le d\u00e9tail des commits.</p> <p></p> <p>Enfin, l'interface de gestion des d\u00e9pendances va permettre de d\u00e9finir les d\u00e9pendances de build et de d\u00e9ploiement.</p> <p></p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#lextension-task","title":"L'extension Task","text":"<p>Pour l'extension Task, il faut que celle-ci soit la plus simple possible pour permettre une int\u00e9gration rapide et facile.</p> <p>Le nombre de param\u00e8tres est donc limit\u00e9 au strict minimum :</p> <ul> <li>un s\u00e9lecteur pour indiquer si l'on souhaite utiliser l'extension pour le build ou pour le d\u00e9ploiement,</li> <li>afin d'\u00e9viter de r\u00e9quisitionner tous les agents de build ou de d\u00e9ploiement disponible, un param\u00e8tre pour indiquer le nombre maximum d'agents \u00e0 utiliser en parall\u00e8le,</li> <li>un param\u00e8tre indiquant l'emplacement du r\u00e9f\u00e9rentiel de build ou de release,</li> <li>un param\u00e8tre indiquant l'emplacement du manifeste de build.</li> </ul> <p>Sample</p> <p>Voici un exemple de notre t\u00e2che de build dans le meta-pipeline : <pre><code>steps:\n  - task: meta-pipeline-build-deploy-task@0\n    displayName: 'Meta-pipeline Task : Build'\n    inputs:\n        EnvironmentStage: Build\n        NbAgents: 3\n        Referential: '$(System.DefaultWorkingDirectory)\\build.yml'\n        BuildManifest: '$(Build.ArtifactStagingDirectory)\\manifest.yml'\n</code></pre></p> <p>Sample</p> <p>Voici un exemple de notre t\u00e2che de d\u00e9ploiement dans le meta-pipeline : <pre><code>steps:\n  - task: meta-pipeline-build-deploy-task@0\n    displayName: 'Meta-pipeline Task : Deploy'\n    inputs:\n        EnvironmentStage: Deploy   \n        NbAgents: 3\n        Referential: '$(System.DefaultWorkingDirectory)\\deploy.yml'  \n        BuildManifest: '$(Build.ArtifactStagingDirectory)\\manifest.yml'\n</code></pre></p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#les-choix","title":"Les choix","text":"<p>Malheureusement, faute de temps et de moyens nous avons d\u00fb d\u00e9prioriser des fonctionnalit\u00e9s et particuli\u00e8rement sur l'extension web.  Par exemple, nous n'avons pour le moment pas impl\u00e9ment\u00e9 l'interface de configuration des d\u00e9pendances. Cependant, cela a un moindre impact pour l'exp\u00e9rimentation. En effet, on modifie rarement les d\u00e9pendances entre les composants. L'\u00e9dition des fichiers Yaml (build et release) permet dans un premier temps de palier \u00e0 ce manque.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#lexperimentation-les-premiers-retours","title":"L'exp\u00e9rimentation / Les premiers retours","text":"<p>Cela fait maintenant 18 mois que notre solution fonctionne pour g\u00e9rer une solution de plus de 40 repository git, autant de pipelines de CI et environ 30 pipelines de CI/CD. Et les retours sont positifs sur plusieurs aspects.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#simplification","title":"Simplification","text":"<p>La simplification r\u00e9side dans l'existence du meta-pipeline. Celui-ci joue le r\u00f4le de chef d'orchestre en s'assurant de builder et de d\u00e9ployer les composants \u00e0 notre place. L'\u00e9quipe et particuli\u00e8rement le tech-lead se retrouve soulag\u00e9s d'avoir un nouveau \"membre\" qui s'occupe de cela \u00e0 sa place. L'\u00e9quipe peut maintenant se consacrer pleinement sur l'impl\u00e9mentation des composants. </p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#rapidite","title":"Rapidit\u00e9","text":"<p>L'orchestration et la parall\u00e8lisation des builds et des d\u00e9ploiements permettent d'optimiser au maximum le processus de CI/CD. D\u00e8s qu'un composant a fini d'\u00eatre build\u00e9 ou d\u00e9ploy\u00e9, notre orchestrateur passe automatiquement au composant suivant. L'\u00e9quipe n'a plus besoin de surveiller les notifications pour d\u00e9clencher le d\u00e9ploiement du composant suivant.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#fiabilite","title":"Fiabilit\u00e9","text":"<p>L'utilisation de r\u00e9f\u00e9rentiel de build et de d\u00e9ploiement permet de syst\u00e9matiser l'orchestration. Notre \"chef d'orchestre\" joue la partition \u00e0 la lettre ! De plus l'automatisation r\u00e9duit les op\u00e9rations manuelles et donc les risques d'erreurs ou d'oublis.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#tracabilite","title":"Tra\u00e7abilit\u00e9","text":"<p>Les commits r\u00e9alis\u00e9s \u00e0 chaque modification de r\u00e9f\u00e9rentiel, les logs du meta-pipeline et la g\u00e9n\u00e9ration du manifeste sont autant d'\u00e9l\u00e9ments qui permettent d'avoir une tra\u00e7abilit\u00e9 :</p> <ul> <li>sur l'ensemble des mises \u00e0 jour des composants et de leurs d\u00e9pendances \u00e0 partir des commits r\u00e9alis\u00e9s sur le repository git,</li> <li>sur ce qui s'est r\u00e9ellement pass\u00e9 au moment de l'ex\u00e9cution de notre meta-pipeline (quel composant a \u00e9chou\u00e9 et \u00e0 quel moment ?) \u00e0 partir des logs,</li> <li>sur l'ensemble des versions de chaque composant \u00e0 chaque ex\u00e9cution du meta-pipeline \u00e0 partir du manifeste.</li> </ul>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#reproductivite","title":"Reproductivit\u00e9","text":"<p>Grace au manifeste, il est possible de red\u00e9ployer \u00e0 moindre effort tous les composants de l'application m\u00eame \u00e0 son \u00e9tat ant\u00e9rieur (plusieurs sprints auparavant).</p> <p>Warning</p> <p>Cela ne veut pas dire que la solution vous permet de g\u00e9rer tout le rollback de votre application, et notamment de vos donn\u00e9es. Mais si vous faites attention \u00e0 prendre en compte l'\u00e9volutivit\u00e9 de vos mod\u00e8les de donn\u00e9es dans la conception de vos composants avec ou sans outils (entity framework, liquibase, ...) vous ne devriez pas avoir trop de probl\u00e8mes au moment du rollback.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#conclusion","title":"Conclusion","text":"<p>Pour le moment, la solution que nous avons mise en place est encore \"verte\". Certes, nous l'avons \u00e9prouv\u00e9e longuement aupr\u00e8s d'un client et de nombreuses fois sur des Proof of Concept, mais de mon point de vue elle n\u00e9cessite encore un certain nombre d'ajustements et d'am\u00e9liorations pour \u00eatre mise \u00e0 la disposition de tous. Si vous souhaitez participer, contribuer ou r\u00e9agir, je vous invite \u00e0 me contacter en priv\u00e9 via LinkedIn. Je serai ravi d'\u00e9changer avec vous. </p> <p>Je pense avoir tout dit sur le sujet durant les 7 articles qui composent cette s\u00e9rie. Ce qu'il faut surtout retenir c'est qu'il est possible en toute circonstance d'appliquer une d\u00e9marche DevOps, que ce soit pour une toute petite application monolithique ou une \u00e9norme application distribu\u00e9e.</p> <p>La d\u00e9marche DevOps ne s'arr\u00eate pas \u00e0 la mise en place de pipeline CI/CD. C'est une d\u00e9marche qui impactera forc\u00e9ment votre organisation : les d\u00e9veloppeurs, les architectes, les int\u00e9grateurs, les testeurs, les exploitants, mais aussi les repr\u00e9sentants m\u00e9tiers (Product Owner, Business Analyst). Et pour ces derniers le couple Agilit\u00e9 + DevOps prend tout son sens.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/devops/vrille/07.lapreuve/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> <li>Nicolas Giraud : pour l'id\u00e9e de la machine \u00e0 \u00e9tat</li> <li>Fabrice Weinling : pour la relecture</li> <li>Etienne Louise : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 08 F\u00e9vrier 2022</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"articles/exceptions/","title":"Azure, Les exceptions qui font mal !","text":"<p>Voici le premier volet d'une s\u00e9rie d'articles bas\u00e9 sur des retours d'exp\u00e9riences malheureux avec Azure. Il ne faut pas y voir une critique de la plateforme cloud, mais plut\u00f4t comprendre cette s\u00e9rie comme une occasion manqu\u00e9e et une possibilit\u00e9 pour Microsoft d'am\u00e9liorer encore son cloud Azure. Rien n'est parfait ! J'esp\u00e8re que cette s\u00e9rie vous permettra d'\u00e9viter les pi\u00e8ges dans lesquels nous sommes tomb\u00e9s, moi et mon \u00e9quipe.</p> <ul> <li>Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet</li> <li>Chapitre 2 : Azure Container Instance et Windows dans votre Vnet</li> <li>Chapitre 3 : Les firewall et les r\u00e9gions Azure</li> </ul>"},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/","title":"Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet","text":"","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#larchitecture","title":"L'architecture","text":"<p>Parlons un peu de l'architecture que nous avions envisag\u00e9 de r\u00e9aliser. L'objectif est d'instancier des conteneurs via des Azure Container Instance \u00e0 partir d'image d\u00e9ploy\u00e9 dans un Azure Container Registry. Tout cela doit \u00eatre s\u00e9curis\u00e9 au niveau reseau dans un Virtual Network.</p> <p>D'un cot\u00e9 le service Azure Container Registry permet d'utiliser les Private Endpoint pour restreindre l'acc\u00e8s de son service de registre de conteneur \u00e0 un r\u00e9seau priv\u00e9. De l'autre, les Azure Container Instance peuvent \u00eatre d\u00e9ploy\u00e9s dans un r\u00e9seau priv\u00e9 virtuel. Donc, sur le papier le sch\u00e9ma d'architecture ci-dessous fonctionne... Ce n'est pas le cas.</p> <p></p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#lexception","title":"L'exception","text":"<p>Apr\u00e8s quelques tests infructueux, nous avons fait une petite recherche et d\u00e9couvert rapidement que l'utilisation d'un Private Endpoint pour un Azure Container Registry comportait quelques exceptions et notamment celle-ci : </p> <p>Extrait docs.microsoft.com</p> <p>Les instances de services Azure, notamment Azure DevOps Services, Web Apps et Azure Container Instances, ne peuvent pas non plus acc\u00e9der \u00e0 un registre de conteneurs dont l\u2019acc\u00e8s r\u00e9seau est restreint.</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#contournement","title":"Contournement","text":"<p>Les 2 services Microsoft ne pouvant \u00eatre utilis\u00e9s conjointement dans un r\u00e9seau priv\u00e9, 3 solutions s'offrent \u00e0 nous :</p> <ol> <li>Ne plus restreindre l'acc\u00e8s r\u00e9seau de notre Azure Container Registry.</li> </ol> <p></p> <ol> <li>Remplacer notre Azure Container Registry par une solution Container Registry Self Hosted </li> </ol> <p></p> <ol> <li>Remplacer nos Azure Container Instance par un cluster Azure Kubernetes Services par exemple.</li> </ol> <p></p> <p>Et il ne faut pas compter sur l'utilisation d'un Service Endpoint (en preview) puisque celui-ci ne permet pas non plus de r\u00e9cup\u00e9rer l'image depuis un Azure Container Instance.</p> <p>Extrait de docs.microsoft.com</p> <p>Les instances de services Azure, notamment Azure DevOps Services, Web Apps et Azure Container Instances, ne peuvent pas non plus acc\u00e9der \u00e0 un registre de conteneurs dont l\u2019acc\u00e8s r\u00e9seau est restreint.</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#conclusion","title":"Conclusion","text":"<p>Il n'y a pour le moment pas de contournement id\u00e9al.  Cependant, bien que la documentation Microsoft indique le contraire, il semblerait qu'il soit possible de tirer (pull) une image Linux via une Azure Web App depuis un Azure Container Registry en ajoutant dans les appsettings :</p> <p>WEBSITE_PULL_IMAGE_OVER_VNET=true</p> <p>C'est un d\u00e9but.</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#dans-la-serie","title":"Dans la s\u00e9rie","text":"<ul> <li>Chapitre 2 : Azure Container Instance et Windows dans votre Vnet</li> <li>Chapitre 3 : Les firewall et les r\u00e9gions Azure</li> </ul>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>D\u00e9ployer des instance de conteneur dans un r\u00e9seau virtuel Azure</li> <li>Connexion priv\u00e9e \u00e0 un registre de conteneurs Azure \u00e0 l\u2019aide d\u2019Azure Private Link</li> <li>Restreindre l\u2019acc\u00e8s \u00e0 un registre de conteneurs \u00e0 l\u2019aide d\u2019un point de terminaison de service dans un r\u00e9seau virtuel Azure</li> <li>Deploying Linux custom container from private Azure Container Registry</li> <li>ACR with private endpoint - Web Apps</li> </ul>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/01.azureException.acrAndAciInYourVnet/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>David Dubourg : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 06 Septembre 2021</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/","title":"Chapite 2 : Azure Container Instance et Windows dans votre Vnet","text":"","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#le-scenario","title":"Le sc\u00e9nario","text":"<p>Vous souhaitez proposer des services ayant une dur\u00e9e de vie limit\u00e9, executable sous Linux ou Windows et isol\u00e9 dans votre Virtual Network. Par exemple : Des runners self-hosted pour github.</p> <p>On imagine donc une architecture avec des Azure Container Instance du style :   </p> <p></p> <p>Cela fonctionne pour nos conteneurs Linux mais pas pour nos conteneurs Windows... </p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#lexception","title":"L'exception","text":"<p>Apr\u00e8s quelques tests infructueux, nous avons fait une petite recherche et d\u00e9couvert rapidement que l'utilisation d'Azure Container Instance dans un Virtual Network comportait quelques exceptions et notamment celle-ci : </p> <p>Extrait docs.microsoft.com</p> <p>Actuellement, seuls les conteneurs Linux sont pris en charge dans un groupe de conteneurs d\u00e9ploy\u00e9 sur un r\u00e9seau virtuel.</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#contournement","title":"Contournement","text":"<p>Les Azure Container Instance ne permettant pas d'int\u00e9grer des conteneurs Windows dans votre Vnet, il ne nous reste que peu d'options :</p> <ol> <li>Microsoft avait annonc\u00e9 fin 2020 que cette fonctionnalit\u00e9 serait disponible d\u00e9but 2021. Si l'on admet un retard pris, on peut esp\u00e9rer que cette fonctionnalit\u00e9 sera bient\u00f4t disponible. Donc, la premi\u00e8re option est d'attendre.</li> <li>La seconde option, consiste \u00e0 remplacer notre Azure Container Instance par Azure Batch avec un pool Windows.</li> </ol> <p></p> <p>Vous pouvez aussi utiliser un AKS ou un VM Scale Set, mais de mon point de vue, c'est un peu \"overkill\".  </p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#conclusion","title":"Conclusion","text":"<p>Si vous \u00eates vraiment press\u00e9 par le temps ou vous doutez que Microsoft propose l'integration Vnet des Azure Container Instance Windows rapidement, je serais tent\u00e9 de vous orienter vers Azure Batch. Un service manag\u00e9 d'Azure pas assez mis en valeur \u00e0 mon go\u00fbt !</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#dans-la-serie","title":"Dans la s\u00e9rie","text":"<ul> <li>Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet</li> <li>Chapitre 3 : Les firewall et les r\u00e9gions Azure</li> </ul>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Ressources et sc\u00e9narios relatifs aux r\u00e9seaux virtuels</li> <li>Azure Container Instances (ACI) under the hood - Azure Friday</li> <li>Ex\u00e9cuter des applications de conteneur sur Azure Batch</li> <li>Utiliser des conteneurs Windows Server</li> </ul>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/02.azureException.aciWindowsWithVnet/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Etienne Louise : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 20 Septembre 2021</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/","title":"Chapitre 3 : Les firewall et les r\u00e9gions Azure","text":"","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#le-scenario","title":"Le sc\u00e9nario","text":"<p>Vous souhaitez connecter un service PaaS ou SaaS Azure avec un Storage Account. M\u00eame si votre service est accessible publiquement (pas d'isolation r\u00e9seau), vous ne souhaitez pas exposer publiquement votre Storage Account. Vous savez que Microsoft vous permet de limiter l'exposition r\u00e9seau via les r\u00e8gles firewall de votre Storage Account. Vous whitlistez donc les IP de votre service. </p> <p>Sur le papier cela fonctionne parfaitement. Dans la r\u00e9alit\u00e9, ce n'est pas le cas...</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#lexception","title":"L'exception","text":"<p>Ce ph\u00e9nom\u00e8ne, j'ai pu l'observer. Il y a certainement d'autres cas similaires avec d'autres services Azure. Je vais vous pr\u00e9senter les 2 cas que j'ai pu rencontrer.</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#logicapp-et-storage-account","title":"LogicApp et Storage Account","text":"<p>Nous souhaitions d\u00e9clencher un workflow lorsqu'un nouveau fichier est d\u00e9pos\u00e9 dans un container blob de notre Storage Account. Nous d\u00e9cidons d'utiliser le service Logic Apps pour notre workflow. Nous ne voulions pas investir dans un Integration Service Environment (environ 720 \u20ac / mois) ou dans un Workflow Standard WS1 (environ 150 \u20ac / mois) afin d'isoler notre workflow.</p> <p>Mais afin de ne pas exposer notre Storage Account publiquement, nous souhaitions mettre une r\u00e8gle firewall sur celui-ci afin de n'autoriser que le service Logic Apps. </p> <p>Note</p> <p>Microsoft fournit la liste des IP sortantes des connecteurs Logic Apps : ici</p> <p>Naturellement, nous avions mis nos 2 services dans la m\u00eame r\u00e9gion Azure.</p> <p></p> <p>Erreur fatale ! Lorsque les 2 ressources Azure sont sur la m\u00eame r\u00e9gion, Microsoft va tr\u00e8s r\u00e9guli\u00e8rement (pas toujours !) privil\u00e9gier son r\u00e9seau interne pour router la communication. Ainsi notre Logic Apps va contacter notre Storage Account avec une adresse IP priv\u00e9e. </p> <p>\"Ce n'est pas grave \u00e7a ! Il suffit juste de whitelister les adresses IP priv\u00e9es !\" </p> <p>Eh bien non ! Vous ne pouvez pas mettre de r\u00e8gles firewall sur des plages IP priv\u00e9es. </p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#azure-devops-services-et-storage-account","title":"Azure DevOps Services et Storage Account","text":"<p>Nous souhaitions notifier un \u00e9v\u00e8nement depuis une extension Azure DevOps Services Agentless vers une queue de notre Storage Account. Encore une fois, afin de ne pas exposer notre Storage Account publiquement, nous voulions mettre une r\u00e8gle firewall sur celui-ci afin de n'autoriser que le service Azure DevOps Services.</p> <p>Note</p> <p>Microsoft fournit la liste des IP sortantes de Azure DevOps Services : ici</p> <p>Encore une fois, nous avons mis nos 2 services dans la m\u00eame r\u00e9gion Azure.</p> <p></p> <p>Je vous le donne en mille, Emile ! Lorsque nos 2 services Azure sont sur la m\u00eame r\u00e9gion, Microsoft va tr\u00e8s r\u00e9guli\u00e8rement privil\u00e9gier son r\u00e9seau interne pour router la communication. Ainsi notre Azure DevOps Services va contacter notre Storage Account avec une adresse IP priv\u00e9e. </p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#contournement","title":"Contournement","text":"<p>On pourrait penser que le probl\u00e8me vient uniquement de notre Storage Account qui ne permet pas d'identifier l'origine du service appelant. On pourrait se dire qu'avec l'utilisation de Service Tag on pourrait r\u00e9soudre notre probl\u00e8me. Malheureusement, non ! </p> <p>Les Service Tag permettent de simplifier la gestion des IP publiques des services Azure. En ajoutant un Service Tag \u00e0 notre firewall on va whitlister uniquement les IP publiques de celui-ci.</p> <p>Finalement, la seule solution de contournement simple est de changer la r\u00e9gion d'un des 2 services.</p> <p></p> <p>En utlisant 2 r\u00e9gions, on force nos services \u00e0 utiliser les IP publiques. les r\u00e8gles firewall peuvent donc \u00eatre appliqu\u00e9es.</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#conclusion","title":"Conclusion","text":"<p>J'avoue qu'utiliser plusieurs r\u00e9gions Azure pour \u00e9viter une exposition r\u00e9seau trop large d'un service est un peu affligeant.  Dans le cas des Logic Apps, si l'on a un petit peu de budget, je vous conseillerais d'utiliser un Workflow Standard WS1 afin d'isoler d'un point de vue r\u00e9seau notre service. Dans le cas d'Azure DevOps Services, \u00e9tant pour le moment uniquement publique, vous n'aurez pas beaucoup d'autres solutions.</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#dans-la-serie","title":"Dans la s\u00e9rie","text":"<ul> <li>Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet</li> <li>Chapitre 2 : Azure Container Instance et Windows dans votre Vnet</li> </ul>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Managed connectors outbound IP addresses</li> <li>Azure DevOps Services - Adresses IP et URL de domaine autoris\u00e9es</li> <li>Azure IP Ranges and Service Tags \u2013 Public Cloud</li> </ul>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/exceptions/03.azureException.firewallAndRegion/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>David Dubourg : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 17 Octobre 2021</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"articles/tips/01.finops.ftpslowcost/","title":"L'astuce FinOps : Un serveur FTPS Low Cost","text":"<p>Il arrive encore que des clients souhaitent utiliser le protocole FTP(S) pour transmettre des fichiers sur Azure. Vous aurez beau chercher sur le marketplace Azure, Microsoft ne propose pas nativement ce service en manag\u00e9. Il vous reste donc 2 options :</p> <ol> <li>Se cr\u00e9er son propre serveur FTP \u00e0 partir d'une VM ou d'une ACI (\u00e0 tester).</li> <li>Passer par un tiers qui vous mettra \u00e0 disposition ce service.</li> </ol> <p>Cela n\u00e9cessitera dans tous les cas un co\u00fbt non n\u00e9gligeable pour un service tr\u00e8s basique. N'y a-t-il pas une autre solution ?</p> <p>J'ai une solution !</p> <p>Je vais certainement faire hurler tous les puristes, mais il s'av\u00e8re que cette solution \u00e0 fait ses preuves et fonctionne parfaitement chez les clients depuis plus de 2 ans. Il suffit d'utiliser 2 services manag\u00e9s Azure : Une FunctionApp + Un StorageAccount.</p> <p></p>","tags":["Azure","ftps","finops"]},{"location":"articles/tips/01.finops.ftpslowcost/#une-solution-une-functionapp-en-tant-que-serveur-ftps","title":"Une solution : Une FunctionApp en tant que serveur FTP(S).","text":"<p>Pour d\u00e9ployer votre code source sur vos FunctionApp, vous avez plusieurs possibilit\u00e9s. L'un d'elle utilise un service FTP(S). L'id\u00e9e est donc de r\u00e9utiliser ce service de la FunctionApp pour en faire la fonctionnalit\u00e9 principale.</p> <p>Pour cela rien de plus simple, il faut :</p> <ol> <li>Cr\u00e9er une FunctionApp avec un service plan \"Free\" (Sku : Y1),</li> <li>Cr\u00e9er un StorageAccount (si vous n'en avez pas d\u00e9j\u00e0) qui sera votre espace de stockage,</li> <li>Configurer votre FunctionApp pour utiliser le StorageAccount. Il faut ajouter les param\u00e8tres suivant dans la section Application Settings :</li> </ol> <p><pre><code>  {\n    \"name\": \"AzureWebJobsDashboard\",\n    \"value\": \"[Endpoint StorageAccount]\",\n    \"slotSetting\": false\n  },\n  {\n    \"name\": \"AzureWebJobsStorage\",\n    \"value\": \"[Endpoint StorageAccount]\",\n    \"slotSetting\": false\n  },\n  {\n    \"name\": \"WEBSITE_CONTENTAZUREFILECONNECTIONSTRING\",\n    \"value\": \"[Endpoint StorageAccount]\",\n    \"slotSetting\": false\n  },\n  {\n    \"name\": \"WEBSITE_CONTENTSHARE\",\n    \"value\": \"MyFtpsLowCost\",\n    \"slotSetting\": false\n  },\n</code></pre> 4. R\u00e9cup\u00e9rer les param\u00e8tres de connexions \u00e0 votre FTP(s) en t\u00e9l\u00e9chargeant le profil de publication. </p> <p>Enfin, il faudra activer les \u00e9l\u00e9ments de s\u00e9curit\u00e9 (\u00e7a reste un pr\u00e9conisation) en :</p> <ul> <li>Autorisant uniquement le FTPS.</li> <li>Activant la restriction d'IP et de Vnet.</li> </ul>","tags":["Azure","ftps","finops"]},{"location":"articles/tips/01.finops.ftpslowcost/#conclusion","title":"Conclusion","text":"<p>Certe cette solution ne permet pas de g\u00e9rer plusieurs compte d'acc\u00e8s. Si vous avez plusieurs partenaires souhaitant utiliser un service FTP pour consommer ou transmettre des fichiers, vous devrez multiplier les FunctionApp.</p> <p>Mais ce qu'il faut retenir, c'est que :</p> <ul> <li>d'une part, ce service ne vous coutera rien ou presque rien (juste les co\u00fbts du StorageAccount).</li> <li>d'autre part, ce sera l'occasion d'inciter vos partenaires \u00e0 changer de m\u00e9thode pour consommer ou pousser des fichiers (API Rest,...).</li> </ul> <p>Note</p> <p>Dans mon exemple j'utilise une FunctionApp mais cela fonctionne tout aussi bien avec un WebApp.</p>","tags":["Azure","ftps","finops"]},{"location":"articles/tips/01.finops.ftpslowcost/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Azure Function Deploiement</li> </ul>","tags":["Azure","ftps","finops"]},{"location":"articles/tips/01.finops.ftpslowcost/#remerciements","title":"Remerciements","text":"<ul> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 04 Novembre 2020</p>","tags":["Azure","ftps","finops"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/","title":"CosmosDB : En attendant le partial update","text":"<p>Cela fait maintenant : </p> <ul> <li>6 ans que cette id\u00e9e a \u00e9t\u00e9 remont\u00e9 \u00e0 Microsoft, </li> <li>2 ans et demi que le sujet est dans la roadmap de Microsoft, </li> <li>1 ans et demi que celui-ci est commenc\u00e9 et... </li> </ul> <p>toujours rien.</p> <p>Pourtant, cette fonctionnalit\u00e9 pourrait tout changer ! J'ai eu l'occasion de rencontrer des clients qui pour cette unique raison pr\u00e9f\u00e9raient partir sur MongoDB Atlas.</p> <p>Mais pourquoi cette fonctionnalit\u00e9 change tout ?</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#constat-atomicite-des-mises-a-jour-documentdb","title":"Constat : Atomicit\u00e9 des mises \u00e0 jour DocumentDB","text":"<p>Via le m\u00e9canisme de contr\u00f4le d\u2019acc\u00e8s concurrentiel optimiste (etag - Transactions optimistic concurrency) de l'api SQL, Microsoft garanti que les transactions envoy\u00e9es vers un Conteneur CosmosDB sont ACID. Mais \u00e0 y regarder de plus pr\u00e8s on constate que le classique \"UPDATE\" SQL n'est pas dans la liste des op\u00e9rations pris en charge. Mais comment faire une mise \u00e0 jour alors ?</p> <p>Aujourd'hui, pour faire une mise \u00e0 jour dans un conteneur CosmosDB, il faut :</p> <ol> <li>r\u00e9cup\u00e9rer le document, </li> <li>le mettre \u00e0 jour (merge entre la donn\u00e9e re\u00e7u et celle exitant dans CosmosDB) et </li> <li>l'enregistrer dans le conteneur.</li> </ol> <p></p> <p>Mais lorsque plusieurs composants sont suceptibles de r\u00e9aliser cette mise \u00e0 jour ou que vous utilisez des m\u00e9canismes de scalabilit\u00e9s horizontal, il y'a un risque d'\u00e9crasement de la donn\u00e9e (et donc de perte de donn\u00e9e).</p> <p>En effet, prenons 2 composants A et B r\u00e9alisant une mise \u00e0 jour au m\u00eame moment sur la m\u00eame donn\u00e9e.</p> <ul> <li>L'identifiant est li\u00e9 \u00e0 la prori\u00e9t\u00e9 \"id\" (je mets de cot\u00e9 volontairement la notion de cl\u00e9 de partition),</li> <li>Le composant A met \u00e0 jour la date de naissance ainsi que l'adresse email,</li> <li>Le composant B met \u00e0 jour la date de naissance et le num\u00e9ro de t\u00e9l\u00e9phone. </li> </ul> Data Composant A Data Composant B Data CosmosDB {\u00a0\u00a0\"id\": \"99039816\",\u00a0\u00a0,\"birthdate\": \"1984-06-16T00:00:00Z\", \"email\": \"joe.doe@yopmail.com\"} {\u00a0\u00a0\"id\": \"99039816\",\u00a0\u00a0\"birthdate\": \"1984-07-16T00:00:00Z\", \"phone\": \"+33.8.76.54.32.10\"} {\u00a0\u00a0\"id\": \"99039816\",\u00a0\u00a0\"firstname\": \"joe\",\u00a0\u00a0\"lastname\": \"doe\",\u00a0\u00a0\"birthdate\": \"1984-05-16T00:00:00Z\",} <p>Dans un traitement classique suite \u00e0 la mise \u00e0 jour de la donn\u00e9e par les 2 composants nous devrions avoir :</p> <ul> <li>Si le composant A est pass\u00e9 avant le composant B : <pre><code>{\n    \"id\": \"99039816\",\n    \"firstname\": \"joe\",\n    \"lastname\": \"doe\",\n    \"birthdate\": \"1984-07-16T00:00:00Z\",\n    \"email\": \"joe.doe@yopmail.com\",\n    \"phone\": \"+33.8.76.54.32.10\"\n}\n</code></pre></li> <li>Si le composant B est pass\u00e9 avant le composant A : <pre><code>{\n    \"id\": \"99039816\",\n    \"firstname\": \"joe\",\n    \"lastname\": \"doe\",\n    \"birthdate\": \"1984-06-16T00:00:00Z\",\n    \"email\": \"joe.doe@yopmail.com\",\n    \"phone\": \"+33.8.76.54.32.10\"\n}\n</code></pre></li> </ul> <p>Imaginons maintenant le s\u00e9quencement suivant :</p> <ol> <li>Composant A : Fetch Data</li> <li>Composant B : Fetch Data</li> <li>Composant A : Merge data</li> <li>Composant A : Upsert data</li> <li>Composant B : Merge data</li> <li>Composant B : Upsert data</li> </ol> <p>Suite \u00e0 la mise \u00e0 jour de la donn\u00e9e par les 2 composants nous aurons dans CosmosDB : <pre><code>{\n    \"id\": \"99039816\",\n    \"firstname\": \"joe\",\n    \"lastname\": \"doe\",\n    \"birthdate\": \"1984-07-16T00:00:00Z\",\n    \"phone\": \"+33.8.76.54.32.10\"\n}\n</code></pre> L'information adresse email est PERDU ! </p> <p>Le probl\u00e8me, c'est que le composant A ne sait pas que le composant B r\u00e9alise une op\u00e9ration de mise \u00e0 jour au m\u00eame moment. Et chaque composant fait sa mise \u00e0 jour de son cot\u00e9 croyant qu'il est seul au monde !</p> <p>Mais comment r\u00e9soudre ce probl\u00e8me ?</p> <p>Il s'agit d'un probl\u00e8me d'atomicit\u00e9. Il va falloir s'assurer que les op\u00e9rations de r\u00e9cup\u00e9ration, de fusion et d'enregistrement soient r\u00e9alis\u00e9e de mani\u00e8re atomique. </p> <p>Je reprend mes vieux cours d'informatique et la solution est \"le verrou\".</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#une-solution-cosmosdb-redis","title":"Une solution : CosmosDB + Redis","text":"<p>Dans le cloud Azure, le service \"cache redis\" est bien pratique. Il ne sert pas qu'\u00e0 faire du cache ! Il peut aussi g\u00e9rer notre verrou.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#le-principe","title":"Le principe","text":"<p>Chaque composant voulant r\u00e9aliser une op\u00e9ration de mise \u00e0 jour doit syst\u00e9matiquement poser un verrou dans Redis avant de r\u00e9aliser la mise \u00e0 jour (fetch-merge-upsert). Si le cache contient d\u00e9j\u00e0 ce verrou, alors le composant sait qu'un autre composant est en train de r\u00e9aliser une op\u00e9ration de mise \u00e0 jour. Ainsi, grace au verrou l'atomicit\u00e9 de l'operation de mise \u00e0 jour est pr\u00e9serv\u00e9e. Il faudra bien entendu penser \u00e0 lib\u00e9rer le verrou une fois l'op\u00e9ration termin\u00e9e.</p> <p></p> <p>Il ne reste plus qu'\u00e0 l'encapsuler dans une petite couche technique (DAL) afin d'abstraire tout cela du traitement m\u00e9tier.</p> <p>Note</p> <p>Pour le verrou, il faut utiliser l'identifiant (la cl\u00e9 primaire) de la donn\u00e9e en tant que cl\u00e9. Par exemple pour notre exemple ci-dessus, on utilisera \"99039816\" comme cl\u00e9. </p> <p>Parfait !</p> <p>Mais que se passe-t-il s'il y a un verrou de pos\u00e9 ? </p> <p>On attends !</p> <p>Oui, mais imaginons que l'on ai une vague de mise \u00e0 jour sur la m\u00eame donn\u00e9e (c'est un cas extr\u00e8me), ou que le cache redis ou que le comosdb ne r\u00e9ponde pas ? Mon composant ne va pas attendre \u00e9ternellement ! </p> <p>C'est vrai. Pour cela, je conseille d'utiliser une file d'attente.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#larchitecture","title":"L'architecture","text":"<p>L'id\u00e9e est de d\u00e9couper le traitement de mise \u00e0 jour en 2. Le premier composant (Business) va pousser sa demande mise \u00e0 jour dans une file d'attente. Le second composant (DAL) va lui traiter cette file d'attente et r\u00e9aliser les mises \u00e0 jour. En cas d'impossibilit\u00e9 de r\u00e9aliser une mise \u00e0 jour par le second composant, celui-ci va remettre la demande en file d'attente (celle-ci sera trait\u00e9 ult\u00e9rieurement)  </p> <p> <pre><code>1 - Demande de mise \u00e0 jour\n2 - Mise en file d'attente de la mise \u00e0 jour par le composant m\u00e9tier\n3 - Consommation de la file d'attente par le composant DAL\n4 - V\u00e9rification du verrou\n5 - Upsert de la donn\u00e9e\n5'- Remise en file d'attente en cas d'\u00e9chec. \n</code></pre></p> <p>Note</p> <p>Je pr\u00e9conise de tenter 5 \u00e0 10 fois la mise \u00e0 jour par le composant avant de remettre la demande  en file d'attente.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#cas-au-limite","title":"Cas au limite","text":"<p>C'est bien cette histoire de file d'attente, mais du coup, j'ai un risque que les op\u00e9rations de mise \u00e0 jour soient r\u00e9alis\u00e9es dans le d\u00e9sordre.</p> <p>C'est vrai.</p> <p>Pour cela, on peut se baser sur le timestamp de la donn\u00e9e (il faudra alors stocker cette information en plus dans CosmosDB). Ainsi, si la mise \u00e0 jour \u00e0 traiter est ant\u00e9rieur \u00e0 la derni\u00e8re mise \u00e0 jour dans CosmosDB, l'op\u00e9ration peut-\u00eatre abandonn\u00e9e.</p> <p>Cela reste imparfait...</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#conclusion","title":"Conclusion","text":"<p>Il faut se doter de plusieurs ressources azure et r\u00e9aliser un peu de d\u00e9veloppement pour obtenir une solution capable de g\u00e9rer presque proprement les mises \u00e0 jour dans CosmosDB.</p> <p>Il existe d'autres solutions :</p> <ul> <li>Une qui pourrait sembler \u00eatre plus \"sexy\" serait d'utiliser les proc\u00e9dures stock\u00e9es JS de CosmosDB. En effet, les ProcStock permettent de garantir l'atomicit\u00e9 de l'op\u00e9ration. Mais \u00e0 mon avis, si vous devez g\u00e9rer des donn\u00e9es complexe dans votre conteneur CosmosDB, vous allez gal\u00e9rer \u00e0 impl\u00e9menter et maintenir celles-ci.</li> <li>Une autre, consiste \u00e0 utiliser les Azure Function Durable Entities. Mais je n'ai pas encore eu l'occassion de tester. </li> </ul> <p>Le partial update permettrait de se d\u00e9faire de cette probl\u00e8matique en n'envoyant dans CosmosDB que les propri\u00e9t\u00e9s \u00e0 mettre \u00e0 jour. Le CosmosDB ce chargeant de r\u00e9aliser les op\u00e9rations de fetch-merge-upsert lui m\u00eame. Cela simplifierait beaucoup de chose.</p> <p>Vivement le Partial Update !</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Feedback Azure</li> <li>Wikip\u00e9dia</li> <li>CosmosDB - Stored Procedures</li> <li>CosmosDB - Transactions optimistic concurrency</li> <li>Azure Function Durable Entities</li> </ul>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/02.cosmosdb.waiting_partialupdate/#remerciements","title":"Remerciements","text":"<ul> <li>Quentin Joseph : pour la relecture</li> <li>Benjamin Dufour : pour les  Azure Function Durable Entities ;-)</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 20 Novembre 2020</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/03.cosmosdb.calculatedPartitionKey/","title":"CosmosDB : Une cl\u00e9 de partition calcul\u00e9e !","text":"<p>Dans CosmosDB, la notion de cl\u00e9 de partition est essentielle. En effet, contraitement \u00e0 d'autres syst\u00e8mes de stockage de donn\u00e9es classique (SQL par exemple), l'unicit\u00e9 d'une donn\u00e9e est bas\u00e9e sur le couple identifiant - cl\u00e9 de partition.</p> <p>Les conteneurs CosmosDB sont d\u00e9coup\u00e9s en partitions logiques. Chaque partition logique g\u00e8re ind\u00e9pendamment l'unicit\u00e9 de ses \u00e9l\u00e9ments en se basant sur l'identifiant id. </p> <p></p> <p>C'est un peu comme un dossier qui s'assure qu'\u00e0 l'int\u00e9rieur de lui, il n'y a pas 2 fois le m\u00eame nom de fichier.  Donc, dans un m\u00eame conteneur vous pouvez tr\u00e8s bien avoir le m\u00eame identifiant dans 2 partitions logiques diff\u00e9rentes.</p> <p>La cl\u00e9 de partition peut-\u00eatre d\u00e9finie \u00e0 partir de n'importe quelle propri\u00e9t\u00e9 de la donn\u00e9e. Mais il y a quelques contraintes \u00e0 respecter :</p> <ul> <li>Cette propri\u00e9t\u00e9 doit \u00eatre obligatoirement valu\u00e9e (tout comme l'identifiant).</li> <li>Cette propri\u00e9t\u00e9 doit \u00eatre immuable (tout comme l'identifiant).</li> <li>Le stockage sur une cl\u00e9 est limit\u00e9 \u00e0 20 Go. </li> <li>Le nombre de valeur possible de cette propri\u00e9t\u00e9 doit \u00eatre proportionnel au nombre d'\u00e9l\u00e9ments stock\u00e9s dans le conteneur (je conseille un rapport compris entre 1/1 000 et 1/10 000).</li> <li>La r\u00e9partition du stockage doit \u00eatre uniforme entre toutes les cl\u00e9s.</li> <li>La r\u00e9partition des requ\u00eates doit \u00eatre de pr\u00e9f\u00e9rence uniforme entre toutes les cl\u00e9s.</li> </ul> <p>Dans ces conditions il est parfois difficile de trouver la propri\u00e9t\u00e9 r\u00e9pondant \u00e0 tous ces crit\u00e8res !</p> <p>Pas de panique, j'ai une solution ! Elle consiste \u00e0 calculer la cl\u00e9 de partition.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/03.cosmosdb.calculatedPartitionKey/#la-fausse-bonne-idee","title":"La fausse bonne id\u00e9e !","text":"<p>Une solution simple serait de d\u00e9finir de fa\u00e7on al\u00e9atoire la cl\u00e9 de partition. Ainsi on maitrise le nombre de partition et on s'assure que la r\u00e9partition du stockage et des requ\u00eates est uniforme. </p> <p>Parfait ! Sauf que s'il on a 2 processus qui r\u00e9alise au m\u00eame moment l'ajout de la m\u00eame donn\u00e9e chacun va calculer sa propre cl\u00e9 de partition et les 2 ajouts seront enregistr\u00e9s. Nous aurons un doublon !</p> <p>Et ne croyez pas que j'exag\u00e8re et que mon exemple ne peux pas arriver ! J'aime souvent citer la loi de Murphy dans ce type de cas : \"Tout ce qui est susceptible d'aller mal, ira mal.\". Et personnellement, je d\u00e9teste les doublons !</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/03.cosmosdb.calculatedPartitionKey/#une-solution-un-crc-en-guise-de-cle-de-partition","title":"Une solution : Un CRC en guise de cl\u00e9 de partition.","text":"<p>Pourquoi ne pas d\u00e9duire la cl\u00e9 de partition \u00e0 partir de l'identifiant ! </p> <p>Un peu comme les 2 derniers chiffres de votre num\u00e9ro de s\u00e9curit\u00e9 sociale... </p> <p>L'id\u00e9e est d'utiliser le CRC (Contr\u00f4le de redondance cyclique) pour d\u00e9duire la cl\u00e9 de partition \u00e0 partir de l'identifiant. Le nombre de bits du CRC, va permettre de jouer sur le nombre de valeurs possible.</p> <p>Voici un petit tableau de correspondance :</p> Nombre de bits (CRC-x) Nombre de partition Volum\u00e9trie de donn\u00e9e 2 4 entre 4 000 et 40 000 3 8 entre 8 000 et 80 000 4 16 entre 16 000 et 160 000 5 32 entre 32 000 et 320 000 6 64 entre 64 000 et 640 000 7 128 entre 128 000 et 1 280 000 8 256 entre 256 000 et 2 560 000 <p>Ainsi, contrairement \u00e0 l'attribution al\u00e9atoire de la valeur de la cl\u00e9 de partition, on garantit que peu importe le processus r\u00e9alisant une op\u00e9ration sur le conteneur il n'y a aucun risque de se retrouver avec des doublons.</p> <p>L'autre avantage, est que si vous souhaitez r\u00e9cup\u00e9rer une donn\u00e9e \u00e0 partir de son identifiant, vous pouvez automatiquement d\u00e9duire sa cl\u00e9 de partition. Ainsi, lorsque vous interrogez votre conteneur cosmosdb vous pouvez pr\u00e9ciser la partition et ainsi vous r\u00e9cup\u00e9rez plus rapidement et/ou pour moins cher (moins de RU consomm\u00e9s) votre donn\u00e9e.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/03.cosmosdb.calculatedPartitionKey/#conclusion","title":"Conclusion","text":"<p>En int\u00e9grant ce m\u00e9canisme de d\u00e9duction de la cl\u00e9 de partition directement dans votre mod\u00e8le de donn\u00e9es, vous faites abstraction de cette contrainte technique.</p> <p>Certe vous aurez dans votre conteneur une donn\u00e9e technique en plus qui ne sert pas \u00e0 grand chose fonctionnellement. Mais bon, c'est mieux que d'avoir des doublons en pagaille !</p> <p>Note</p> <p>Cette solution peut aussi s'appliquer pour les Table Storage Azure ;-).</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/03.cosmosdb.calculatedPartitionKey/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Partitions CosmosDB</li> <li>Jim Blackler CRCTool</li> </ul>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/03.cosmosdb.calculatedPartitionKey/#remerciements","title":"Remerciements","text":"<ul> <li>Quentin Joseph : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 27 Novembre 2020</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"articles/tips/04.sonarqube.managed/","title":"D\u00e9ployer Sonarqube sur des services manag\u00e9s Azure.","text":"<p>Dans le cadre de mes diff\u00e9rentes missions clients j'ai eu le besoin de d\u00e9ployer l'outil Sonarqube. Sonarqube propose ses images sur docker hub. En m\u00eame temps les Azure WebApp permettent d'ex\u00e9cuter des conteneurs docker. Pourquoi ne pas faire tourner Sonarqube sur une Azure WebApp ?</p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"articles/tips/04.sonarqube.managed/#pourquoi","title":"Pourquoi ?","text":"<p>Sonarqube est une plateforme web de reporting qualit\u00e9. Cette plateforme permet de collecter les rapports d'analyse de code et d'ex\u00e9cution de tests automatis\u00e9s (Couverture de code). A partir de ces \u00e9l\u00e9ments, elle est capable d'attribuer une note qualit\u00e9 \u00e0 votre code. Pour cela, Sonarqube a besoin d'une base de donn\u00e9es afin de stocker les r\u00e9sultats d'analyse.</p> <p>Dans un contexte professionnel nous allons souhaiter que : </p> <ul> <li>Sonarqube soit suffisamment disponible pour que chaque d\u00e9veloppeur et chaque tech-lead puisse observer la qualit\u00e9 du code.</li> <li>le code source accessible dans Sonarqube ne puisse pas \u00eatre exfiltr\u00e9.</li> <li>l'exploitation de cette plateforme soit la plus simple possible afin de limiter les co\u00fbts de maintenance.</li> </ul> <p>Les services manag\u00e9s Azure: Azure WebApp et Azure SQL database, offrent de tr\u00e8s bonnes SLA et permettent de r\u00e9duire les co\u00fbts d'exploitation en d\u00e9l\u00e8guant une bonne partie de celle-ci \u00e0 Microsoft. </p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"articles/tips/04.sonarqube.managed/#larchitecture","title":"L'architecture","text":"<p>Il existe d\u00e9j\u00e0 sur le github de microsoft un quickstart template ARM permettant de d\u00e9ployer Sonarqube sur une Azure WebApp avec une base de donn\u00e9es Azure SQL database. Les soucis de ce quickstart sont les suivants :</p> <ul> <li>il ne permet pas de d\u00e9ployer la derni\u00e8re version de Sonarqube (8.9 LTS),</li> <li>il n'isole pas au niveau r\u00e9seau. Il y a donc un risque d'exfiltration du code.</li> <li>il ne permet pas de conserver la configuration et les plugins de Sonarqube en cas d'incident sur l'Azure WebApp.</li> </ul> <p>Je vous propose donc de revoir un peu l'architecture afin de blinder tout cela : </p> <ul> <li> <p>On va ajouter un Storage Account qui contiendra les extensions et les donn\u00e9es de Sonarqube afin de garantir la r\u00e9silience de la solution. En cas de dysfonctionnement de l'Azure WebApp, les donn\u00e9es Sonarqube ne seront pas perdues. De plus, si l'on doit migrer la solution sur un autre cloud provider, nous serons en capacit\u00e9 de faire cette migration sereinement.</p> </li> <li> <p>Ensuite, on va cr\u00e9er un Virtual network et un Subnet dans lequel on va int\u00e9grer notre Azure WebApp. On va ajouter les services endpoints du Storage Account et du Sql Server \u00e0 notre Subnet. Ainsi notre Azure WebApp pourra communiquer avec les autres services manag\u00e9s sans passer sur internet et donc sans risque d'exposition \u00e0 une potentielle attaque.</p> </li> <li> <p>Enfin, on va mettre en place des r\u00e8gles firewall pour emp\u00e8cher tout acc\u00e8s en dehors de notre Virtual Network. </p> <ul> <li>on va restreindre le Storage Account au Subnet de notre Azure WebApp.</li> <li>on va faire de m\u00eame pour l'Azure Sql Server.</li> <li>on va restreindre l'Azure WebApp aux autres Subnet de notre Virtual Network.</li> </ul> </li> </ul>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"articles/tips/04.sonarqube.managed/#resultat","title":"R\u00e9sultat","text":"<p>Vous trouverez ci-dessous le template ARM permettant de d\u00e9ployer rapidement un Sonarqube isol\u00e9 et r\u00e9silient.  </p> <p> </p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"articles/tips/04.sonarqube.managed/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Deploy Sonarqube on a Linux web app with Azure SQL</li> <li>Sonarqube on Docker Hub</li> </ul>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"articles/tips/04.sonarqube.managed/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Marine Perroteau : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 27 Septembre 2021</p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"articles/tips/05.azuredevops.extension.agentless/","title":"Azure DevOps : Cr\u00e9er sa propre task agentless","text":"<p>Cela fait maintenant des ann\u00e9es que j'utilise quotidiennement Azure DevOps. J'ai pu connaitre sa version On-Premise nomm\u00e9e Team Foundation Server, puis sa premi\u00e8re version SaaS nomm\u00e9e Visual Studio Team Services.</p> <p>Vous ne le savez peut-\u00eatre pas, mais il est possible d'\u00e9tendre les fonctionnalit\u00e9s d'Azure DevOps au travers d'extensions. Ces extensions vont vous permettre d'\u00e9tendre les capacit\u00e9s d'Azure DevOps pour r\u00e9pondre \u00e0 vos enjeux de productivit\u00e9. Vous allez pouvoir personnaliser vos boards Azure, la gestion de vos repositories Azure, vos pipelines CI/CD, ...</p> <p>Le marketplace d'Azure DevOps propose d\u00e9j\u00e0 de nombreuses extensions gratuites et payantes. Mais il est possible que vous ne trouviez pas votre bonheur. Dans ce cas, vous pouvez vous m\u00eame d\u00e9velopper vos propres extensions. </p> <p>Note</p> <p>Les possibilit\u00e9s d'extensions sont \u00e9normes mais sont malheureusement tr\u00e8s peu document\u00e9es. L'article Azure DevOps extensibility points liste en partie les extensions possibles.</p> <p>Je vous propose dans cet article d'\u00e9tendre les capacit\u00e9s de vos pipelines de CI/CD avec une agentless task ou server task.</p> <p>Note</p> <p>J'aurais pr\u00e9f\u00e9r\u00e9 vous faire un comparatif de ce type de t\u00e2che entre les extensions Azure DevOps et les Github Action, malheureusement Github ne propose pas encore ce type de fonctionnalit\u00e9. C'est bien dommage !</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#developper-sa-propre-tache-agentless","title":"D\u00e9velopper sa propre t\u00e2che agentless","text":"","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#une-tache-agentless-cest-quoi-et-pourquoi-jen-aurais-besoin","title":"Une t\u00e2che agentless, c'est quoi et pourquoi j'en aurais besoin ?","text":"<p>Lorsque vous ex\u00e9cutez un pipeline dans Azure DevOps pour compiler, analyser, tester ou d\u00e9ployer un composant vous utilisez un agent. Cet agent est une \"machine\" sur laquelle Azure DevOps va demander de r\u00e9aliser des actions (une compilation .NET par exemple). Mais il est possible de demander \u00e0 Azure DevOps d'ex\u00e9cuter lui-m\u00eame certaines t\u00e2ches. On parle alors d'agentless task ou de server task. </p> <p>Les possibilit\u00e9s de ce type de t\u00e2ches sont cependant limit\u00e9es. Vous ne pourrez r\u00e9aliser que 3 types d'op\u00e9rations :</p> <ul> <li>HttpRequest : pour r\u00e9aliser une requ\u00eate HTTP/S,</li> <li>ServiceBus : pour envoyer un message dans une file d'attente d'Azure Service Bus,</li> <li>HttpRequestChain : pour r\u00e9aliser une suite de requ\u00eates HTTP/S.</li> </ul> <p>Mais, dans de nombreux cas vous n'aurez besoin que de cela :</p> <ul> <li>Imaginons que vous souhaitez notifier automatiquement une application de votre SI d'une mise \u00e0 jour applicative sur un environnement depuis votre pipeline Azure DevOps. Vous n'avez peut-\u00eatre pas besoin de solliciter un agent pour cela ? Peut-\u00eatre qu'une ou plusieurs requ\u00eates HTTP/S seraient suffisantes.</li> <li>Imaginons que vous souhaitez provisionner vos propres agents Azure DevOps \u00e9ph\u00e9m\u00e8res (cf. mon article). Il serait pr\u00e9f\u00e9rable de se passer d'un agent pour en provisionner un autre !</li> </ul> <p>Note</p> <p>Les t\u00e2ches agentless sont execut\u00e9es depuis les serveurs Azure DevOps qui ont des plages d'IP bien d\u00e9finies (cf. documentation microsoft). Elles offrent donc l'avantage d'\u00eatre plus faciles \u00e0 whitelister aupr\u00e8s des firewalls que les agents Microsoft Hosted.  </p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#pas-besoin-de-savoir-coder-pour-cela","title":"Pas besoin de savoir coder pour cela !","text":"<p>Et oui, l'impl\u00e9mentation de ce type de t\u00e2che ne n\u00e9cessite aucune comp\u00e9tence dans un langage ou framework autre que le format \"json\".</p> <p>Pour commencer, il vous faudra installer localement Node.js puis installer tfx-cli via l'utilitaire npm install\u00e9 avec Node.js.</p> <p>Si vous \u00eates sur Linux/OSX :</p> <pre><code>sudo npm install -g tfx-cli\n</code></pre> <p>Si vous \u00eates sur Windows :</p> <pre><code>npm install -g tfx-cli\n</code></pre> <p>Ensuite dans votre r\u00e9pertoire de travail, vous allez cr\u00e9er 2 dossiers et 3 fichiers comme ceci :</p> <pre><code>  |--- images                        \n      |--- extension-icon.png         // l'ic\u00f4ne de votre extension\n  |--- buildandreleasetask            \n      |--- task.json                  // la t\u00e2che agentless \n  |--- vss-extension.json             // le manifeste de votre extension\n</code></pre> <p>Warning</p> <p>L'ic\u00f4ne de votre extension doit \u00eatre au format PNG et respecter une dimension bien pr\u00e9cise : 128x128 pixels. En dehors de cela, vous \u00eatre compl\u00e8tement libre.</p> <p>Note</p> <p>Il n'est pas obligatoire de respecter les noms des dossiers et des fichiers. Mais pour plus de compr\u00e9hension, je conseille de respecter une nomenclature proche de celle-ci.</p> <p>Commen\u00e7ons par l'impl\u00e9mentation du manifeste.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#le-fichier-vss-extensionjson","title":"Le fichier vss-extension.json","text":"<p>Le fichier manifeste est un descriptif de l'extension. L'extension pouvant contenir plusieurs \u00e9l\u00e9ments, ce fichier va permettre de les lister et de pr\u00e9ciser quelques informations obligatoires pour \u00eatre sur le marketplace Azure Devops.</p> <p>Ci-dessous un exemple de manifeste :</p> <pre><code>{\n    \"manifestVersion\": 1,\n    \"id\": \"test-push-to-storagequeue\",\n    \"publisher\": \"Pmorisseau\",\n    \"version\": \"1.0.7\",\n    \"name\": \"test-push-to-storagequeue\",\n    \"description\": \"test-push-to-storagequeue\",\n    \"public\": false,\n    \"categories\": [ \"Azure Pipelines\" ],\n    \"targets\": [\n        {\n            \"id\": \"Microsoft.VisualStudio.Services\"\n        }\n    ],\n    \"icons\": {\n        \"default\": \"images/icon.png\"\n    },\n    \"files\": [\n        {\n            \"path\": \"buildandreleasetask\"\n        }\n    ],\n    \"contributions\": [\n        {\n            \"id\": \"sendtostoagequeue1\",\n            \"description\": \"Agentless task that push a message to an azure queue\",\n            \"type\": \"ms.vss-distributed-task.task\",\n            \"targets\": [ \"ms.vss-distributed-task.tasks\" ],\n            \"properties\": {\n                \"name\": \"buildandreleasetask\"\n            }\n        }        \n    ]\n}\n</code></pre> <p>Ce qu'il est important de retenir \u00e0 propos des diff\u00e9rents attributs :</p> <ul> <li>id : doit \u00eatre constant au fil des \u00e9volutions de l'extension. C'est lui qui permet d'identifier de fa\u00e7on unique l'extension,</li> <li>version : doit toujours \u00eatre incr\u00e9ment\u00e9 avant d'\u00eatre publi\u00e9 sur le marketplace,</li> <li>public : permet de rendre publique ou non l'extension. Une version publique de l'extension le restera m\u00eame si ult\u00e9rieurement vous la repassez en priv\u00e9e,</li> <li>files : doit lister tous les dossiers qui devront \u00eatre int\u00e9gr\u00e9s dans l'extension,</li> <li> <p>contribution :</p> <ul> <li>id : est un identifiant unique et doit correspondre au nom de la t\u00e2che (attribut name dans le fichier task.json),</li> <li>type : doit \u00eatre <code>ms.vss-distributed-task.task</code> dans le cas d'une agentless task,</li> <li>targets : doit contenir <code>ms.vss-distributed-task.tasks</code> dans le cas d'une agentless task,</li> <li> <p>properties :</p> <ul> <li>name : doit correspondre au dossier contenant le fichier task.json.</li> </ul> </li> </ul> </li> </ul> <p>Note</p> <p>Microsoft met \u00e0 disposition une documentation d\u00e9taill\u00e9e ici</p> <p>Passons maintenant \u00e0 l'impl\u00e9mentation de la t\u00e2che.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#le-fichier-taskjson","title":"Le fichier task.json","text":"<p>Imaginons que nous souhaitons r\u00e9aliser une t\u00e2che permettant d'envoyer des messages dans une storage queue. Voici ce que pourrait donner le fichier task.json :</p> <pre><code>{\n    \"$schema\": \"https://raw.githubusercontent.com/Microsoft/azure-pipelines-task-lib/master/tasks.schema.json\",\n    \"id\": \"bee81c33-f056-4721-a4fd-7141e07c42ad\",\n    \"name\": \"sendtostoagequeue1\",\n    \"friendlyName\": \"Send to Storage Queue\",\n    \"description\": \"\",\n    \"helpMarkDown\": \"Send to Storage Queue\",\n    \"category\": \"Azure Pipelines\",\n    \"author\": \"Pmorisseau\",\n    \"visibility\": [\n        \"Build\",\n        \"Release\"\n    ],\n    \"runsOn\": [\n        \"Server\",\n        \"ServerGate\"\n    ],\n    \"version\": {\n        \"Major\": 0,\n        \"Minor\": 0,\n        \"Patch\": 1\n    },       \n    \"instanceNameFormat\": \"Send message to queue : $(queueName)\",\n    \"inputs\": [\n        {\n            \"name\": \"storageAccountUrl\",\n            \"type\": \"string\",\n            \"label\": \"Url du Storage Account\",\n            \"defaultValue\": \"\",\n            \"required\": true\n        },\n        {\n            \"name\": \"queueName\",\n            \"type\": \"string\",\n            \"label\": \"Nom de la file d'attente\",\n            \"defaultValue\": \"\",\n            \"required\": true\n        },\n        {\n            \"name\": \"storageAccountSasToken\",\n            \"type\": \"string\",\n            \"label\": \"Cl\u00e9 d'acc\u00e8s \u00e0 votre file d'attente\",\n            \"defaultValue\": \"\",\n            \"required\": true\n        }        \n    ],\n    \"execution\": {\n        \"HttpRequest\": {\n            \"Execute\": {\n                \"EndpointUrl\": \"{{storageAccountUrl}}/{{queueName}}/messages$(storageAccountSasToken)\",\n                \"Method\": \"POST\",\n                \"Body\": \"&lt;QueueMessage&gt;&lt;MessageText&gt;Lorem Ipsum dolor sit amet !&lt;/MessageText&gt;&lt;/QueueMessage&gt;\",\n                \"Headers\": \"{\\n\\\"Content-Type\\\":\\\"application/xml\\\"\\n}\"\n            }\n        }\n    } \n}    \n</code></pre> <p>Ce qu'il est important de retenir c'est que :</p> <ul> <li>l'attribut id doit \u00eatre unique et constant au fil des \u00e9volutions de la t\u00e2che,</li> <li>l'attribut name doit correspondre \u00e0 un id du n\u0153ud contributions dans le fichier vss-extension.json, </li> <li>l'attribut runsOn doit contenir Server et/ou ServerGate pour \u00eatre consid\u00e9r\u00e9 comme une t\u00e2che agentless, </li> <li>le n\u0153ud inputs doit contenir tous les param\u00e8tres de la t\u00e2che,</li> <li>le n\u0153ud execution doit contenir la commande agentless \u00e0 executer.  </li> </ul> <p>Note</p> <p>Le sch\u00e9ma complet est disponible ici</p> <p>Notre exemple ci-dessus, une fois d\u00e9ploy\u00e9 dans Azure DevOps, va mettre \u00e0 disposition une nouvelle t\u00e2che qui, dans un pipeline classique, ressemblera \u00e0 cela :</p> <p></p> <p>Et dans un pipeline yaml, \u00e0 cela :</p> <pre><code>- task: Pmorisseau.test-push-to-storagequeue.sendtostoagequeue1.sendtostoagequeue1@0\n  displayName: 'Send message to queue : [your queue name]'\n  inputs:\n    storageAccountUrl: 'https://[your storage account name].queue.core.windows.net'\n    queueName: '[your queue name]'\n    storageAccountSasToken: '?sv=2019-02-02&amp;st=2021-12-12T10%3A51%3A39Z&amp;se=2022-12-13T10%3A51%3A00Z&amp;sp=raup&amp;sig=JTDK%2BDc16YpMtGTKkoqtLw1QVDOL7mnzTxOGEKwvWtY%3D'\n</code></pre> <p>Cependant, on est oblig\u00e9 de renseigner dans notre pipeline des donn\u00e9es sensibles comme l'url ou la cl\u00e9 d'acc\u00e8s \u00e0 notre api. Cela peut \u00eatre consid\u00e9r\u00e9 comme une faille de s\u00e9curit\u00e9.</p> <p>Pas de souci, on peut aussi cr\u00e9er ses propres service connections.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#creer-son-service-connection","title":"Cr\u00e9er son service connection","text":"<p>Tout d'abord, il va falloir modifier le fichier manifeste (vss-extension.json) pour d\u00e9clarer le nouveau type de service connection. </p> <p>Dans le n\u0153ud contributions, on va rajouter :</p> <pre><code>        {\n            \"id\": \"storagequeue\",\n            \"description\": \"Storage Queue\",\n            \"type\": \"ms.vss-endpoint.service-endpoint-type\",\n            \"targets\": [\n                \"ms.vss-endpoint.endpoint-types\"\n            ],\n            \"properties\": {\n                \"name\": \"storagequeue\",\n                \"displayName\": \"Storage Queue\",\n                \"url\": {\n                    \"displayName\": \"Azure storage URL (without SAS token)\",\n                    \"required\": true\n                },\n                \"inputDescriptors\": [\n                    {\n                        \"id\": \"queueName\",\n                        \"name\": \"Queue Name\",\n                        \"description\": \"Azure storage queue name\",\n                        \"inputMode\": \"textbox\",\n                        \"isConfidential\": false,\n                        \"validation\": {\n                            \"isRequired\": true,\n                            \"dataType\": \"string\",\n                            \"maxLength\": 200\n                        }\n                    },   \n                    {\n                        \"id\": \"sasToken\",\n                        \"name\": \"SAS token\",\n                        \"description\": \"Azure storage queue SAS token\",\n                        \"inputMode\": \"passwordbox\",\n                        \"isConfidential\": false,\n                        \"validation\": {\n                            \"isRequired\": true,\n                            \"dataType\": \"string\",\n                            \"maxLength\": 500\n                        }\n                    }                                          \n                ],\n                \"dataSources\": [\n                    { \n                        \"name\": \"TestConnection\",\n                        \"endpointUrl\": \"{{endpoint.url}}/{{endpoint.queueName}}/messages$(endpoint.sasToken)\",\n                        \"resultSelector\": \"xpath://QueueMessagesList\"\n                    }\n                ],                                  \n                \"authenticationSchemes\": [\n                    {\n                        \"type\": \"ms.vss-endpoint.endpoint-auth-scheme-none\"\n                    }\n                ]\n            }\n        }\n</code></pre> <p>Ce qu'il est important de retenir \u00e0 propos des diff\u00e9rents attributs :</p> <ul> <li>id : est un identifiant unique,</li> <li>type : doit \u00eatre <code>ms.vss-endpoint.service-endpoint-type</code>,</li> <li>targets : doit contenir <code>ms.vss-endpoint.endpoint-types</code>,</li> <li> <p>properties :</p> <ul> <li>url : corresponde \u00e0 l'url du service,</li> <li>inputDescriptors : doit contenir l'ensemble des param\u00e8tres compl\u00e9mentaire \u00e0 l'url,</li> <li> <p>dataSource et l'item TestConnection (exactement orthographi\u00e9 comme cela) : permettent de d\u00e9finir le test de connexion du service connection,</p> <ul> <li>endpointUrl : corresponde \u00e0 l'url appel\u00e9e lors du test de connexion,</li> <li>resultSelector : correpond \u00e0 la v\u00e9rification \u00e0 r\u00e9aliser sur la r\u00e9ponse lors du test de connexion,</li> </ul> </li> <li> <p>authenticationSchemes : d\u00e9finit le mode d'authentification parmi :</p> <ul> <li>Authentification de base avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-basic</code> dans le cas d'une authentification avec un identifiant et un mot de passe encod\u00e9 en base 64 dans l'en-t\u00eate HTTP,</li> <li>Authentification bas\u00e9e sur un jeton avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-token</code> dans le cas d'une authentification avec un jeton dans l'en-t\u00eate HTTP,</li> <li>Authentification par certificat  avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-cert</code>  dans le cas d'une authentification avec certificat,</li> <li>Sans athentification avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-none</code> lorsqu'il n'y a pas d'authentification.</li> </ul> </li> </ul> </li> </ul> <p>Note</p> <p>Les diff\u00e9rents types d'authentification sont d\u00e9crits ici</p> <p>Ensuite, il va falloir modifier le fichier task.json pour utiliser notre service connection en rempla\u00e7ant le contenu du n\u0153ud inputs par :</p> <pre><code>        {\n            \"name\": \"connectedServiceName\",\n            \"aliases\": [\n                \"serviceConnection\",\n                \"genericService\"\n            ],\n            \"type\": \"connectedService:storagequeue\",\n            \"label\": \"Storage queue service connection\",\n            \"defaultValue\": \"\",\n            \"required\": true,\n            \"helpMarkDown\": \"Select an storage queue service connection\"\n        }\n</code></pre> <p>Il faudra veiller \u00e0 ce que l'attribut type corresponde \u00e0 <code>connectedService:[id du service connection dans le fichier manifeste]</code>.</p> <p>Et modifier le contenu du n\u0153ud executions par :</p> <pre><code>        \"HttpRequest\": {\n            \"Execute\": {\n                \"EndpointId\": \"$(connectedServiceName)\",\n                \"EndpointUrl\": \"{{endpoint.url}}/{{endpoint.queueName}}/messages$(endpoint.sasToken)\",\n                \"Method\": \"POST\",\n                \"Body\": \"&lt;QueueMessage&gt;&lt;MessageText&gt;Lorem Ipsum dolor sit amet !&lt;/MessageText&gt;&lt;/QueueMessage&gt;\",\n                \"Headers\": \"{\\n\\\"Content-Type\\\":\\\"application/xml\\\"\\n}\"\n            }\n        }   \n</code></pre> <p>Il faudra veiller \u00e0 ce que :</p> <ul> <li>l'attribut EndpointId corresponde \u00e0 <code>$([l'attribut name dans le n\u0153ud inputs])</code>,</li> <li>les param\u00e8tres du service connection soient pr\u00e9fix\u00e9s par \"endpoint.\".</li> </ul> <p>Note</p> <p>Il y a 2 syntaxes possibles pour faire r\u00e9f\u00e9rence \u00e0 un param\u00e8tre :</p> <ul> <li><code>{{le_nom_de_l_attribut}}</code> : sera int\u00e9pr\u00e9t\u00e9 comme un texte devant \u00eatre converti en url (httpencode).</li> <li><code>$(le_nom_de_l_attribut)</code> : ne sera pas int\u00e9pr\u00e9t\u00e9 et donc sera utilis\u00e9 tel quel.</li> </ul> <p>Dans notre exemple, le sasToken contenant un ensemble de param\u00e8tres au format Http query, il ne doit donc pas \u00eatre converti.</p> <p>Notre exemple n\u00b02, une fois d\u00e9ploy\u00e9 dans Azure DevOps, va mettre \u00e0 disposition un nouveau service connection qui ressemblera \u00e0 cela :</p> <p></p> <p>Il modifiera aussi la t\u00e2che qui ressemblera \u00e0 cela :</p> <p></p> <p>Et dans un pipeline yaml, \u00e0 cela :</p> <pre><code>- task: Pmorisseau.test-push-to-storagequeue.sendtostoagequeue2.sendtostoagequeue2@0\n  displayName: 'Send to Storage Queue'\n  inputs:\n    serviceConnection: myqueue\n</code></pre> <p>Maintenant, le pipeline ne contient plus de donn\u00e9es \"sensibles\".</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#les-limitations","title":"Les limitations","text":"<p>Les limitations d'impl\u00e9mentation des service connections sont nombreuses et parfois un peu frustrantes :</p> <ul> <li>les param\u00e8tres d\u00e9crits dans le n\u0153ud inputDescriptors ne peuvent pas \u00eatre utilis\u00e9s si l'attribut isConfidential est d\u00e9finit \u00e0 \"true\",</li> <li>les modes d'authentification permis sont trop peu nombreux. Il aurait \u00e9t\u00e9 bienvenue de permettre les authentifications modernes comme l'oauth 2.0 et les authentifications simples comme l'apikey ou le sasToken dans l'url de la requ\u00eate HTTP,</li> <li>l'inputMode password ne sert \u00e0 rien dans le n\u0153ud inputDescriptors.</li> </ul> <p>Note</p> <p>Dans notre exemple le sasToken de notre storage queue restera toujours en clair. </p> <p>Maintenant que nous avons prepar\u00e9 notre extension avec notre nouvelle t\u00e2che agentless, il ne nous reste plus qu'\u00e0 la publier ! </p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#publier-sur-le-marketplace","title":"Publier sur le marketplace","text":"<p>Pour pouvoir utiliser nos extensions sur Azure DevOps, il faut pr\u00e9alablement publier celle-ci sur le marketplace d'Azure DevOps.</p> <p>Note</p> <p>Il vous faut obligatoirement un compte d\u00e9j\u00e0 enregistr\u00e9 dans une organisation Azure DevOps pour publier sur le marketplace.</p> <ol> <li>Connectez-vous \u00e0 votre organisation Azure DevOps : https://dev.azure.com/[votre organisation]</li> <li> <p>Une fois connect\u00e9, g\u00e9n\u00e9rez un personal acces token en cliquant sur User settings puis sur Personal access tokens.</p> <p></p> </li> <li> <p>Cr\u00e9ez un nouveau Personal access token en pr\u00e9cisant bien All accessible organisations et en cochant Manage sous Marketplace.</p> <p></p> </li> <li> <p>Cliquez sur Create et notez bien la cl\u00e9 retourn\u00e9e, c'est votre Personal access token.</p> </li> <li>Ex\u00e9cutez la commande ci-dessous pour packager l'extension :    <pre><code> tfx extension create --manifest-globs vss-extension.json\n</code></pre></li> <li>Ex\u00e9cutez la commande ci-dessous pour publier l'extension sur le marketplace :    <pre><code> tfx extension publish --manifest-globs vss-extension.json --share-with [liste des organisations avec qui vous voulez partager votre extension (s\u00e9par\u00e9 par une virgule)]\n</code></pre></li> <li>durant le processus de publication, il vous sera demand\u00e9 de saisir votre personal access token.</li> </ol> <p>Attention</p> <p>Votre personal access token a syst\u00e9matiquement une date d'expiration. Vous recevrez une notification par email (envoy\u00e9 par azuredevops@microsoft.com) 5 jours avant l'expiration.</p> <p></p> <p>Pensez \u00e0 renouveler votre token !</p> <p>Votre extension est maintenant publi\u00e9e. </p> <p>Vous pouvez consulter celle-ci directement sur le marketplace. Pour cela, une fois connect\u00e9, cliquez sur Publish extensions.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#conclusion","title":"Conclusion","text":"<p>Bien que les capacit\u00e9s d'Azure DevOps peuvent \u00eatre \u00e9tendues sur de nombreux aspects, il s'av\u00e8re que la documentation Microsoft pour aider les d\u00e9veloppeurs est souvent \u00e9parpill\u00e9e et/ou incompl\u00e8te.</p> <p>Dans cet article, j'ai essay\u00e9 de vous montrer un exemple simple d'extension. Pour cela, bien que je connaisse le syst\u00e8me d'extension, j'ai d\u00fb m'y reprendre de nombreuses fois pour avoir une extension op\u00e9rationnelle. Les nombreuses limitations sont souvent des facteurs de frustration.</p> <p>Cependant, les github action ne permettant pas aujourd'hui ce type de t\u00e2che, nous n'avons pas vraiment le choix avec les outils Microsoft... Il reste encore beaucoup de choses \u00e0 am\u00e9liorer de ce point de vue !</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Azure DevOps extensibility points</li> <li>Server Task Authoring</li> <li>Tfx cli</li> <li>Ajouter une extension de t\u00e2che de pipeline personnalis\u00e9e</li> <li>Task Json Schema</li> <li>R\u00e9f\u00e9rence du manifeste de l\u2019extension</li> <li>Sch\u00e9mas d\u2019authentification du point de terminaison de service</li> </ul>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/05.azuredevops.extension.agentless/#remerciements","title":"Remerciements","text":"<ul> <li>Oussama Mouchrit : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 14 D\u00e9cembre 2021</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/","title":"Azure DevOps : Vos propres agents \u00e0 la demande dans votre SI","text":"<p>Une solution de bout en bout pour ex\u00e9cuter des agents Azure DevOps conteneuris\u00e9s dans votre r\u00e9seau d'entreprise, \u00e7a vous dit ? Vous pourrez ainsi utiliser Azure DevOps Services pour g\u00e9rer le d\u00e9ploiement de vos applications et services m\u00eame dans les zones s\u00e9curis\u00e9es de votre SI. </p> <p>Dans mes pr\u00e9c\u00e9dents articles j'avais effleur\u00e9 le sujet (Azure DevOps : Cr\u00e9er sa propre task agentless et Azure Batch, le mal-aim\u00e9), dans cet article je vous propose de d\u00e9tailler comment mettre tout cela en place.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#pourquoi-le-faire","title":"Pourquoi le faire ?","text":"<ul> <li>Si vous souhaitez utiliser Azure DevOps Services pour d\u00e9ployer vos applications et services dans votre SI d'entreprise isol\u00e9 d'un point de vue r\u00e9seau.</li> <li>Si vous souhaitez utiliser des conteneurs pour vos op\u00e9rations de build et/ou de d\u00e9ploiements afin d'\u00e9viter les effets de bords li\u00e9s aux pr\u00e9c\u00e9dentes ex\u00e9cutions de pipeline CI/CD. </li> <li>Si vous souhaitez r\u00e9duire le temps de build et de d\u00e9ploiement de vos pipelines en pr\u00e9installant vos frameworks et outils legacy sur vos agents.</li> </ul>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#larchitecture","title":"L'architecture","text":"<p>Je vous propose d'orchestrer vos agents Azure DevOps avec Azure Batch. L'ensemble de l'architecture sera donc sur Azure. Bien entendu, c'est une proposition, il est certain que vous pouvez r\u00e9aliser une architecture \u00e9quivalente sur un autre h\u00e9bergeur cloud ou sur votre cloud priv\u00e9.</p> <p></p> <p>Concr\u00e8tement voici le s\u00e9quencement qui va se produire pour la mise \u00e0 disposition d'un agent \u00e9ph\u00e9m\u00e8re :</p> <ol> <li>Une t\u00e2che agentless \"Invoke Azure Function\" du pipeline de build/d\u00e9ploiement Azure DevOps appel la fonction ProvideAzDOAgent pour demander un agent \u00e9ph\u00e9m\u00e8re,</li> <li>Pour chaque appel, l'Azure Function cr\u00e9e une t\u00e2che dans Azure Batch Account,</li> <li>L'Azure Batch Account traite les t\u00e2ches et affecte la t\u00e2che au bon pool de n\u0153uds,</li> <li>Le pool de n\u0153uds instancie un conteneur \u00e0 partir de l'image pr\u00e9sente dans l'Azure Container Registry,</li> <li>Une fois le conteneur instanci\u00e9 et d\u00e9marr\u00e9, celui-ci s'enregistre aupr\u00e8s d'Azure DevOps pour faire savoir qu'il est disponible. Azure DevOps lui affecte alors un job en attente. </li> <li>Le job Azure DevOps s'ex\u00e9cute dans le Virtual Network A et peut communiquer avec le r\u00e9seau On Premise.</li> </ol> <p>On constate que le service Azure Batch (et ses pools) ainsi qu'Azure Container Registry sont compl\u00e8tement isol\u00e9s d'un point de vue r\u00e9seau. Seule l'Azure Function est accessible publiquement. Cette derni\u00e8re a cependant une r\u00e8gle firewall limitant les appels aux plages d'IP publiques d'Azure DevOps Services.</p> <p>Note</p> <p>Microsoft met \u00e0 disposition les plages d'IP du service Azure DevOps pour chacune des r\u00e9gions : ici</p> <p>Mise \u00e0 jour du 05/02/2022</p> <p>Lors de la publication de cet article, j'ai oubli\u00e9 un \u00e9l\u00e9ment important de la s\u00e9curisation de cette solution.  En effet, dans la premi\u00e8re version les nodes des pools Azure Batch avaient une adresse IP publique qui permettait un acc\u00e8s au travers des protocoles RDP pour Windows et SSH pour Linux. Mon coll\u00e8gue, Etienne Louise, me l'a fait remarqu\u00e9 et m'a pr\u00e9-mach\u00e9 le travail en me donnant directement la solution. Pour cela :</p> <ul> <li>Lors de la cr\u00e9ation du pool, il faut indiquer que l'on ne veux pas cr\u00e9er d'IP publique cf. documentation Microsoft,</li> <li>Il faut ajouter le service Azure NAT Gateway branch\u00e9 sur le subnet des pools. Cela permettra \u00e0 nos node de pouvoir acc\u00e9der \u00e0 internet pour s'enregistrer aupr\u00e8s d'Azure DevOps.</li> </ul> <p>Il ne reste donc plus qu'\u00e0 d\u00e9ployer notre infrastructure sur Azure.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#linfrastructure","title":"L'infrastructure","text":"<p>Vous trouverez ci-dessous le template ARM permettant de d\u00e9ployer rapidement l'infrastructure.  </p> <p> </p> <p>Ce template d'infra. met \u00e0 disposition 2 pools de nodes : Un pour les agents Azure DevOps sur Windows et un autre pour les agents sur Linux.</p> <p>Note</p> <p>Etant donn\u00e9 que les conteneurs Windows ne peuvent tourner que sur des OS Windows, nous n'avons pas d'autres choix que de provisionner des pools avec des OS distincts.</p> <p>Mise \u00e0 jour du 05/02/2022</p> <p>L'infrastructure disponible ci-dessus prend en compte les remarques d'Etienne Louise.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#lauto-scale","title":"L'auto-scale","text":"<p>Azure Batch propose un syst\u00e8me d'auto-scale des nodes d'un pool. Dans notre cas, nous allons l'utiliser pour \u00e9viter de laisser tourner des VM sur Azure pendant plusieurs heures sans op\u00e9rations de build ou de d\u00e9ploiement. Pour chacun de ces pools, j'ai donc rajout\u00e9 le script d'auto-scale ci-dessous :</p> <pre><code>$nbTaskPerNodes = $TaskSlotsPerNode;\n$currentNodes = $TargetLowPriorityNodes;\n$nbPending5min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 5) &lt; 70 ? max($PendingTasks.GetSample(1)) : max($PendingTasks.GetSample(TimeInterval_Minute * 5));\n$nbPending60min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 60) &lt; 70 ? 1000 : max($PendingTasks.GetSample(TimeInterval_Minute * 60));\n$totalLowPriorityNodes = $nbPending5min &gt; max(0, $TaskSlotsPerNode * $currentNodes) ? $currentNodes + 1 : $currentNodes;\n$totalLowPriorityNodes = $nbPending60min &lt;= $TaskSlotsPerNode * max(0, $currentNodes - 1) \u00a0? $currentNodes - 1 : $totalLowPriorityNodes;\n$totalLowPriorityNodes = min(4, max($totalLowPriorityNodes, 0));\n$TargetLowPriorityNodes = $totalLowPriorityNodes;\n$NodeDeallocationOption = taskcompletion;\n</code></pre> <p>Ce script va \u00e9valuer le nombre de t\u00e2ches en cours ou en attente :</p> <ul> <li>Si celui-ci est sup\u00e9rieur au nombre de n\u0153ud multipli\u00e9 par le nombre de t\u00e2ches parall\u00e8les, un nouveau n\u0153ud sera ajout\u00e9.</li> <li>Si celui-ci est inf\u00e9rieur au nombre de n\u0153ud - 1 multipli\u00e9 par le nombre de t\u00e2ches parall\u00e8les, un n\u0153ud sera lib\u00e9r\u00e9.</li> </ul> <p>Le Scale-Out (ajout d'un n\u0153ud) est \u00e9valu\u00e9 sur les 5 derni\u00e8re minutes afin d'\u00eatre le plus r\u00e9actif possible en cas de hausse du nombre de t\u00e2ches. Le Scale-In (suppression d'un n\u0153ud) est \u00e9valu\u00e9 sur la derni\u00e8re heure afin de pouvoir g\u00e9rer les baisses ponctuelles de t\u00e2ches.</p> <p>Voici un exemple de ce que pourrait donner l'activit\u00e9 sur une journ\u00e9e :</p> <p></p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#les-limitations","title":"Les limitations","text":"<p>Cependant, il faut savoir qu'il y a quelques petites limitations :</p> <ol> <li>Bien que vous puissiez d\u00e9ployer vos pools Azure Batch avec ARM, il n'est pas possible d'incr\u00e9menter l'infrastructure du pool. Autrement dit, vous ne pouvez pas modifier un pool existant. Et, c'est m\u00eame pire puisque vous aurez une erreur si votre pool existe d\u00e9j\u00e0 au moment de l'ex\u00e9cution de votre template ARM. Pour compenser cette limitation, j'ai ajout\u00e9 2 param\u00e8tres \"create_WindowsBatchPool\" et \"create_UbuntuBatchPool\".</li> <li>Lors de la cr\u00e9ation de votre container registry, celui-ci ne contient aucune image. Il faudra ainsi pr\u00e9voir l'importation des images de vos agents Azure DevOps. </li> </ol> <p>Pour cette seconde limitation, je vous propose d'\u00e9tudier la conteneurisation de notre agent Azure DevOps. </p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#conteneuriser-votre-agent-azure-devops","title":"Conteneuriser votre agent Azure DevOps","text":"<p>En parcourant dockerhub \u00e0 la recherche d'une image docker de mon agent Azure DevOps, j'ai d\u00e9couvert le projet de Czon. Son projet consiste \u00e0 automatiser la construction d'images docker afin d'embarquer syst\u00e9matiquement la derni\u00e8re version de l'agent Azure DevOps. Ainsi sur son repository dockerhub, Czon partage les images ubuntu avec la derni\u00e8re version de l'agent Azure DevOps. \u00c7a c'est classe !</p> <p>Je me suis donc permis de forker son repository Github pour apporter quelques petites \u00e9volutions au travail d\u00e9j\u00e0 excellent de Czon et ajouter les fonctionnalit\u00e9s suivantes :</p> <ul> <li>Cr\u00e9ation de conteneurs sur les bases Windows ltsc2019, Ubuntu 18.04 et Ubuntu 20.04,</li> <li>Et pour chacun de ces OS, ajout des frameworks dotnet core 3.1 et dotnet 6.0</li> </ul> <p>Vous pouvez trouver mes modifications sur mon repository Github, et les images g\u00e9n\u00e9r\u00e9es sur dockerhub.</p> <p>Il ne reste plus qu'\u00e0 importer les images de dockerhub vers votre Azure Container Registry avec les commandes Azure CLI suivantes :</p> <pre><code>    az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/azdo-agent:ubuntu-20.04-azdo -t azdo-agent:ubuntu-20.04-azdo\n    az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/azdo-agent:ubuntu-20.04-azdo -t azdo-agent:ubuntu-18.04-azdo\n    az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/azdo-agent:windows-core-ltsc2019-azdo -t azdo-agent:windows-core-ltsc2019-azdo\n</code></pre> <p>Maintenant, passons \u00e0 la programmation de la fonction qui va g\u00e9n\u00e9rer les t\u00e2ches dans Azure Batch.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#une-azure-function-pour-piloter-azure-batch","title":"Une Azure function pour piloter Azure Batch","text":"<p>Notre objectif est de permettre la cr\u00e9ation d'une t\u00e2che ex\u00e9cutant notre image conteneuris\u00e9e dans Azure Batch via l'appel HTTP d'une fonction Azure.</p> <p>Pour rappel, une t\u00e2che doit s'ex\u00e9cuter dans un job. Donc si le job n'existe pas, il faudra le cr\u00e9er. Notre job va permettre aussi de d\u00e9finir les variables d'environnements de notre agent conteneuris\u00e9. Dans notre cas, nous devons d\u00e9finir comme variables d'environnement :</p> <ul> <li>L'url de notre organisation Azure DevOps,</li> <li>Le personal access token pour permettre \u00e0 notre agent de s'authentifier sur l'organisation,</li> <li>Le nom du pool dans lequel notre agent sera ajout\u00e9,</li> <li>Le top indiquant si l'agent ne doit ex\u00e9cuter qu'un seul job Azure DevOps.</li> </ul> <p>Nous allons utiliser le .net 6.0 pour programmer notre Azure Function. Vous trouverez ici le code source cr\u00e9\u00e9 pour l'occasion.</p> <p>Aujourd'hui, seule l'authentification par jeton personnel pour ajouter un agent Self-Hosted dans un pool sur Azure DevOps est possible. Ce n'est pas id\u00e9al. En effet : </p> <ul> <li>Celui-ci ayant une dur\u00e9e de validit\u00e9 limit\u00e9 dans le temps, cela implique que vous devrez r\u00e9guli\u00e8rement intervenir pour pouvoir le renouveler.</li> <li>Celui-ci \u00e9tant li\u00e9 \u00e0 un utilisateur Azure DevOps, si il vient \u00e0 partir alors ses PAT seront r\u00e9voqu\u00e9s. Il faudra alors reg\u00e9n\u00e9rer un nouveau jeton.</li> </ul> <p>Note</p> <p>Microsoft met \u00e0 disposition la proc\u00e9dure de cr\u00e9ation d'un PAT pour votre agent Azure DevOps : ici</p> <p>Voici la configuration n\u00e9cessaire pour notre Azure Function :</p> Nom Description BatchAccountUrl Url du service Azure Batch BatchAccountName Nom du service Azure Batch BatchAccountKey Cl\u00e9 d'acc\u00e8s au service Azure Batch ContainerRegistryServer Nom complet du service Azure Container Registry AzDOUrl Url de notre organisation Azure DevOps AzDOToken Personal access token permettant \u00e0 notre agent de s'authentifier sur l'organisation AzDOUbuntuPool Nom du pool contenant les agents s'ex\u00e9cutant sur Ubuntu AzDOWindowsPool Nom du pool contenant les agents s'ex\u00e9cutant sur Windows","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#lintegration-avec-azure-devops","title":"L'int\u00e9gration avec Azure DevOps","text":"<p>Maintenant que nous avons notre solution op\u00e9rationnelle sur Azure, il faut permettre \u00e0 nos pipelines Azure DevOps de demander un agent et d'utiliser celui-ci lorsqu'il est disponible.</p> <p>Avant tout, il faut cr\u00e9er les pools d'agents sur Azure DevOps. Ce document de Microsoft explique la proc\u00e9dure. </p> <p>Ensuite, nous allons ajouter dans notre pipeline un job Agentless ou Server-side avec une t\u00e2che Invoke Azure Function. Cette t\u00e2che devra r\u00e9aliser une requ\u00eate HTTP POST.</p> <p>Ci-dessous un exemple de pipeline yaml utilisant cette t\u00e2che.</p> <pre><code>  jobs:\n  - job: RequestAzDOAgent\n    pool: server\n    steps:\n    - task: AzureFunction@1\n      displayName: 'Request new ephemeral agent'\n      inputs:\n        function: 'https://[YOUR_FUNCTION_NAME].azurewebsites.net/api/ProvideAzDOAgent'\n        key: '[YOUR_FUNCTION_KEY]'\n        body: |\n        {\n            \"AgentOSType\":\"ubuntu-latest\"\n        }\n  - job: RunWithEphemeralAgent\n    dependsOn: RequestAzDOAgent\n    pool:\n      name: '[AzDOUbuntuPool]'\n    steps:\n    - bash: \n      displayName: 'Bash Script'\n</code></pre> <p>Note</p> <p>Les attributs YOUR_FUNCTION_NAME et YOUR_FUNCTION_KEY auront \u00e9t\u00e9 pr\u00e9alablement r\u00e9cup\u00e9r\u00e9s depuis votre Azure Function. L'attribut AzDOUbuntuPool correspond au nom du pool d\u00e9finit dans Azure DevOps</p> <p>Et voil\u00e0 !!!</p> <p>Enfin non, presque... </p> <p>En effet, lorsque vous allez lancer votre pipeline celui-ci se soldera par un \u00e9chec syst\u00e9matique vous indiquant qu'il n'y a pas d'agent dans votre *pool*. En effet, entre le moment o\u00f9 vous allez faire votre demande d'agent et celui o\u00f9 il sera disponible, il peut se passer quelques secondes ou quelques minutes (si c'est la premi\u00e8re ex\u00e9cution de la journ\u00e9e par exemple). Dans tous les cas, Azure DevOps va automatiquement lancer le job suivant cens\u00e9 s'ex\u00e9cuter sur votre agent \u00e9ph\u00e9m\u00e8re. Ne trouvant aucun agent, le pipeline Azure DevOps consid\u00e8re \u00e0 tort qu'il n'y aura jamais aucun agent dans ce pool** et tombe en erreur.</p> <p>Mais alors comment dire \u00e0 notre instance de pipeline de patienter ?</p> <p>Ma solution consiste \u00e0 enregistrer un agent \"fictif\" dans le pool. Pour cela, rien de plus simple, il suffit de suivre la proc\u00e9dure d'installation d'un agent Self-Hosted, puis de d\u00e9sinstaller celui-ci sans le d\u00e9senregistrer. Ainsi, vous conservez dans votre pool un agent Offline. Cela sera suffisant pour faire patienter Azure DevOps le temps que votre agent \u00e9ph\u00e9m\u00e8re soit disponible.</p> <p> </p> <p>C'est moche, mais \u00e7a marche !</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#conclusion","title":"Conclusion","text":"<p>Au travers de cet article j'ai essay\u00e9 de vous montrer plusieurs points :</p> <ul> <li>Que vous pouvez utiliser les services manag\u00e9s en tant qu'enabler de votre plateforme de production logicielle,</li> <li>Que vous pouvez s\u00e9curiser vos d\u00e9ploiements logiciels m\u00eame avec des solutions cloud,</li> <li>Que vous pouvez mettre en place des solutions de build et de d\u00e9ploiement sobre en conteneurisant les framework et outils dont vous avez besoin,</li> <li>Que vous pouvez facilement l'int\u00e9gr\u00e9 avec Azure DevOps.</li> </ul> <p>Tout n'est pas parfait, et j'aurais pr\u00e9f\u00e9r\u00e9 :</p> <ul> <li>Que les pool d'Azure Batch soient mieux g\u00e9r\u00e9s par Azure resource Manager,</li> <li>Que l'on puisse enregistrer des agents Azure DevOps sans utiliser de Personal access token ou,</li> <li>Que l'on ne soit pas oblig\u00e9 de cr\u00e9er un agent \"fictif\" dans Azure DevOps.</li> </ul> <p>Mais, j'esp\u00e8re vous avoir convaincu de ma d\u00e9marche. Et si cela vous int\u00e9resse, je vous invite \u00e0 vous approprier ce que j'ai produit dans le cadre de cet article :</p> <ul> <li>Le fork Github de Czon permettant de construire des images avec l'agent AzDO</li> <li>Mon repo. dockerhub contenant les images avec la derni\u00e8re version de l'agent AzDO</li> <li>Mon repo. Github contenant toute la solution (Infra + Code + Pipeline AzDO)</li> </ul> <p>Et qu'en est-il des runner Github ? Nous verrons cela dans un prochain article...</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Azure DevOps Services : Connexions entrantes</li> <li>Github Czon : Azure Pipelines Agent Docker Container</li> <li>Docker hub Czon : AzDO agent</li> <li>Azure DevOps : S\u2019authentifier avec un jeton d\u2019acc\u00e8s personnel (PAT)</li> <li>Azure DevOps : Cr\u00e9ation de pools d\u2019agents</li> </ul>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/06.azuredevops.ephemeralagents/#remerciements","title":"Remerciements","text":"<ul> <li>David Dubourg : pour la relecture</li> <li>Quentin Joseph : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> <li>Etienne Louise : pour la remarque et la solution avec le NAT Gateway</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 25 Janvier 2022. Mis \u00e0 jour le 5 F\u00e9vrier 2022</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/","title":"GitHub : Vos propres runner \u00e0 la demande dans votre SI","text":"<p>Une solution de bout en bout pour ex\u00e9cuter des GitHub Actions Runner conteneuris\u00e9s dans votre r\u00e9seau d'entreprise, \u00e7a vous dit ? Vous pourrez ainsi utiliser GitHub pour g\u00e9rer le d\u00e9ploiement de vos applications et services m\u00eame dans les zones s\u00e9curis\u00e9es de votre SI. </p> <p>Dans un pr\u00e9c\u00e9dent article je vous ai propos\u00e9 de mettre en place une solution vous permettant de provisionner \u00e0 la demande vos agents Azure DevOps (cf. Azure DevOps : Vos propres agents \u00e0 la demande dans votre SI). Je vous propose de faire la m\u00eame chose mais avec GitHub. </p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#pourquoi-le-faire","title":"Pourquoi le faire ?","text":"<p>Pour les m\u00eames raisons qu'avec Azure DevOps Services, \u00e0 savoir :</p> <ul> <li>Si vous souhaitez utiliser GitHub Actions pour d\u00e9ployer vos applications et services dans votre SI d'entreprise isol\u00e9 d'un point de vue r\u00e9seau.</li> <li>Si vous souhaitez utiliser des conteneurs pour vos op\u00e9rations de build et/ou de d\u00e9ploiement afin d'\u00e9viter les effets de bord li\u00e9s aux pr\u00e9c\u00e9dentes ex\u00e9cutions de pipeline CI/CD. </li> <li>Si vous souhaitez r\u00e9duire le temps de build et de d\u00e9ploiement de vos pipelines en pr\u00e9installant vos frameworks et outils legacy sur vos agents.</li> </ul>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#larchitecture","title":"L'architecture","text":"<p>Je vous propose d'orchestrer vos GitHub Actions Runner avec Azure Batch. L'ensemble de l'architecture sera donc sur Azure. Bien entendu, c'est une proposition, il est certain que vous pouvez r\u00e9aliser une architecture \u00e9quivalente sur un autre h\u00e9bergeur cloud ou sur votre cloud priv\u00e9.</p> <p></p> <p>Concr\u00e8tement voici le s\u00e9quencement qui va se produire pour la mise \u00e0 disposition d'un agent \u00e9ph\u00e9m\u00e8re :</p> <ol> <li>GitHub appelle la fonction ProvideActionsRunner pour demander un runner \u00e9ph\u00e9m\u00e8re,</li> <li>Pour chaque appel, l'Azure Function cr\u00e9e une t\u00e2che dans Azure Batch Account,</li> <li>L'Azure Batch Account traite les t\u00e2ches et affecte la t\u00e2che au bon pool de n\u0153uds,</li> <li>Le pool de n\u0153uds instancie un conteneur \u00e0 partir de l'image pr\u00e9sente dans l'Azure Container Registry,</li> <li>Une fois le conteneur instanci\u00e9 et d\u00e9marr\u00e9, celui-ci s'enregistre aupr\u00e8s de GitHub pour faire savoir qu'il est disponible. GitHub lui affecte alors un job en attente. </li> <li>Le job GitHub s'ex\u00e9cute dans le Virtual Network A et peut communiquer avec le r\u00e9seau On Premise.</li> </ol> <p>On constate que le service Azure Batch (et ses pools) ainsi qu'Azure Container Registry sont compl\u00e8tement isol\u00e9s d'un point de vue r\u00e9seau. Seule l'Azure Function est accessible publiquement. Cette derni\u00e8re a cependant une r\u00e8gle firewall limitant les appels aux plages d'IP publiques de GitHub.</p> <p>Note</p> <p>GitHub met \u00e0 disposition les plages d'IP de ses services \u00e0 partir de cette api</p> <p>Il ne reste donc plus qu'\u00e0 d\u00e9ployer notre infrastructure sur Azure.</p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#linfrastructure","title":"L'infrastructure","text":"<p>J'ai mis \u00e0 jour l'infrastructure pr\u00e9alablement mise en place pour Azure DevOps Service avec les quelques sp\u00e9cificit\u00e9s de GitHub.  Vous trouverez ci-dessous le template ARM permettant de d\u00e9ployer rapidement l'infrastructure pour GitHub et pour Azure DevOps).  </p> <p> </p> <p>Ce template d'infra. met \u00e0 disposition 2 pools de nodes : un pool pour les Actions Runner sur Windows et un autre pour les Actions Runner sur Linux.</p> <p>Note</p> <p>Etant donn\u00e9 que les conteneurs Windows ne peuvent tourner que sur des OS Windows, nous n'avons pas d'autres choix que de provisionner des pools avec des OS distincts.</p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#lauto-scale","title":"L'auto-scale","text":"<p>Azure Batch propose un syst\u00e8me d'auto-scale des nodes d'un pool. Dans notre cas, nous allons l'utiliser pour \u00e9viter de laisser tourner des VM sur Azure pendant plusieurs heures sans op\u00e9ration de build ou de d\u00e9ploiement. Pour chacun de ces pools, j'ai donc rajout\u00e9 le script d'auto-scale ci-dessous :</p> <pre><code>$nbTaskPerNodes = $TaskSlotsPerNode;\n$currentNodes = $TargetLowPriorityNodes;\n$nbPending5min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 5) &lt; 70 ? max($PendingTasks.GetSample(1)) : max($PendingTasks.GetSample(TimeInterval_Minute * 5));\n$nbPending60min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 60) &lt; 70 ? 1000 : max($PendingTasks.GetSample(TimeInterval_Minute * 60));\n$totalLowPriorityNodes = $nbPending5min &gt; max(0, $TaskSlotsPerNode * $currentNodes) ? $currentNodes + 1 : $currentNodes;\n$totalLowPriorityNodes = $nbPending60min &lt;= $TaskSlotsPerNode * max(0, $currentNodes - 1) \u00a0? $currentNodes - 1 : $totalLowPriorityNodes;\n$totalLowPriorityNodes = min(4, max($totalLowPriorityNodes, 0));\n$TargetLowPriorityNodes = $totalLowPriorityNodes;\n$NodeDeallocationOption = taskcompletion;\n</code></pre> <p>Ce script va \u00e9valuer le nombre de t\u00e2ches en cours ou en attente :</p> <ul> <li>Si celui-ci est sup\u00e9rieur au nombre de n\u0153uds multipli\u00e9 par le nombre de t\u00e2ches parall\u00e8les, un nouveau n\u0153ud sera ajout\u00e9.</li> <li>Si celui-ci est inf\u00e9rieur au nombre de n\u0153uds - 1 multipli\u00e9 par le nombre de t\u00e2ches parall\u00e8les, un n\u0153ud sera lib\u00e9r\u00e9.</li> </ul> <p>Le Scale-Out (ajout d'un n\u0153ud) est \u00e9valu\u00e9 sur les 5 derni\u00e8res minutes afin d'\u00eatre le plus r\u00e9actif possible en cas de hausse du nombre de t\u00e2ches. Le Scale-In (suppression d'un n\u0153ud) est \u00e9valu\u00e9 sur la derni\u00e8re heure afin de pouvoir g\u00e9rer les baisses ponctuelles de t\u00e2ches.</p> <p>Voici un exemple de ce que pourrait donner l'activit\u00e9 sur une journ\u00e9e :</p> <p></p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#les-limitations","title":"Les limitations","text":"<p>Cependant, il faut savoir qu'il y a quelques petites limitations :</p> <ol> <li>Bien que vous puissiez d\u00e9ployer vos pools Azure Batch avec ARM, il n'est pas possible d'incr\u00e9menter l'infrastructure du pool. Autrement dit, vous ne pouvez pas modifier un pool existant. Et, c'est m\u00eame pire puisque vous aurez une erreur si votre pool existe d\u00e9j\u00e0 au moment de l'ex\u00e9cution de votre template ARM. Pour compenser cette limitation, j'ai ajout\u00e9 2 param\u00e8tres \"create_WindowsBatchPool\" et \"create_UbuntuBatchPool\".</li> <li>Lors de la cr\u00e9ation de votre container registry, celui-ci ne contient aucune image. Il faudra ainsi pr\u00e9voir l'importation des images de vos Actions Runner. </li> </ol> <p>Pour cette seconde limitation, je vous propose d'\u00e9tudier la conteneurisation de notre Actions Runner. </p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#conteneuriser-votre-actions-runner","title":"Conteneuriser votre actions runner","text":"<p>Je suis reparti de mon travail pour la conteneurisation des agents Azure DevOps pour l'appliquer aux Actions Runner.</p> <p>Vous pouvez trouver mes adaptations sur mon repository GitHub, et les images g\u00e9n\u00e9r\u00e9es sur dockerhub.</p> <p>Il ne reste plus qu'\u00e0 importer les images de dockerhub vers votre Azure Container Registry avec les commandes Azure CLI suivantes :</p> <pre><code>    az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner -t githubactions-runner:ubuntu-20.04-actionsrunner\n    az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner -t githubactions-runner:ubuntu-18.04-actionsrunner\n    az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner -t githubactions-runner:windows-core-ltsc2019-actionsrunner\n</code></pre> <p>Maintenant, passons \u00e0 la programmation de la fonction qui va g\u00e9n\u00e9rer les t\u00e2ches dans Azure Batch.</p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#une-azure-function-pour-piloter-azure-batch","title":"Une Azure function pour piloter Azure Batch","text":"<p>Notre objectif est de permettre la cr\u00e9ation d'une t\u00e2che ex\u00e9cutant notre image conteneuris\u00e9e dans Azure Batch via l'appel HTTPS d'une fonction Azure.</p> <p>Pour rappel, une t\u00e2che doit s'ex\u00e9cuter dans un job. Donc si le job n'existe pas, il faudra le cr\u00e9er. Notre job va permettre aussi de d\u00e9finir les variables d'environnements de notre agent conteneuris\u00e9. Dans notre cas, nous devons d\u00e9finir comme variables d'environnement :</p> <ul> <li>L'url de l'organisation GitHub ou l'url du repo personnel,</li> <li>Le token pour permettre \u00e0 notre agent de s'enregistrer,</li> <li>Les tags qui permettront d'affecter le bon runner au bon job GitHub,</li> <li>Le top indiquant si l'agent ne doit ex\u00e9cuter qu'un seul job GitHub Actions.</li> </ul> <p>Nous allons utiliser le .NET 6.0 pour programmer notre Azure Function. Vous trouverez ici le code source am\u00e9lior\u00e9 pour g\u00e9rer \u00e0 la fois Azure Devops et GitHub.</p> <p>Sur GitHub le jeton permettant d'enregistrer notre runner a une validit\u00e9 d'une heure. Il faut donc pr\u00e9voir de demander syst\u00e9matiquement un nouveau jeton pour chaque job. Pour cela, il faut appeler l'api GitHub. </p> <p>Note</p> <p>GitHub fournit une documentation d'api compl\u00e8te permettant de r\u00e9cup\u00e9rer ce token pour :</p> <ul> <li>GitHub enterprise</li> <li>GitHub organization</li> <li>GitHub repository</li> </ul> <p>Mais pour pouvoir appeler l'api, il faut \u00eatre authentifi\u00e9 !  Il existe 3 m\u00e9thodes :</p> <ul> <li>GitHub App : Vous permet de cr\u00e9er une application permettant \u00e0 vos utilisateurs d'acc\u00e9der au travers de celle-ci aux services de GitHub.</li> <li>OAuth App : Vous permet de cr\u00e9er une application permettant d'acc\u00e9der \u00e0 la place de l'utilisateur aux services de GitHub.</li> <li>Personal Access Token : Vous permet d'acc\u00e9der aux services de GitHub en se faisant passer pour vous.</li> </ul> <p>Dans mon cas, j'ai opt\u00e9 pour la solution la plus simple \u00e0 mettre en \u0153uvre : le Personal Access Token. Mais je vous recommande fortement d'opter pour l'OAuth App.</p> <p>Pour cr\u00e9er votre Personal Access Token :</p> <ol> <li>Cliquez sur Settings dans l'onglet de votre compte,</li> <li>Cliquez sur Developer settings et ensuite Personal access tokens,</li> <li>Puis Generate new token</li> <li>Saisissez un libell\u00e9 et une dur\u00e9e de validit\u00e9.</li> <li>S\u00e9lectionnez les scopes. Dans notre cas, si vous souhaitez cr\u00e9er des runners au niveau de votre organisation il faudra cocher <code>admin:org</code>. Et si vous souhaitez cr\u00e9er des runners au niveau de vos repos, il faudra cocher <code>repo</code>.     </li> <li>Enfin cliquez sur Generate token. Votre token s'affiche. Sauvegardez-le puisqu'il ne sera plus visible ensuite !</li> </ol> <p>Voici donc la configuration n\u00e9cessaire pour l'Azure Function :</p> Nom Description BatchAccountUrl Url du service Azure Batch BatchAccountName Nom du service Azure Batch BatchAccountKey Cl\u00e9 d'acc\u00e8s au service Azure Batch ContainerRegistryServer Nom complet du service Azure Container Registry UbuntuPool Nom du pool contenant les agents s'ex\u00e9cutant sur Ubuntu WindowsPool Nom du pool contenant les agents s'ex\u00e9cutant sur Windows GithubToken Personal access token permettant de demander un token pour l'enregistrement du runner","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#lintegration-avec-github","title":"L'int\u00e9gration avec GitHub","text":"<p>Maintenant que nous avons notre solution op\u00e9rationnelle sur Azure, il faut permettre \u00e0 nos workflows GitHub de demander un runner et d'utiliser celui-ci lorsqu'il est disponible.</p> <p>Ce qui est super avec GitHub contrairement \u00e0 Azure DevOps Services, c'est la multitude de webhooks. GitHub propose notamment un webhook pour les jobs.  </p> <p>Note</p> <p>GitHub fournit une documentation de webhook et de payload compl\u00e8te ici</p> <p>Dans notre cas, nous allons souscrire notre Azure function aux webhooks de GitHub.</p> <p>Pour cela :</p> <ol> <li>dans les Settings de votre repo ou de votre organization cliquez sur Webhooks,</li> <li>cliquez sur Add Webhooks,</li> <li>dans Payload URL saisissez l'url compl\u00e8te de votre function : https://<code>[VotreAzureFunction]</code>.azurewebsites.net/api/ProvideActionsRunner?code=<code>[VotreSecret]</code></li> <li>dans Content Type s\u00e9lectionnez <code>application/json</code></li> <li>cochez <code>Let me select individual events.</code></li> <li>d\u00e9cochez <code>Pushes</code></li> <li>cochez <code>Workflow jobs</code></li> <li>Enfin cliquez sur Add webhooks</li> </ol> <p>Maintenant \u00e0 chaque fois que vous aurez un nouveau job GitHub, votre Azure function recevra une notification pour cr\u00e9er un runner.</p> <p>Il ne reste plus qu'\u00e0 cr\u00e9er le workflow GitHub !</p> <p>Pour indiquer que vous souhaitez un agent self-hosted vous devez pr\u00e9ciser pour vos jobs : <code>runs-on: [self-hosted]</code>. Et pour indiquer le type d'OS que vous souhaitez utiliser, il faudra ajouter un autre label : <code>ubuntu-18.04</code>, <code>ubuntu-latest</code> ou <code>windows-latest</code>.</p> <p>Par exemple :</p> <pre><code>name: Test Agent\non:\n  push:\n    branches: \n      - master\n      - main\n\njobs:\n  use-selfhosted-ubuntu1804:\n    runs-on: [self-hosted, ubuntu-18.04]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Fetch release version\n        run: |\n          echo \"Hello world !\"\n\n  use-selfhosted-ubuntu2004:\n    runs-on: [self-hosted, ubuntu-latest]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Fetch release version\n        run: |\n          echo \"Hello world !\"\n\n  use-selfhosted-windows:\n    runs-on: [self-hosted, windows-latest]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Fetch release version\n        run: |\n          echo \"Hello world !\"\n</code></pre>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#conclusion","title":"Conclusion","text":"<p>Apr\u00e8s vous avoir montr\u00e9 qu'il \u00e9tait possible de provisionner ses propres agents Azure DevOps Services dans son SI, je r\u00e9it\u00e8re ma d\u00e9monstration sur GitHub. L'usine logicielle change mais le concept fonctionne toujours.</p> <p>C'est aussi l'occasion de comparer les forces et les faiblesses de chacun.</p> <p>GitHub est incontestablement le grand vainqueur avec :</p> <ul> <li>la multitude de webhooks disponible permettant d'impl\u00e9menter des sc\u00e9narii interactifs affectant l'\u00e9cosyst\u00e8me environnant.</li> <li>l'enregistrement des runners avec un jeton temporaire qui est bien plus s\u00e9curis\u00e9 que le Personal Access Token d'Azure DevOps.</li> </ul> <p>Mais Azure DevOps n'a pas dit son dernier mot ! </p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>GitHub : Api Meta</li> <li>GitHub : Api Actions</li> <li>GitHub : Basic Authentication</li> <li>GitHub : Webhook events and payloads</li> <li>Terraform module for scalable self hosted GitHub action runners</li> </ul>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/07.github.ephemeralactionsrunner/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 21 F\u00e9vrier 2022.</p>","tags":["DevOps","GitHub","CI/CD","d\u00e9veloppement","Azure","Infra as Code","PaaS"]},{"location":"articles/tips/08.dockerhub.windowsServerCore2022/","title":"Dockerhub : Votre Actions Runner et votre Azure DevOps Agent sous Windows Server Core 2022","text":"<p>Ces derni\u00e8res semaines j'ai propos\u00e9 des solutions pour h\u00e9berger vos agents Azure DevOps et vos runners GitHub sur vos environnements au travers de conteneurs docker. Ce weekend, j'ai apport\u00e9 une petite \u00e9volution pour proposer en plus ces m\u00eames agents/runners sur Windows Server Core 2022 (aka ltsc2022).</p> <p>Voici un r\u00e9capitulatif des diff\u00e9rentes images disponible sur mon repository dockerhub :</p> Syst\u00e8me d'exploitation Version Agent install\u00e9 framework install\u00e9 image docker Ubuntu 18.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner Ubuntu 18.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-core-3.1 Ubuntu 18.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-6.0 Ubuntu 20.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner Ubuntu 20.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-core-3.1 Ubuntu 20.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-6.0 Ubuntu 18.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-18.04-azdo Ubuntu 18.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-core-3.1 Ubuntu 18.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-6.0 Ubuntu 20.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-20.04-azdo Ubuntu 20.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-core-3.1 Ubuntu 20.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-6.0 Windows Server 2019 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner Windows Server 2019 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-core-3.1 Windows Server 2019 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-6.0 Windows Server 2022 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner Windows Server 2022 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-core-3.1 Windows Server 2022 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-6.0 Windows Server 2019 Azure DevOps Agent Aucun pmorisseau/azdo-agent:windows-core-ltsc2019-azdo Windows Server 2019 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-core-3.1 Windows Server 2019 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-6.0 Windows Server 2022 Azure DevOps Agent Aucun pmorisseau/azdo-agent:windows-core-ltsc2022-azdo Windows Server 2022 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-core-3.1 Windows Server 2022 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-6.0 <p>Note</p> <p>Un traitement quotidien v\u00e9rifie la version des agents Azure DevOps et des runners Github Actions afin que les images docker embarquent syst\u00e9matiquement la derni\u00e8re version. Les images docker sont donc r\u00e9guli\u00e8rement et automatiquement mise \u00e0 jour.</p> <p>Note</p> <p>Si vous souhaitez utiliser ces images, je vous invite \u00e0 lire mes p\u00e9c\u00e9dents articles :</p> <ul> <li>Azure DevOps : Vos propres agents \u00e0 la demande dans votre SI</li> <li>GitHub : Vos propres runner \u00e0 la demande dans votre SI</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 28 F\u00e9vrier 2022.</p>","tags":["DevOps","GitHub","Azure DevOps","docker","Windows"]},{"location":"articles/tips/09.azurefunction.limitlogs/","title":"L'astuce FinOps : Limiter la verbosit\u00e9 de vos Azure Function","text":"<p>Mettre en place le monitoring de vos Azure Function est essentiel (surtout pour vos applications en production). Mais il arrive que celles-ci produisent beaucoup plus de logs que n\u00e9cessaire. Dans ce cas, vous pouvez avoir un impact financier non n\u00e9gligeable sur Application Insights/Log Analytics. Voici quelques astuces pour limiter cela.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"articles/tips/09.azurefunction.limitlogs/#monitorer-les-volumes-de-logs","title":"Monitorer les volumes de logs","text":"<p>Afin de comprendre pourquoi vos co\u00fbts d'ingestion de logs explosent sur Application Insights/Log Analytics, il faut identifier les types de logs les plus pr\u00e9sents. Depuis Log Analytics ex\u00e9cutez la requ\u00eate Kusto suivante :</p> <pre><code>union *\n| where timestamp &gt; ago(7d)\n| summarize sum(_BilledSize) by itemType\n| render piechart \n</code></pre> <p>Cette requ\u00eate vous g\u00e9n\u00e8re un graphique camembert avec la r\u00e9partition du volume de logs facturable par type de logs.</p> <p></p> <p>Dans cet exemple, on constate que les logs de type <code>trace</code> repr\u00e9sentent plus de 74% du volume de logs facturable. </p> <p>Concentrons-nous sur ces logs <code>trace</code> pour identifier maintenant quelles sont les sources qui produisent le plus de volume. Peut-\u00eatre qu'une application en particulier g\u00e9n\u00e8re trop de logs. Depuis Log Analytics ex\u00e9cutez maintenant la requ\u00eate Kusto suivante :</p> <pre><code>traces\n| where timestamp &gt; ago(7d)\n| summarize sum(_BilledSize) by cloud_RoleName\n| render piechart\n</code></pre> <p></p> <p>Dans l'exemple ci-dessus, on constate que les sources de nos logs sont vari\u00e9es et plut\u00f4t reparties. Ce n'est pas toujours la bonne piste !</p> <p>Si ce n'est pas l'une des sources l'origine de notre volume de logs peut-\u00eatre que c'est une librairie, un SDK utilis\u00e9 par nos Azure Function qui est la source de nos malheurs. </p> <p>Note</p> <p>Le runtime des Azure Function classe les logs par <code>category</code>. Ces <code>category</code> sont accessibles dans les <code>customDimensions</code> des logs <code>trace</code>.  </p> <p>On va pour cela ex\u00e9cuter la requ\u00eate Kusto suivante :</p> <pre><code>traces\n| where timestamp &gt; ago(7d)\n| summarize sum(_BilledSize) by tostring(customDimensions.Category)\n| render piechart \n</code></pre> <p></p> <p>Dans l'exemple ci-dessus il apparait que la cat\u00e9gorie <code>Azure.Messaging.ServiceBus</code> repr\u00e9sente 62% du volume de logs <code>trace</code>. Ramen\u00e9 au volume total des logs cela repr\u00e9sente : 46,5 %.</p> <p>Maintenant que nous avons identifi\u00e9 notre origine. Il faut s'assurer de la pertinence des logs. Peut-\u00eatre que ces logs sont n\u00e9cessaires ? Une simple exploration des logs sur les 30 derni\u00e8res minutes (ou plus cela depend de votre contexte) permet d'analyser rapidement les logs :</p> <pre><code>traces\n| where timestamp &gt; ago(30m) and customDimensions.Category == \"Azure.Messaging.ServiceBus\"\n</code></pre> <p></p> <p>On constate dans notre cas que ce sont des logs permettant de tracer les envois et r\u00e9ceptions de message vers et depuis Azure ServiceBus.</p> <p>Nous consid\u00e9rons que ces logs ne sont pas pertinents (simple hypoth\u00e8se, ce n'est pas une g\u00e9n\u00e9ralit\u00e9). Ces logs peuvent \u00eatre retir\u00e9s de l'ingestion d'Azure Application Insights/Log Analytics. Mais avant d'intervenir il faut v\u00e9rifier la r\u00e9partition de ces logs par niveau de s\u00e9v\u00e9rit\u00e9.</p> <p>Pour cela, la requ\u00eate Kusto suivante va nous aider :</p> <pre><code>traces\n| where timestamp &gt; ago(30m) and customDimensions.Category == \"Azure.Messaging.ServiceBus\"\n| summarize count() by tostring(customDimensions.LogLevel)\n| render piechart \n</code></pre> <p></p> <p>On constate que 99% des logs sont du niveau de s\u00e9v\u00e9rit\u00e9 <code>Information</code>.</p> <p>Ce processus d'analyse montre qu'une simple rem\u00e9diation au niveau de la configuration des Azure Function va permettre de r\u00e9duire de 46% le volume de logs. Cette rem\u00e9diation consiste \u00e0 monter le niveau de verbosit\u00e9 \u00e0 <code>Warning</code> pour les logs de la cat\u00e9gorie <code>Azure.Messaging.ServiceBus</code>.  </p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"articles/tips/09.azurefunction.limitlogs/#remediation-au-niveau-des-azure-function","title":"Rem\u00e9diation au niveau des Azure Function","text":"<p>Je ne vais pas vous expliquer comment configurer votre Azure function pour qu'elle puisse envoyer ses logs dans Application Insights. Cet article de Microsoft l'explique tr\u00e8s bien.</p> <p>En revanche, ce que cette documentation n'explique pas bien, c'est que la liste des cat\u00e9gories d\u00e9crite ici n'est pas exhaustive.</p> <p>En effet, l'ensemble des cat\u00e9gories pr\u00e9c\u00e9demment identifi\u00e9es durant l'analyse peuvent \u00eatre configur\u00e9es.</p> <p>Pour monter le niveau de verbosit\u00e9 \u00e0 <code>Warning</code> pour les logs de la cat\u00e9gorie <code>Azure.Messaging.ServiceBus</code>, il suffit de modifier le fichier <code>host.json</code> en ajoutant <code>\"Azure.Messaging.ServiceBus\": \"Warning\"</code>.</p> <p>On aura un fichier qui ressemblera \u00e0 cela :</p> <pre><code>{\n  \"logging\": {\n    \"logLevel\": {\n      \"default\": \"Information\",\n      \"Azure.Messaging.ServiceBus\": \"Warning\"\n    }\n  }\n}\n</code></pre> <p>Et c'est tout !</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"articles/tips/09.azurefunction.limitlogs/#conclusion","title":"Conclusion","text":"<p>Il est important de prendre le temps d'analyser la nature des logs. Les services Application Insights et Log Ananlytics offrent d'excellents moyens d'analyse et de recherche. Dans une d\u00e9marche FinOps, ils peuvent s'av\u00e9rer \u00eatre des outils tr\u00e8s pratiques. En effet, au travers de cet exemple j'ai r\u00e9ussi \u00e0 r\u00e9duire de 46% le volume de logs ing\u00e9r\u00e9s par Application Insights/Log Ananlytics. Dans l'hypoth\u00e8se o\u00f9 nous avions 10 Go de logs ing\u00e9r\u00e9s par jour (sur la r\u00e9gion France Central), cela reviendrait \u00e0 une \u00e9conomie de 350 \u20ac par mois.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"articles/tips/09.azurefunction.limitlogs/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Microsoft : Comment configurer l\u2019analyse pour Azure Functions</li> <li>azure-sdk-for-net - issue : [QUERY] Service bus telemetry seems excessive</li> </ul>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"articles/tips/09.azurefunction.limitlogs/#remerciements","title":"Remerciements","text":"<ul> <li>Nicolas Bregent : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> <li>Etienne Louise : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 27 Juin 2022.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"articles/tips/10.dockerhub.ubuntu22.04/","title":"Votre agent Azure DevOps et votre runner Github avec Jammy la m\u00e9duse.","text":"<p>Apr\u00e8s plusieurs semaines de repos, j'ai d\u00e9cid\u00e9 d'apporter une nouvelle petite contribution en proposant les images des agents Azure DevOps et les runners GitHub sur la derni\u00e8re distribution LTS de l'OS Ubuntu : Ubuntu 22.04 (Jammy Jellyfish).</p> <p>Contraitement aux pr\u00e9c\u00e9dentes versions Microsoft ne propose pas le SDK du .net core 3.1 sur Ubuntu 22.04. Je n'ai donc cr\u00e9\u00e9 les images qu'avec le SDK .net 6.0.  Aussi, j'en ai profit\u00e9 pour mettre \u00e0 niveau les 2 SDK (.net core 3.1 et .net 6.0) afin d'embarquer les derniers correctifs. A savoir :</p> <ul> <li>Pour .NET 6 la version 6.0.8</li> <li>Pour .NET core 3.1 la version 3.1.28</li> </ul> <p></p> <p>Voici un r\u00e9capitulatif des diff\u00e9rentes images disponible sur mon repository dockerhub :</p> Syst\u00e8me d'exploitation Version Agent install\u00e9 framework install\u00e9 image docker Ubuntu 18.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner Ubuntu 18.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-core-3.1 Ubuntu 18.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-6.0 Ubuntu 20.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner Ubuntu 20.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-core-3.1 Ubuntu 20.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-6.0 Ubuntu 18.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-18.04-azdo Ubuntu 18.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-core-3.1 Ubuntu 18.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-6.0 Ubuntu 20.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-20.04-azdo Ubuntu 20.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-core-3.1 Ubuntu 20.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-6.0 Windows Server 2019 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner Windows Server 2019 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-core-3.1 Windows Server 2019 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-6.0 Windows Server 2022 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner Windows Server 2022 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-core-3.1 Windows Server 2022 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-6.0 Windows Server 2019 Azure DevOps Agent Aucun pmorisseau/azdo-agent:windows-core-ltsc2019-azdo Windows Server 2019 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-core-3.1 Windows Server 2019 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-6.0 Windows Server 2022 Azure DevOps Agent Aucun pmorisseau/azdo-agent:windows-core-ltsc2022-azdo Windows Server 2022 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-core-3.1 Windows Server 2022 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-6.0 Ubuntu 22.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-22.04-actionsrunner Ubuntu 22.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-22.04-actionsrunner-dotnet-6.0 Ubuntu 22.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-22.04-azdo Ubuntu 22.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-22.04-azdo-dotnet-6.0 <p>Dans le cas des agents Azure DevOps, j'ai d\u00fb \"bricoler\". En effet, avec la version 22.04 (bas\u00e9 sur la debian 11), les sources des packages officiels ne proposent plus que OpenSSL v3. Hors, pour fonctionner, les agents Azure DevOps ont toujours besoin d'OpenSSL v1.1. J'ai donc install\u00e9 \"manuellement\" OpenSSL v1.1 lors de la cr\u00e9ation de l'image. Si vous voulez en savoir plus, un ticket sur le Github de Microsoft est actuellement ouvert.</p> <p>Note</p> <p>Un traitement quotidien v\u00e9rifie la version des agents Azure DevOps et des runners Github Actions afin que les images docker embarquent syst\u00e9matiquement la derni\u00e8re version. Les images docker sont donc r\u00e9guli\u00e8rement et automatiquement mise \u00e0 jour.</p> <p>Note</p> <p>Si vous souhaitez utiliser ces images, je vous invite \u00e0 lire mes p\u00e9c\u00e9dents articles :</p> <ul> <li>Azure DevOps : Vos propres agents \u00e0 la demande dans votre SI</li> <li>GitHub : Vos propres runner \u00e0 la demande dans votre SI</li> </ul>","tags":["DevOps","GitHub","Azure DevOps","docker","Linux"]},{"location":"articles/tips/10.dockerhub.ubuntu22.04/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>[VSTS Agent] Unable to install vsts agent on Ubuntu Server 22.04 LTS </li> <li>Fix installation on aarch64 / Ubuntu 22.04</li> <li>Distributions prises en charge</li> <li>Download .NET Core 3.1</li> <li>Download .NET 6.0</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 23 Aout 2022.</p>","tags":["DevOps","GitHub","Azure DevOps","docker","Linux"]},{"location":"en/about/","title":"About","text":"<p>This blog aims to share my experiences around the Azure cloud and DevOps.</p>"},{"location":"en/about/#biography","title":"Biography","text":"<p>Co-manager of the Microsoft center of excellence in the Atlantic community of onepoint, I coordinate a team of specialists on Microsoft technologies but not only...</p> <p>We bring our expertise and support to our clients on the following topics:</p> <ul> <li>DevOps with Azure DevOps,</li> <li>Cloud with Azure,</li> <li>Modern Workspace with Microsoft 365,</li> <li>Data.</li> </ul> <p>We also design and produce innovative application solutions around the cloud, DevOps, collaboration and data.</p> <p>With more than 15 years of experience, myself, I bring my knowledge on:</p> <ul> <li>the Azure Cloud architecture,</li> <li>FinOps Azure expertise,</li> <li>DevOps expertise,</li> <li>Data architecture (ETL, Datahub),</li> <li>the design and development of heavy client and web .net applications,</li> <li>the agility,</li> <li>lean and</li> <li>operation of OnPremise infrastructure.</li> </ul> <p>I share my knowledge through various training courses around the Azure cloud and DevOps.</p> <p>Finally, i'm very proud to be recognized by Microsoft as a MVP (Most Valuable Professional).</p>"},{"location":"en/about/#my-certifications","title":"My certifications","text":""},{"location":"en/about/#mes-talks","title":"Mes Talks","text":"<p>Coming :</p> <ul> <li>DevOpsDays Geneva (le 24-25 avril 2023) : Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> </ul> <p>Past :</p> <ul> <li>AgiLeMans (le 2 f\u00e9vrier 2023) : Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> <li>Touraine Tech (du 19 au 20 Janvier 2023) : Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> <li>Agile Tour Grenoble (du 23 au 25 Novembre 2022) :  Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite.</li> <li>Agile Tour Grenoble (du 23 au 25 Novembre 2022) :  Au secours, le DevOps part en vrille !</li> <li>Devfest Strasbourg (18 Novembre 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>Agile Tour Nantes (3 Novembre 2022) : Et PAF, encore un PoC ! ... qu'on pousse en prod. \ud83d\ude44</li> <li>Agile Tour Montpellier (le 17 Octobre 2022) :  Le DevOps expliqu\u00e9 \u00e0 mon p\u00e8re, agriculteur \u00e0 la retraite. replay</li> <li>Volcamp (les 13 et 14 Octobre 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?!</li> <li>Breizhcamp (1er Juillet 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>Sunny Tech (30 Juin 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>Meetup onepoint (22 Juin 2022) : Au secours, le DevOps part en vrille !</li> <li>Azug Nantes (31 Mai 2022) : Pourquoi j\u2019ai mal \u00e0 la t\u00eate lorsqu\u2019il faut mettre en place l\u2019isolation r\u00e9seau avec Azure ?</li> <li>Cloud Sud 2022 (24 Mars 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?!</li> <li>Inauguration / 20 ans onepoint (17 Mars 2022) : Au secours, le DevOps part en vrille !</li> <li>France DevOps (08 Mars 2022) : GitOps, Continuous Delivery et environnements : Comment \u00e9viter l'enfer ?! replay</li> <li>SnowCamp 2022 (du 02 au 04 F\u00e9vrier 2022) : Un datahub dans Azure, Retour d'exp\u00e9rience sur les services manag\u00e9s</li> <li>Azug Nantes (24 Janvier 2022) : Azure Batch, le mal-aim\u00e9 ! replay</li> <li>Agile Tour Rennes 2021 : Au secours, le DevOps part en vrille !</li> <li>Agile Tour Paris 2021 : Au secours, le DevOps part en vrille !</li> <li>Agile Tour Montpellier 2021 : Au secours, le DevOps part en vrille ! replay</li> <li>CloudEst 2021 : Un datahub dans Azure, Retour d'exp\u00e9rience sur les services manag\u00e9s</li> <li>TADx 2021 (Novembre 2021) : Au secours, le DevOps part en vrille ! replay</li> <li>France DevOps (Juillet 2021) : Au secours, le DevOps part en vrille ! replay</li> <li>CloudOuest 2021 : Un datahub dans Azure, Retour d'exp\u00e9rience sur les services manag\u00e9s</li> <li>ReBuild 2019 (Nantes) - REX Services Manag\u00e9s Azure (Talk)</li> <li>MS Experience 2018 (Paris) - G\u00c9RER SON PARC CLOUD AVEC AZURE DEVOPS (Quickie)</li> <li>ReBuild 2018 (Nantes) - G\u00c9RER SON PARC CLOUD AVEC AZURE DEVOPS (Talk)</li> </ul>"},{"location":"en/about/#follow-me-or-react","title":"Follow me or react !","text":"<ul> <li>LinkedIn</li> <li>Twitter</li> </ul>"},{"location":"en/articles/assatbac/ep01/","title":"Private Endpoint","text":"<p>It's been several months since I've published articles. Indeed, I have been very busy. But, I had an idea that was in my head for several weeks. After a while, I started it!</p> <p>And here is the result...</p> <p>This is the first episode of a long (I hope) series. I was directly inspired by the blogs I had the pleasure to browse a few years ago (Marion Montaigne's and the LHC's).</p> <p>I present you Professor Somlinton !</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","virtual network","architecture"]},{"location":"en/articles/assatbac/ep01/#references","title":"References","text":"<ul> <li>What is a private endpoint?</li> <li>Tu mourras moins b\u00eate (blog of Marion Montaigne)</li> <li>LHC-France (The LHC comic book)</li> <li>Ray Tomlinson (One of the internet daddies, source of inspiration for the narrator)</li> </ul>","tags":["Azure","virtual network","architecture"]},{"location":"en/articles/assatbac/ep01/#thanks","title":"Thanks","text":"<ul> <li>Jean-Philippe SENON : for the proofreading</li> <li>Samy Mameri : for the proofreading</li> <li>Michael Maillot : for the proofreading</li> <li>Charlie Bethuys : for the proofreading</li> <li>Stephane Deloison : for the proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on February 11, 2023.</p>","tags":["Azure","virtual network","architecture"]},{"location":"en/articles/assatbac/ep02/","title":"Private Endpoint VS Vnet Integration","text":"<p>Today Professor Somlinton explains the difference between private-endpoint and vnet integration!</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","virtual network","architecture"]},{"location":"en/articles/assatbac/ep02/#references","title":"References","text":"<ul> <li>What is a private endpoint?</li> <li>Tu mourras moins b\u00eate (blog of Marion Montaigne)</li> <li>LHC-France (The LHC comic book)</li> <li>Ray Tomlinson (One of the internet daddies, source of inspiration for the narrator)</li> </ul>","tags":["Azure","virtual network","architecture"]},{"location":"en/articles/assatbac/ep02/#thanks","title":"Thanks","text":"<ul> <li>Etienne Louise : for the proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on February 20, 2023.</p>","tags":["Azure","virtual network","architecture"]},{"location":"en/articles/assatbac/ep03/","title":"SPN, SMI et UMI","text":"<p>Today Professor Somlinton explains the difference between the service principal name, the system-assigned managed identity and the user-assigned managed identity!</p> <p>Please note that Tony Parker's activities at Villard-de-Lans are pure fiction and serve only to explain the point.</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","Active Directory","Identit\u00e9"]},{"location":"en/articles/assatbac/ep03/#references","title":"References","text":"<ul> <li>What are managed identities for Azure resources?</li> <li>Application and service principal objects in Azure Active Directory</li> </ul>","tags":["Azure","Active Directory","Identit\u00e9"]},{"location":"en/articles/assatbac/ep03/#thanks","title":"Thanks","text":"<ul> <li>Stephane Deloison : for the proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on March 13, 2023.</p>","tags":["Azure","Active Directory","Identit\u00e9"]},{"location":"en/articles/assatbac/ep04/","title":"Cosmos DB, it's like Morag's orb","text":"<p>Today Professor Somlinton reassures you about using Cosmos DB, one of the most powerful services in Azure.</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>","tags":["Azure","Cosmos DB","FinOps"]},{"location":"en/articles/assatbac/ep04/#references","title":"References","text":"<ul> <li>Request Units in Azure Cosmos DB</li> <li>Introduction to provisioned throughput in Azure Cosmos DB</li> <li>Create Azure Cosmos DB containers and databases with autoscale throughput</li> <li>Azure Cosmos DB serverless</li> </ul>","tags":["Azure","Cosmos DB","FinOps"]},{"location":"en/articles/assatbac/ep04/#thanks","title":"Thanks","text":"<ul> <li>Jean-Philippe SENON : for the proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on March 27, 2023.</p>","tags":["Azure","Cosmos DB","FinOps"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/","title":"Private Endpoint, Service Endpoint, Dedicated Service, Service Tags & Firewall","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Il m'arrive r\u00e9guli\u00e8rement de constater que les clients utilisant Azure sont un peu perdu lorsqu'il s'agit de mettre en place la s\u00e9curisation r\u00e9seau de leurs services manag\u00e9s. Et j'avoue qu'ils n'ont pas tort. Devant les nombreuses possibilit\u00e9s et exceptions propos\u00e9es par le cloud de Microsoft, comment ne pas \u00eatre paum\u00e9 !</p> <p>Je vous propose un petit cours de rattrapage sur le sujet de l'isolation r\u00e9seau des services manag\u00e9s Azure.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#private-endpoint-private-link","title":"Private Endpoint &amp; Private Link","text":"<p>Le m\u00e9canisme de Private Endpoint / Private Link peut s'apparenter \u00e0 celui d'un VPN. Il faut imaginer que cela est comparable \u00e0 votre client VPN que vous lancez lorsque vous \u00eates en t\u00e9l\u00e9-travail pour vous connecter sur le r\u00e9seau de votre employeur. Lorsque vous vous authentifiez sur votre logiciel VPN, votre carte r\u00e9seau virtuelle s'active et vous donne une adresse IP priv\u00e9e du r\u00e9seau de votre employeur. Sur Azure, vous pouvez comparer le Private Endpoint \u00e0 la carte r\u00e9seau virtuelle et votre Private Link au logiciel client-serveur VPN.</p> <p></p> <p>Concr\u00e8tement sur Azure, avec Private Endpoint / Private Link, vous allez pouvoir attribuer \u00e0 votre service manag\u00e9 une adresse IP priv\u00e9e dans le subnet de votre choix. Et vous allez pouvoir ainsi interagir avec votre service azure tout en restant d'un point de vue r\u00e9seau dans votre Virtual Network. Mais, cela n'est g\u00e9n\u00e9ralement pas suffisant si vous souhaitez prot\u00e9ger votre service manag\u00e9 de l'exterieur. Mettre en place un Private Endpoint ne limite pas l'acc\u00e8s de votre ressource \u00e0 votre subnet.</p> <p></p> <p>Dans l'exemple ci-dessus on constate que notre Event Hubs A bien qu'il ait un Private Endpoint dans le Subnet A est accessible depuis le Subnet B et internet.</p> <p>Si on souhaite restreindre son acc\u00e8s, il va falloir mettre en place des r\u00e8gles firewall.  Dans le cas d'un Private Endpoint / Private Link, la r\u00e8gle est tr\u00e8s simple :  <pre><code>Deny : All\n</code></pre></p> <p>En effet, il faut savoir que les r\u00e8gles firewall au niveau du service manag\u00e9 ne s'appliquent pas au Private Endpoint. </p> <p></p> <p>Avec cette r\u00e8gle firewall vous bloquez ainsi tous les autres acc\u00e8s possibles \u00e0 votre service manag\u00e9.</p> <p>Note</p> <p>Vous ne pouvez pas appliquer de r\u00e8gle firewall \u00e0 votre Private Endpoint en associant un Network Security Group \u00e0 la Network Interface li\u00e9 \u00e0 votre Private Endpoint.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#service-endpoint","title":"Service Endpoint","text":"<p>Le m\u00e9canisme de Service Endpoint vous permet d'acceder depuis votre Subnet via le backbone Azure \u00e0 vos services manag\u00e9s sans jamais passer par internet. En gros, Microsoft vous garanti que la communication restera interne au cloud Azure.</p> <p></p> <p>Dans l'exemple ci-dessus, en activant le Service Endpoint Microsoft.Storage sur le Subnet A, on s'assure que la communication passera uniquement sur le backbone Azure pour atteindre la ressource Storage Account A.</p> <p>Encore une fois, cela n'est pas suffisant si vous souhaitez isoler votre service manag\u00e9.</p> <ul> <li>Premi\u00e8rement, le Service Endpoint vous permet un acc\u00e8s s\u00e9curis\u00e9 via le backbone Azure \u00e0 l'ensemble des instances du service manag\u00e9 en question (Par exemple : l'ensemble des Storage Account). </li> <li>Ensuite, tout comme le Private Endpoint, cela ne limite pas l'acc\u00e8s de votre ressource \u00e0 un unique subnet. </li> </ul> <p></p> <p>S'il on souhaite isoler notre service manag\u00e9, il va falloir mettre en places des r\u00e8gles firewall.  Dans le cas d'un Service Endpoint, la r\u00e8gle est plut\u00f4t simple :  <pre><code>Allow : [Votre Subnet]\nDeny : All\n</code></pre></p> <p></p> <p>Dans l'exemple ci-dessus, nous avons uniquement autoris\u00e9 le Subnet A sur le Storage Account A et le Subnet B sur le Storage Account B.</p> <p>Attention, si votre service manag\u00e9 doit contacter une de vos ressources de votre Virtual Network, il le fera avec une adresse IP public. Ce qui vous obligera \u00e0 autoriser l'inbound trafic depuis une IP public.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#dedicated-service","title":"Dedicated service","text":"<p>Le m\u00e9canisme de Dedicated service consiste \u00e0 injecter dans un subnet un service manag\u00e9.</p> <p></p> <p>Par ce m\u00e9canisme, au moment de l'instanciation du service manag\u00e9, une adresse IP priv\u00e9e du subnet lui sera affect\u00e9. Ainsi, vous pouvez appeler ou \u00eatre appel\u00e9 par votre service manag\u00e9 avec une adresse IP priv\u00e9e et sans avoir recours \u00e0 l'utilisation d'un Private Endpoint / Private Link. L'exemple le plus connu sur Azure est la fonctionnalit\u00e9 Vnet integration de l'Application Service (Web App, Function App).</p> <p>Note</p> <p>Contrairement au Private Endpoint, vous n'aurez pas une adresse IP priv\u00e9e fixe.</p> <p></p> <p>Encore une fois, l'utilisation de Dedicated service n'implique pas que votre service ne sera pas joignable depuis internet ou un autre Virtual Network et ne pourra pas joindre un autre service en dehors de votre Virtual Network (Comme le montre le sch\u00e9ma ci-dessus). Il faudra mettre en place des r\u00e8gles firewall. La r\u00e8gle est plut\u00f4t simple :  <pre><code>Allow : [Votre Subnet]\nDeny : All\n</code></pre></p> <p></p> <p>Dans l'exemple ci-dessus, nous avons uniquement autoris\u00e9 le Subnet A1 sur la Web App A et le Subnet B1 sur le Web App B.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#service-tag","title":"Service Tag","text":"<p>Ce m\u00e9canisme permet de simplifier les r\u00e8gles firewall en apposant des \u00e9tiquettes sur des types de services manag\u00e9s et des r\u00e9gions azure. Imaginons que vous souhaitez bloquer tout le trafic sortant depuis votre Subnet sauf celui \u00e0 destination de votre storage account : Vous avez mis en place un Service Endpoint Microsoft.Storage. Pour r\u00e9aliser cela vous allez cr\u00e9er un Network Security Group dans lequel vous allez bloquer le trafic vers internet et autoriser le trafic vers tous les storage account, puis associer votre Network Security Group \u00e0 votre subnet.</p> <p></p> <p>Ci-dessous un exemple de configuration du Network Security Group :</p> <p></p> <p>Les Service Tag peuvent aussi \u00eatre utilis\u00e9 dans les r\u00e8gles firewall de nombreux services manag\u00e9s azure (Web App, Function App, ...)</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#conclusion","title":"Conclusion","text":"<p>L'utilisation du Private Endpoint / Private Link :</p> <ul> <li>est l\u00e9g\u00e8rement complexe \u00e0 mettre en place, </li> <li>est relativement \u00e9conomique (\u00e0 partir de 6,57 \u20ac / mois).</li> <li>est recommand\u00e9 en cas d'inbound/outbound trafic : De votre Virtual Network vers ou \u00e0 destination de votre service manag\u00e9.</li> </ul> <p>L'utilisation du Service Endpoint :</p> <ul> <li>est simple \u00e0 mettre en place, </li> <li>n'implique pas de frais suppl\u00e9mentaires.</li> <li>est recommand\u00e9 uniquement en cas d'outbound trafic : De votre Virtual Network vers votre service manag\u00e9.</li> </ul> <p>L'utilisation du Dedicated service :</p> <ul> <li>est simple \u00e0 mettre en place, </li> <li>est parfois on\u00e9reux (Application Service Environment, Integration Service Environnement, ...). </li> <li>est recommand\u00e9 en cas d'inbound/outbound trafic : De votre Virtual Network vers ou \u00e0 destination de votre service manag\u00e9.</li> </ul> <p>Comme vous pouvez le constatez chaque fonctionnalit\u00e9 de s\u00e9curisation r\u00e9seau a son utilit\u00e9. Et vous pouvez tr\u00e8s bien mixer celles-ci pour obtenir le niveau de s\u00e9curit\u00e9 souhait\u00e9.</p> <p></p> <p>Ci-dessus un exemple d'application web recevant des \u00e9v\u00e8nements provenant d'un event grid et stockant ceux-ci dans un Storage Account.</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Int\u00e9grer des services Azure \u00e0 des r\u00e9seaux virtuels pour l\u2019isolement r\u00e9seau</li> <li>Configurer des restrictions d\u2019acc\u00e8s dans Azure App Service</li> <li>Configurer des pare-feux et des r\u00e9seaux virtuels dans Stockage Azure</li> </ul>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/01.azureClassroom.VnetEndpointFirewall/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>David Dubourg : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Quentin Joseph : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 13 Septembre 2021</p>","tags":["Azure","virtual network","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/","title":"Azure Batch, le mal-aim\u00e9","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Avec l'\u00e9mergence des services manag\u00e9s de cloud-computing moderne propos\u00e9s sur Azure : AKS, ARO, Databricks,... et maintenant Azure Container Apps. On finit par oublier les anciens... L'un des services que Microsoft ne met plus vraiment en avant depuis un certain temps mais qui pour moi est digne d'int\u00e9r\u00eat est Azure Batch.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#azure-batch-cest-quoi","title":"Azure Batch : C'est quoi ?","text":"<p>Azure Batch est un service propos\u00e9 par Microsoft permettant d'ex\u00e9cuter des traitements sur une machine virtuelle. Vous pouvez choisir la puissance de calcul (la taille de la VM), mais aussi choisir entre Windows et Linux (ubuntu, debian, centOS,...).</p> <p>Et ce n'est pas tout ! </p> <p>Il propose aussi nativement :</p> <ul> <li>un service de scalabilit\u00e9 horizontal que vous pourrez customiser,</li> <li>un service de VM low-priority, qui vous permettra de diviser par 4 les co\u00fbts par rapport \u00e0 une VM classique,</li> <li>un gestionnaire de packages d'applications (Artefacts),</li> <li>un gestionnaire de t\u00e2ches avec l'historique des ex\u00e9cutions,</li> <li>un planificateur de t\u00e2ches,</li> <li>la possibilit\u00e9 d'int\u00e9grer les machines virtuelles dans un Virtual Network,</li> <li>la possibilit\u00e9 de charger les variables d'environnement depuis Azure KeyVault,</li> <li>la possibilit\u00e9 d'ex\u00e9cuter des conteneurs Windows et Linux.</li> </ul> <p>Et le mieux, c'est que ce service est GRATUIT ! Seules les machines virtuelles utilis\u00e9es sont payantes.</p> <p>Mais, dans quel cas j'aurais besoin d'Azure Batch ?</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#les-cas-dutilisation","title":"Les cas d'utilisation","text":"<p>Si vous pr\u00e9parez l'examen de certification Azure Architect vous avez d\u00fb tomber sur la question : \"Dans quel cas utiliser Azure Batch ?\"</p> <p>Microsoft indique dans sa documentation que ce service permet d'ex\u00e9cuter des traitements par lot de calculs haute performance. Pour le traitement d'image, de vid\u00e9o, de mod\u00e9lisation ou de projection complexe, par exemple.</p> <p>De mon point de vue, c'est un peu r\u00e9ducteur. Pour l'utiliser depuis des ann\u00e9es, ce service permet des usages beaucoup plus communs comme :</p> <ul> <li>l'ex\u00e9cution d'agents de build ou de d\u00e9ploiement \u00e9ph\u00e9m\u00e8re,</li> <li>le traitement d'op\u00e9rations sur des donn\u00e9es m\u00e9tier en mode batch.</li> </ul> <p>Pour faire simple, si vous avez des traitements d'une dur\u00e9e de plusieurs minutes et que vous n'avez pas forc\u00e9ment de contraintes de temps de r\u00e9ponse, vous pouvez envisager Azure Batch comme une solution.</p> <p>Je vous propose de nous focaliser sur un cas d'utilisation : les agents \u00e9ph\u00e9m\u00e8res.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#les-agents-ephemeres","title":"Les agents \u00e9ph\u00e9m\u00e8res","text":"<p>Si vous utilisez Azure DevOps Services (ou Github Entreprise), vous avez la possibilit\u00e9 de provisionner des agents Microsoft Hosted. Ces agents sont h\u00e9berg\u00e9s par Microsoft et sont disponibles \u00e0 la demande pour chaque Job. Et pour chaque Job, un agent \"tout propre\" est mis \u00e0 disposition. </p> <p>Ce m\u00e9canisme vous permet de r\u00e9aliser vos builds et vos d\u00e9ploiements sans induire de biais li\u00e9s \u00e0 l'environnement de l'agent (logiciels, variables d'environnement, reliquats d'un pr\u00e9c\u00e9dent builds, ...).</p> <p>L'inconv\u00e9nient majeur, c'est que celui-ci s'ex\u00e9cute sur le r\u00e9seau de Microsoft. Si vous souhaitez d\u00e9ployer une application dans votre SI isol\u00e9 d'un point de vue r\u00e9seau, vous devez autoriser les plages d'IP publiques utilis\u00e9es par Microsoft pour ces agents. Autant dire que votre RSSI (Responsable de la S\u00e9curit\u00e9 du Syst\u00e8me d'Information) ne vous le permettra jamais !</p> <p>Azure Batch peut vous permettre de r\u00e9soudre cet inconv\u00e9nient majeur.</p> <p>Note</p> <p>L'utilisation du service Azure Container Instance aurait pu \u00eatre un bonne solution. Mais certaines limitations au niveau de l'interconnexion avec Azure Registry l'emp\u00e8che de r\u00e9pondre pleinement au besoin d'isolation r\u00e9seau des d'agents \u00e9ph\u00e9m\u00e8res. </p> <p>Cf. Azure Container Registry et Azure Container Instance dans votre Vnet </p> <p>Pour cela, il nous faudra :</p> <ul> <li>Le service Azure Batch,</li> <li>Un pool de n\u0153uds Windows Server 2019 with container (pour les builds windows),</li> <li>Un pool de n\u0153uds Ubuntu Server with container (pour les builds linux), </li> <li>Un Virtual Network avec un subnet d\u00e9di\u00e9 \u00e0 nos 2 pools d'agents,</li> <li>Le service Azure Storage Queue pour transmettre les instructions de cr\u00e9ation d'agents,</li> <li>Le service Azure Container Registry pour h\u00e9berger les images utilis\u00e9es pour instancier les agents,</li> <li>Le service Azure Function pour d\u00e9clencher la cr\u00e9ation des agents,</li> <li>La solution Azure DevOps Services pour d\u00e9clencher les t\u00e2ches de build. </li> </ul> <p>L'architecture applicative est la suivante :</p> <p></p> <ul> <li>L'Azure Container Registery et l'Azure Batch Account sont restreints au r\u00e9seau Virtual network A via l'utilisation de private endpoint. </li> <li>L'Azure Function utilise le m\u00e9canisme de Vnet int\u00e9gration afin d'\u00eatre visible dans le Virtual network A (Il faut aussi penser \u00e0 mettre en place les r\u00e8gles firewall pour restreindre l'acc\u00e8s au Virtual network A uniquement).</li> <li>Les pools de n\u0153uds (Windows et Ubuntu) ex\u00e9cutent les machines virtuels dans le Virtual network A.</li> <li> <p>Pour \u00e9viter un flux entrant depuis Azure DevOps (sur internet) et notre Azure Function (isol\u00e9e), nous utilisons le service Azure Storage Queue en ayant pris soin de mettre en place les r\u00e8gles firewall afin de limiter l'acc\u00e8s : </p> </li> <li> <p>au Virtual network A pour l'Azure Function,</p> </li> <li>aux plages d'IP publiques d'Azure DevOps.</li> </ul> <p>Ainsi avec cette architecture nous limitons l'accessibilit\u00e9 des agents Azure DevOps \u00e0 :</p> <ul> <li>un flux sortant depuis l'Azure Function vers une Storage Queue (qui fera office de passe-plat)</li> <li>un flux sortant depuis les agents Azure DevOps (obligatoire \u00e0 minima pour enregistrer l'agent).</li> </ul> <p>Concr\u00e8tement voici le s\u00e9quencement qui va se produire pour la mise \u00e0 disposition d'un agent \u00e9ph\u00e9m\u00e8re :</p> <p></p> <ol> <li>La t\u00e2che agentless \"Invoke REST API\" du pipeline de build/deploiement Azure DevOps envoie un message dans la Storage Queue A pour demander un agent \u00e9ph\u00e9m\u00e8re,</li> <li>L'Azure Function consomme la file d'attente de la Storage Queue A,</li> <li>Pour chaque message, l'Azure Function cr\u00e9e une t\u00e2che dans Azure Batch Account,</li> <li>L'Azure Batch Account traite les t\u00e2ches et affecte la t\u00e2che au bon pool de n\u0153uds,</li> <li>Le pool de n\u0153uds instancie un conteneur \u00e0 partir de l'image pr\u00e9sente dans l'Azure Container Registry,</li> <li>Une fois le conteneur instanci\u00e9 et d\u00e9marr\u00e9, celui-ci s'enregistre aupr\u00e8s d'Azure DevOps pour faire savoir qu'il est disponible. Azure DevOps lui affecte alors un job en attente. </li> <li>Le job Azure DevOps s'ex\u00e9cute dans le Virtual Network A et peut communiquer avec le r\u00e9seau On Premise.</li> </ol> <p>Dans ce cas d'utilisation, on peut tr\u00e8s facilement utiliser la fonctionnalit\u00e9 des VM low-priority et ainsi r\u00e9duire au maximum les co\u00fbts de run de nos agents Azure DevOps. Il s'av\u00e9rera difficile de trouver une solution moins on\u00e9reuse et aussi s\u00e9curis\u00e9e.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#les-fonctionnalites","title":"Les fonctionnalit\u00e9s","text":"<p>Maintenant, voyons en d\u00e9tail les fonctionnalit\u00e9s d'Azure Batch.</p> <p></p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#le-gestionnaire-de-pool","title":"Le gestionnaire de pool","text":"<p>Le service Azure Batch Account vous permet de g\u00e9rer une multitude de pools. Un pool est un ensemble de VM dedicated ou low-priority ayant une configuration commune :</p> <ul> <li>type et taille de machine, </li> <li>OS de la VM,</li> <li>subnet,</li> <li>variables d'environnements,</li> <li>commande s'ex\u00e9cutant au d\u00e9marrage de chaque machine virtuelle,</li> <li>certificats,</li> <li>images des conteneurs \u00e0 pr\u00e9charger (vous permettra de r\u00e9duire de fa\u00e7on significative la dur\u00e9e d'instanciation du conteneur),</li> <li>nombre de t\u00e2ches pouvant s'executer en parall\u00e8le sur une m\u00eame machine virtuelle.</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#le-gestionnaire-dapplication","title":"Le gestionnaire d'application","text":"<p>Le service Azure Batch Account vous permet de g\u00e9rer les packages d'applications. Ainsi vous pouvez vous passer d'outils comme Azure DevOps Artifacts, Nexus ou Artifactory.  Le gestionnaire de packages est simple mais reste efficace avec 2 param\u00e8tres pour g\u00e9rer le r\u00e9f\u00e9rencement :</p> <ul> <li>Nom de l'application</li> <li>Version</li> </ul> <p>Attention</p> <p>Le gestionnaire d'application ne vous permet pas de g\u00e9rer vos images Docker.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#le-gestionnaire-de-certificat","title":"Le gestionnaire de certificat","text":"<p>Le service Azure Batch Account vous permet de g\u00e9rer aussi les certificats. Vous pouvez les mettre \u00e0 disposition de vos pools qui pourront les utiliser au moment de l'ex\u00e9cution des t\u00e2ches.</p> <p>Attention</p> <p>Azure Batch Account ne vous pr\u00e9viendra pas de l'expiration de vos certificats !</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#le-gestionnaire-de-job-et-de-taches","title":"Le gestionnaire de job et de t\u00e2ches","text":"<p>Le service Azure Batch Account vous permet de regrouper vos t\u00e2ches dans le cas o\u00f9 vous souhaitez ex\u00e9cuter sur un m\u00eame pool un ensemble de t\u00e2ches. Vous pouvez au sein de votre job d\u00e9finir :</p> <ul> <li>des variables d'environnement communes \u00e0 l'ensemble des t\u00e2ches,</li> <li>des commandes au d\u00e9marrage et \u00e0 la fin du job.</li> </ul> <p>Une t\u00e2che ne peut s'ex\u00e9cuter qu'au sein d'un job. S'il n'y a pas de disponibilit\u00e9 sur le pool utilis\u00e9 par le job, Azure Batch Account va mettre en attente la t\u00e2che. Pour ex\u00e9cuter votre t\u00e2che vous pouvez d\u00e9finir :</p> <ul> <li>une ligne de commande</li> <li>des variables d'environnement sp\u00e9cifique</li> <li>les applications du gestionnaire d'application \u00e0 charger lors de l'ex\u00e9cution de la t\u00e2che. </li> </ul> <p>Le service Azure Batch Account historise les ex\u00e9cutions des t\u00e2ches et des jobs. Mais, je vous recommande d'utiliser des outils comme Log Analytics pour tracer les logs d'ex\u00e9cution des t\u00e2ches, la recherche dans Azure Batch \u00e9tant fastidieuse.</p> <p>Note</p> <p>Log Analytics est un service manag\u00e9 d'Azure permettant de collecter et parcourir les logs de vos diff\u00e9rentes applications. Vous pouvez donc l'utiliser pour centraliser les logs de vos batchs, mais aussi de vos autres applications (Web, Mobile, Desktop, ...).</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#le-planificateur-de-taches","title":"Le planificateur de t\u00e2ches","text":"<p>Enfin, Azure Batch Account propose un planificateur de t\u00e2ches. Mais ce planificateur ne vous permettra de d\u00e9finir que la fr\u00e9quence d'ex\u00e9cution. Je vous recommande vivement de passer votre chemin et d'utiliser des services int\u00e9grant un planificateur complet bas\u00e9 sur un CRONtab par exemple.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#conclusion","title":"Conclusion","text":"<p>Pour conclure je vous propose de r\u00e9sumer les plus et les moins de ce service.</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#les-plus","title":"Les plus","text":"<ul> <li>Le gestionnaire d'application qui vous \u00e9vitera d'avoir \u00e0 provisionner un autre service,</li> <li>Le gestionnaire de certificat qui vous simplifiera le d\u00e9ploiement de vos certificats sur vos VM,</li> <li>La prise en charge des OS Windows et Linux,</li> <li>La possibilit\u00e9 d'ex\u00e9cuter des conteneurs sur les OS Windows et Linux,</li> <li>L'int\u00e9gration Vnet compl\u00e8te qui vous permet d'ex\u00e9cuter vos batchs et conteneurs de fa\u00e7on enti\u00e8rement isol\u00e9e,</li> <li>La possibilit\u00e9 de provisionner des VM low-priority qui vous permettra une r\u00e9duction des co\u00fbts significative.</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#les-moins","title":"Les moins","text":"<ul> <li>Le planificateur de t\u00e2ches qui se limite \u00e0 la fr\u00e9quence d'ex\u00e9cution. Un CRONtab aurait \u00e9t\u00e9 le bienvenu,</li> <li>L'int\u00e9gration aux autres services manag\u00e9s Azure comme Logic Apps, Data Factory est inexistante ou trop peu exploitable. Vous serez souvent oblig\u00e9 d'utiliser une Azure Function pour palier \u00e0 ce manque,</li> <li>Le moteur de recherche de l'historique des jobs n'est pas assez abouti.</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#le-mot-de-la-fin","title":"Le mot de la fin","text":"<p>Si vous avez r\u00e9guli\u00e8rement besoin d'ex\u00e9cuter des traitements de plusieurs minutes sur le cloud, le service Azure Batch peut \u00eatre consid\u00e9r\u00e9 comme une v\u00e9ritable solution.</p> <p>De plus, si vous \u00eates en pleine migration Cloud et que dans votre SI OnPremise vous avez des traitements batchs en ligne de commande, le service Azure Batch peut-\u00eatre un v\u00e9ritable QuickWin. Il vous \u00e9vitera un refactoring de vos batchs pour les int\u00e9grer \u00e0 des services plus moderne comme Azure DataFactory.  </p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Batch</li> <li>Ephemeral Pipelines Agents</li> </ul>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/classroom/02.azureClassroom.batch/#remerciements","title":"Remerciements","text":"<ul> <li>Samy Mameri : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Etienne Louise : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> <li>Quentin Joseph : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 1er D\u00e9cembre 2021</p>","tags":["Azure","compute","batch","architecture","cours"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/","title":"Adopt a GitOps approach with Azure App Configuration (Part 2)","text":"<p>In my last talk GitOps, Continuous Delivery and environments: how to escape hell!, a participant pointed out to me that it would be good to show concretely how to set up a GitOps approach with modern tools.</p> <p>Being a fan of Azure managed services, I therefore suggest that you study how to set up a GitOps approach with Azure App Configuration.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#why-adopt-a-gitops-approach","title":"Why adopt a GitOps approach?","text":"<p>Commen\u00e7ons par un petit rappel. </p> <p>The GitOps approach is the result of the meeting of the world of developers and the world of administrators and operators. This meeting took place at the time of the democratization of the DevOps approach. Developers working with administrators, the two (once well-separated) worlds have inspired each other and one of the results is the GitOps approach.</p> <p>But what is GitOps?</p> <p>The GitOps approach is simply the use of code management tools like git to manage the configuration parameters of an application. These tools offer the following advantages:</p> <ul> <li>Centralization: thanks to the repository server,</li> <li>Historization: thanks to commits,</li> <li>Governance: thanks to access control,</li> <li>Automation: thanks to CI/CD pipelines.</li> </ul> <p>Does that mean it's the new standard?</p> <p>Yes and no. This will mainly depend on the context of your application. If you manage a monolithic application, you may not need to implement a GitOps approach. Maybe you can just manage your application's configuration settings directly in your pipeline. \"Keep it simple and stupid!\".</p> <p>You will find the benefit of setting up a GitOps approach as soon as you have to manage a distributed application. Indeed, in your configuration settings, you will have to manage attributes common to the components of your architecture (such as connection strings to your databases) and attributes that are not related to the deployment of your components (such as certificates). These parameters will be managed independently of your components.</p> <p></p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#overview-of-azure-app-configuration","title":"Overview of Azure App Configuration","text":"<p>The Azure App Configuration service will allow you to set up a GitOps approach on Azure. Indeed, this managed service will allow you to manage and distribute your configuration parameters to your applications.</p> <p>Microsoft offers SDKs for this service available in many languages: .NET, Java, Python, JavaScript, ...</p> <p>You will therefore be able to use this service to distribute your configuration to your Function Apps, Web Apps, Container Instances, Kubernetes Services, ...</p> <p>There are 2 pricing tiers: Free and Standard. You will find that the Free level may be interesting but only for non-production environments. The absence of SLAs and quotas are simply not an option for a production application (unless you have a taste for risk).</p> <p>Note</p> <p>To learn more, I invite you to consult the Microsoft documentation: here</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#architecture","title":"Architecture","text":"<p>Enough with blabla and let's go straight to the heart of the matter. Let's start with a small architectural diagram. The goal is to use Azure DevOps and Azure App Configuration together to distribute the configuration to the different elements of our distributed application.</p> <p></p> <p>We will push the configuration from Azure DevOps to Azure App Configuration and configure our various components of our distributed architecture to retrieve the configuration from the latter.</p> <p>It is possible to indicate in Azure App Configuration that one of the parameters is in Azure Key vault. Your application will then directly retrieve the configuration in the vault from the key indicated by Azure App Configuration.</p> <p>There are 2 ways to connect to Azure App Configuration:</p> <ul> <li>with an access key,</li> <li>with a managed identity (System Assigned or User Assigned).</li> </ul> <p>I strongly recommend that you use the second solution; the first should only be used if you have no other solution.</p> <p>You can also isolate this service from a network point of view by using a Private Endpoint. But in this case, you will have to make sure to use *Self-hosted Azure DevOps agents to deploy your configuration. Here is an example of an architecture diagram with network isolation:</p> <p></p> <p>Finally, if you want your components to be notified on every configuration change, you can add the Event Grid System Topic service.</p> <p></p> <p>Note</p> <p>It is not possible to network isolate an Event Grid System Topic with a Private Endpoint. To solve this problem, it will be necessary to make a \"small hole\" via Service Tag to authorize traffic coming from your Event Grid (cf.: my article on network isolation).</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#implementation-in-your-applications","title":"Implementation in your applications","text":"","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#configure-your-net-apps-to-use-azure-app-configuration","title":"Configure your .NET apps to use Azure App Configuration","text":"<p>To configure your .NET applications, you will need to add the nuget package <code>Microsoft.Azure.AppConfiguration.AspNetCore</code> for your ASP.NET Core or <code>Microsoft.Extensions.Configuration.AzureAppConfiguration</code> for all your other .NET Core apps.</p> <p>Next, you need to configure the service.</p> <p>Here is an example of a simple configuration of your ASP.NET core application:</p> <pre><code>var builder = WebApplication.CreateBuilder(args);\n\nbuilder.Host.ConfigureAppConfiguration(builder =&gt;\n{\n    var settings = builder.Build();\n    //Connect to your App Config Store\n    builder.AddAzureAppConfiguration(options =&gt;\n    {\n        options.Connect(new Uri(settings[\"AppConfig:Endpoint\"]), new ManagedIdentityCredential())\n    });\n    // ...\n}); \n</code></pre> <p>In this example, we're using the managed identity to authenticate the app to the Azure App Configuration service.</p> <p>Finally, you must give the <code>App Configuration Data Reader</code> (RBAC) role at the Azure App Configuration level to your ASP.NET core application.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#refresh-the-configuration-in-pull-mode","title":"Refresh the configuration in \"Pull\" mode","text":"<p>Being able to load your app configuration from Azure App Configuration is good. But performing a restart of the application to load the new configuration is not always ideal. The Azure App Configuration SDK overcomes this problem by detecting the modification of the configuration and reloading it automatically.</p> <p>First of all, make sure that the middleware of Azure App Configuration is configured. To do this in the <code>HostBuilder</code>, you must add the service via <code>AddAzureAppConfiguration</code>.</p> <pre><code>builder.Host.ConfigureAppConfiguration(builder =&gt;\n{\n    // ...   \n})\n.ConfigureServices(services =&gt;\n{\n    services.AddControllersWithViews();\n    services.AddAzureAppConfiguration();\n});\n</code></pre> <p>Then activate the middleware at the <code>WebApplication</code> level via <code>UseAzureAppConfiguration</code>.</p> <pre><code>var app = builder.Build();\napp.UseHttpsRedirection();\napp.UseAzureAppConfiguration();\n// ...\n</code></pre> <p>Next, we'll use a \"sentinel\" parameter in Azure App Configuration. Each time this parameter is changed, it will indicate that the configuration must be reloaded.</p> <p>Here is an example :</p> <pre><code>builder.AddAzureAppConfiguration(options =&gt;\n{\n    options.Connect(new Uri(settings[\"AppConfig:Endpoint\"]), new ManagedIdentityCredential())\n        .ConfigureRefresh(refresh =&gt; refresh.Register(\"TestApp:Settings:Sentinel\", true);\n});\n// ...\n</code></pre> <p>In this example, we will condition the refresh of all the parameters to the update of <code>TestApp:Settings:Sentinel</code>.</p> <p>Thus our application will regularly check the value of our \"sentinel\" parameter. By default the frequency is set to 30 seconds. But you can set the frequency yourself:</p> <pre><code>// ...    \nrefresh.Register(\"TestApp:Settings:Sentinel\", true).SetCacheExpiration(new TimeSpan(0, 0, 10))\n// ...\n</code></pre> <p>In this example, we will check the \"sentinel\" parameter every 10 seconds.</p> <p>Warning</p> <p>Be careful not to set the frequency too high. Indeed, if you want to make sure that your configuration can be refreshed very quickly, you will be tempted to reduce it to one second or even less. But it must be taken into account that each web app will do this verification independently. By setting to 1 second, your components will poll at least 2.6 million times per month Azure App Configuration. Let's say you have 10 components in your architecture, then that goes up to 26 million requests. You will then have a significant impact on the costs of your Azure App Configuration service (~ 140 \u20ac / month).</p> <p>If you absolutely want to have a solution that takes your new configuration into account almost instantly, then I advise you to refresh the configuration of your application in \"Push\" mode.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#refresh-the-configuration-in-push-mode","title":"Refresh the configuration in \"Push\" mode","text":"<p>The principle is that each change made to your configuration in Azure App Configuration triggers a notification that is captured by your components. This solution will use another service: the Event Grid System Topic.</p> <p>In the case of an ASP.NET core component, you will need:</p> <ol> <li>Create a webhook capable of registering with the Event Grid,</li> <li>Set up the mechanism for refreshing the settings.</li> </ol> <p>Let's start with the webhook. To do this, we must add the nuget package <code>Azure.Messaging.EventGrid</code> to our project. Then, create a dedicated controller with a POST method. Like this :</p> <pre><code>using Azure.Messaging.EventGrid;\nusing Azure.Messaging.EventGrid.SystemEvents;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace [yournamespace].Controllers\n{\n    [ApiController]\n    [Route(\"[controller]\")]\n    public class ConfigurationController : ControllerBase\n    {\n        [HttpPost]\n        public async Task&lt;IActionResult&gt; Post()\n        {\n            BinaryData events = await BinaryData.FromStreamAsync(Request.Body);\n            EventGridEvent[] eventGridEvents = EventGridEvent.ParseMany(events);\n\n            foreach (EventGridEvent eventGridEvent in eventGridEvents)\n            {\n                // Handle system events\n                if (eventGridEvent.TryGetSystemEventData(out object eventData))\n                {\n                    // Handle the subscription validation event\n                    if (eventData is SubscriptionValidationEventData subscriptionValidationEventData)\n                    {\n                        var responseData = new SubscriptionValidationResponse()\n                        {\n                            ValidationResponse = subscriptionValidationEventData.ValidationCode\n                        };\n                        return new OkObjectResult(responseData);\n                    }\n                    // Handle the app configuration keyvalue event\n                    else if (eventData is AppConfigurationKeyValueModifiedEventData || eventData is AppConfigurationKeyValueDeletedEventData)\n                    {\n                        // TO DO\n                    }\n                }\n            }\n            return new OkObjectResult(string.Empty);\n        }\n    }\n}\n</code></pre> <p>We are now able to capture events pushed by the Event Grid. You must now trigger the refresh of the configuration. To do this, you must create a class in charge of triggering the refresh with the middleware of Azure App Configuration. Here is an example :</p> <pre><code>using Microsoft.Extensions.Configuration.AzureAppConfiguration;\n\nnamespace [yournamespace]\n{\n    public class OnDemandConfigurationRefresher : IOnDemandConfigurationRefresher\n    {\n        private readonly List&lt;IConfigurationRefresher&gt; _configurationRefreshers = new List&lt;IConfigurationRefresher&gt;();\n\n        public OnDemandConfigurationRefresher(IConfiguration configuration)\n        {\n            var configurationRoot = configuration as IConfigurationRoot;\n\n            if (configurationRoot == null)\n            {\n                throw new InvalidOperationException(\"The 'IConfiguration' injected in OnDemandConfigurationRefresher is not an 'IConfigurationRoot', and needs to be as well.\");\n            }\n\n            foreach (var provider in configurationRoot.Providers)\n            {\n                if (provider is IConfigurationRefresher refresher)\n                {\n                    _configurationRefreshers.Add(refresher);\n                }\n            }\n        }\n\n        public void RefreshAllRegisteredKeysAsync(PushNotification pushNotification)\n        {\n            _configurationRefreshers.ForEach(r =&gt; r.ProcessPushNotification(pushNotification));\n        }\n    }\n}\n</code></pre> <p>And add this class as a service.</p> <pre><code>builder.Host.ConfigureAppConfiguration(builder =&gt;\n{\n    // ...   \n})\n.ConfigureServices(services =&gt;\n{\n    services.AddControllersWithViews();\n    services.AddAzureAppConfiguration();\n    services.AddScoped&lt;IOnDemandConfigurationRefresher, OnDemandConfigurationRefresher&gt;();\n});\n</code></pre> <p>Finally, implement triggering the refresh from the webhook:</p> <pre><code>using Azure.Messaging.EventGrid;\nusing Azure.Messaging.EventGrid.SystemEvents;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Configuration.AzureAppConfiguration;\nusing Microsoft.Extensions.Configuration.AzureAppConfiguration.Extensions;\n\nnamespace [yournamespace].Controllers\n{\n    [ApiController]\n    [Route(\"[controller]\")]\n    public class ConfigurationController : ControllerBase\n    {\n        private readonly IOnDemandConfigurationRefresher _azureAppConfigurationRefresher;\n\n        public ConfigurationController(IOnDemandConfigurationRefresher azureAppConfigurationRefresher)\n        {\n            _configuration = configuration;\n            _azureAppConfigurationRefresher = azureAppConfigurationRefresher;\n        }\n\n        [HttpPost]\n        public async Task&lt;IActionResult&gt; Post()\n        {\n            BinaryData events = await BinaryData.FromStreamAsync(Request.Body);\n            EventGridEvent[] eventGridEvents = EventGridEvent.ParseMany(events);\n\n            foreach (EventGridEvent eventGridEvent in eventGridEvents)\n            {\n                // Handle system events\n                if (eventGridEvent.TryGetSystemEventData(out object eventData))\n                {\n                    // Handle the subscription validation event\n                    if (eventData is SubscriptionValidationEventData subscriptionValidationEventData)\n                    {\n                        var responseData = new SubscriptionValidationResponse()\n                        {\n                            ValidationResponse = subscriptionValidationEventData.ValidationCode\n                        };\n                        return new OkObjectResult(responseData);\n                    }\n                    // Handle the app configuration keyvalue event\n                    else if (eventData is AppConfigurationKeyValueModifiedEventData || eventData is AppConfigurationKeyValueDeletedEventData)\n                    {\n                        eventGridEvent.TryCreatePushNotification(out PushNotification pushNotification);\n                        _azureAppConfigurationRefresher.RefreshAllRegisteredKeysAsync(pushNotification);\n                    }\n                }\n            }\n            return new OkObjectResult(string.Empty);\n        }\n    }\n}\n</code></pre> <p>And There you go !</p> <p>You can then increase the cache expiration to one or more days: <code>SetCacheExpiration(TimeSpan.FromDays(10))</code>.</p> <p>This solution has a drawback. If at the time of your configuration change your component is not available, the event will not be captured and the configuration will not be updated. You can overcome this problem by using a Service Bus queue between your Event Grid and your Web app. This way, your component can then retrieve the configuration change as soon as it becomes available again.</p> <p></p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#configure-to-use-azure-app-configuration-with-azure-key-vault","title":"Configure to use Azure App Configuration with Azure Key vault","text":"<p>In your configuration settings, it is not uncommon to find sensitive elements such as access keys, passwords, connection strings. It is strongly recommended to protect these sensitive parameters in a safe. Azure App Configuration allows you to reference sensitive settings of your configuration and indicate their location in Azure Key vault. This way your application can easily retrieve the value of the parameter directly from the vault. Additionally, as with all other configuration settings, you will be able to notify your components of a change in the vault.</p> <p>To do this, it's very simple, all you have to do is modify the setting of Azure App Configuration in your component. Here is an example using managed identities:</p> <pre><code>builder.AddAzureAppConfiguration(options =&gt;\n{\n    options.Connect(new Uri(settings[\"AppConfig:Endpoint\"]), new ManagedIdentityCredential())\n        .ConfigureRefresh(refresh =&gt; refresh.Register(\"TestApp:Settings:Sentinel\", true)\n        .ConfigureKeyVault(kv =&gt; kv.SetCredential(new ManagedIdentityCredential()));\n});\n// ...\n</code></pre> <p>Note</p> <p>Your application (via its managed identity) must be authorized to retrieve (GET) the values \u200b\u200bin Azure Key vault.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#conclusion","title":"Conclusion","text":"<p>In this first part we saw how to set up Azure App Configuration with our applications. We will see in the second part, how to automate the configuration update with Azure DevOps. </p> <p>To be continued...</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#references","title":"References","text":"<ul> <li>Microsoft : Azure App Configuration</li> <li>Azure App Configuration refresh on demand</li> </ul>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/01.gitops.AzureAppConfiguration/#thanks","title":"Thanks","text":"<ul> <li>Etienne Louise : for the proofreading and the comment that led me to publish this article</li> <li>David Dubourg : for the proofreading</li> <li>Michael Maillot : for the proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on April 25, 2022.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/","title":"Adopt a GitOps approach with Azure App Configuration (Part 2)","text":"<p>In the first part we saw how to use Azure App Configuration with different applications and constraints: configuration vault, push or pull. In this second part we will see together how to use the git repos and the Azure DevOps pipelines to manage and push the configuration to Azure App Configuration.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#reminder-of-the-gitops-approach","title":"Reminder of the GitOps approach","text":"<p>The GitOps approach consists of managing the configuration of applications using a source manager like git. git offers the advantage of providing a history of modifications thanks to commits and of being able to automate the deployment of the configuration thanks to CI/CD pipelines.</p> <p>Each configuration change produces a git commit. This triggers a pipeline that will deploy the configuration.</p> <p>To this, we will be able to add the branching model (TBD, Gitflow, github flow, ...) and the semantic versioning, to condition the configuration deployment.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#architecture-reminder","title":"Architecture (reminder)","text":"<p>The goal is to use Azure DevOps and Azure App Configuration together to distribute the configuration to the different elements of our distributed application.</p> <p></p> <p>We will push the configuration from Azure DevOps to Azure App Configuration and configure our various components of our distributed architecture to retrieve the configuration from the latter.</p> <p>If you have network isolating Azure App Configuration using a Private Endpoint, you will need to be sure to use Self-hosted Azure DevOps agents to deploy your configuration (see my article). Here is an example of an architecture diagram with network isolation:</p> <p></p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#the-azure-devops-implementation","title":"The Azure DevOps implementation","text":"","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#create-the-azure-devops-azure-connection","title":"Create the Azure DevOps &lt;-&gt; Azure connection","text":"<p>If you already use Azure DevOps to deploy your applications on Azure this means that you have most certainly already configured a service connection in your project. In this case, you just have to note the Service Principal Id. Otherwise, you can follow the procedure described here.</p> <p>Once your connection service is operational, you will need to give it permission to manage the configuration of your Azure App Configuration. To do this, in Azure, add the <code>App Configuration Data Owner</code> (RBAC) role at the Azure App Configuration level.</p> <p></p> <p>Azure DevOps can now manage your configuration for you.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#manage-your-setup","title":"Manage your setup","text":"<p>Your configuration will have to be managed in Json or Yaml files.</p> <p>Note</p> <p>I recommend using the Json format. Indeed, this format is much easier to manage with Azure DevOps tasks than the Yaml format.</p> <p>In order to simplify management, I advise you to separate your configuration into different files:</p> <ul> <li>a file for the \"classic\" parameters,</li> <li>a file for the Feature flags,</li> <li>a file for references to your Azure Keyvault.</li> </ul> <p>Let's start with the \"classic\" settings file. Nothing's easier. For each key, you will set the value. For example in yaml you will have:</p> <pre><code>TestApp:Settings:Param1: ValueOfParam1\nTestApp:Settings:Param2: ValueOfParam2\nAll:Settings:Param3: ValueOfParam3\n</code></pre> <p>For the file containing the Features flags, it will be a bit more complicated. For each Feature flags, you will have to define a node containing the parameters id, enabled and optionally description and conditions. And the key must start with <code>.appconfig.featureflag/</code>.</p> <p>Below is an example in json to change ;-):</p> <pre><code>{ \n   \".appconfig.featureflag/flag001\": {\n        \"id\": \"Flag001\",\n        \"enabled\": true\n   }, \n   \".appconfig.featureflag/flag002\": {\n        \"id\": \"Flag002\",\n        \"enabled\": true,\n        \"conditions\": {\n            \"client_filters\": [\n                {\n                    \"name\": \"Microsoft.TimeWindow\",\n                    \"parameters\": {\n                        \"Start\": \"Thu, 19 May 2022 22:00:00 GMT\",\n                        \"End\": \"Sat, 21 May 2022 22:00:00 GMT\"\n                    }\n                }\n            ]\n        }        \n   },         \n   \".appconfig.featureflag/flag003\": {\n        \"id\": \"Flag003\",\n        \"description\": \"Lorem ipsum dolor sit amet\",\n        \"enabled\": true,\n        \"conditions\": {\n            \"client_filters\": [\n                {\n                    \"name\": \"Microsoft.Targeting\",\n                    \"parameters\": {\n                        \"Audience\": {\n                            \"Users\": [],\n                            \"Groups\": [\n                                {\n                                    \"Name\": \"groupA\",\n                                    \"RolloutPercentage\": 0\n                                },\n                                {\n                                    \"Name\": \"groupB\",\n                                    \"RolloutPercentage\": 100\n                                }\n                            ],\n                            \"DefaultRolloutPercentage\": 50\n                        }\n                    }\n                }\n            ]\n        }\n   }   \n}\n</code></pre> <p>Finally, for the references file to your Azure Keyvault, you will have to define a node containing the uri parameter with the url to access your secret. For example (in json):</p> <pre><code>{\n    \"TestApp:Settings:Secret1\": {\n        \"uri\":\"https://[YourKeyVaultName].vault.azure.net/secrets/Secret1\"\n    },\n    \"TestApp:Settings:Secret2\": {\n        \"uri\":\"https://[YourKeyVaultName].vault.azure.net/secrets/Secret2\"\n    },\n    \"TestApp:Settings:Secret3\": {\n        \"uri\":\"https://[YourKeyVaultName].vault.azure.net/secrets/Secret3\"\n    }\n}\n</code></pre> <p>All that remains is to push these different files to a dedicated repository.</p> <p>To manage all this, you will have to automate the deployment and above all manage the \"sentinel\" parameter capable of indicating to the applications that the configuration has changed! (cf. Refresh the configuration in \"Pull\" mode)</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#sematic-versioning-and-sentinel","title":"Sematic versioning and sentinel.","text":"<p>Our \"sentinel\" parameter must indicate a modification of the configuration in order to force the refresh of this one at the level of the applications. For that, why not use semantic versioning?</p> <p>We are going to run a small script that will add a \"sentinel\" parameter to our \"classic\" configuration file. This will be evaluated with the desired version.</p> <p>Below is an example of a powershell script that will modify the yaml file to add the <code>TestApp:Settings:Sentinel</code> parameter:</p> <pre><code># Arguments that get passed to the script when running it\nparam (\n    [Parameter(Position=1)]\n    $yamlFile,\n    [Parameter(Position=2)]\n    $version\n)\n\n# Install and import the `powershell-yaml` module\n# Install module has a -Force -Verbose -Scope CurrentUser arguments which might be necessary in your CI/CD environment to install the module\nInstall-Module -Name powershell-yaml -Force -Verbose -Scope CurrentUser\nImport-Module powershell-yaml\n\n# LoadYml function that will read YML file and deserialize it\nfunction LoadYml {\n    param (\n        $FileName\n    )\n    # Load file content to a string array containing all YML file lines\n    [string[]]$fileContent = Get-Content $FileName\n    $content = ''\n    # Convert a string array to a string\n    foreach ($line in $fileContent) { $content = $content + \"`n\" + $line }\n    # Deserialize a string to the PowerShell object\n    $yml = ConvertFrom-YAML $content\n    # return the object\n    Write-Output $yml\n}\n\n# WriteYml function that writes the YML content to a file\nfunction WriteYml {\n    param (\n        $FileName,\n        $Content\n    )\n    #Serialize a PowerShell object to string\n    $result = ConvertTo-YAML $Content\n    #write to a file\n    Set-Content -Path $FileName -Value $result\n}\n\n# Loading yml, setting new values and writing it back to disk\n$yml = LoadYml $yamlFile\n$yml.'TestApp:Settings:Sentinel' = $version\nWriteYml $yamlFile $yml\n</code></pre> <p>When setting up CI/CD pipelines, I particularly enjoy using tools like GitVersion. This utility will allow you to manage your sematic versioning from your git history: your commits, your tags, your branches.</p> <p>To do this, you will need to add a GitVersion.yml file to your repository git. This file will define how to infer the version from your history.</p> <p>Here is a simple example with Trunk Based Development:</p> <pre><code>mode: ContinuousDeployment\nassembly-versioning-scheme: MajorMinorPatch\ntag-prefix: '[vV]'\ncontinuous-delivery-fallback-tag: ci\nmajor-version-bump-message: '\\+semver:\\s?(breaking|major)'\nminor-version-bump-message: '\\+semver:\\s?(feature|minor)'\npatch-version-bump-message: '\\+semver:\\s?(fix|patch)'\nlegacy-semver-padding: 5\nbuild-metadata-padding: 5\ncommits-since-version-source-padding: 5\ncommit-message-incrementing: Enabled\nbranches:\n  master:\n    mode: ContinuousDeployment\n    tag: unstable\n    increment: Minor\n    prevent-increment-of-merged-branch-version: true\n    track-merge-target: false\n  release:\n    regex: releases?[/-]\n    increment: Patch\n    tag: stable\n    prevent-increment-of-merged-branch-version: true\n    track-merge-target: false\n</code></pre> <p>All that remains is to automate the deployment of the configuration.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#the-cicd-pipeline","title":"The CI/CD pipeline","text":"<p>Let's start with the CI. Contrary to what one might think, continuous integration will be useful for:</p> <ul> <li>Define the value of the \"sentinel\" parameter,</li> <li>Pack the configuration in order to be able to reproduce this configuration.</li> </ul> <p></p> <p>And in the case of a Azure DevOps multi-stage pipeline, this is what it can give:</p> <pre><code>stages:\n- stage: Prepare\n  displayName: Prepare\n  jobs:  \n  - job: PrepareConfiguration\n    displayName: Prepare configuration\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    # T\u00e9l\u00e9charge gitversion (s'il n'existe pas)\n    - task: gittools.gittools.setup-gitversion-task.gitversion/setup@0\n      displayName: gitversion/setup\n      inputs:\n        versionSpec: '5.*'\n    # D\u00e9finit la version\n    - task: gittools.gittools.execute-gitversion-task.gitversion/execute@0\n      displayName: gitversion/execute\n      inputs:\n        useConfigFile: true\n        configFilePath: GitVersion.yml\n    # D\u00e9finit le param\u00e8tre sentinelle\n    - task: PowerShell@2\n      displayName: setSentinelVersion\n      inputs:\n        filePath: tools/setSentinel.ps1\n        arguments: '-yamlFile configuration.yml -version $(GitVersion.FullSemVer)'\n    # Copie la configuration \u00e0 ins\u00e9rer dans l'artefact\n    - task: CopyFiles@2\n      displayName: 'Copy Files to: $(Build.ArtifactStagingDirectory)'\n      inputs:\n        Contents: config*.yml\n        TargetFolder: '$(Build.ArtifactStagingDirectory)'\n    # Publie l'artefact\n    - task: PublishBuildArtifacts@1\n      displayName: 'Publish Artifact: drop'\n</code></pre> <p>Once our configuration deliverable is ready, all that remains is to deploy it on Azure App Configuration. You can easily do this with the <code>AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3</code> task.</p> <p>The problem with this task is that it cannot deploy all configurations at once. Deploy by parameter type by passing a distinct value to the <code>ContentType</code> parameter:</p> <ul> <li>For vault references: <code>application/vnd.microsoft.appconfig.keyvaultref+json;charset=utf-8</code></li> <li>For features flags: <code>application/vnd.microsoft.appconfig.ff+json;charset=utf-8</code> </li> </ul> <p>And in the case of a Azure DevOps multi-stage pipeline, this can give:</p> <pre><code>- stage: Deploy\n  displayName: Deploy\n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: YOUR_ENVIRONMENT\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          #  Publie les r\u00e9f\u00e9rences \u00e0 votre Azure Keyvault \n          - task: AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3\n            displayName: 'Azure App Configuration KeyVault'\n            inputs:\n              azureSubscription: ${{variables.azureSubscription}}\n              AppConfigurationEndpoint: ${{variables.AppConfigurationEndpoint}}\n              ConfigurationFile: $(Pipeline.Workspace)/drop/configurationKeyVault.yml\n              Separator: .\n              Depth: '1'\n              ContentType: 'application/vnd.microsoft.appconfig.keyvaultref+json;charset=utf-8'\n          # Publie les features flags \n          - task: AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3\n            displayName: 'Azure App Configuration Feature Flags'\n            inputs:\n              azureSubscription: ${{variables.azureSubscription}}\n              AppConfigurationEndpoint: ${{variables.AppConfigurationEndpoint}}\n              ConfigurationFile: $(Pipeline.Workspace)/drop/configurationFeatureFlags.yml\n              Separator: .\n              Depth: '1'\n              ContentType: 'application/vnd.microsoft.appconfig.ff+json;charset=utf-8'\n          # Publie la configuration \"classique\" \n          - task: AzureAppConfiguration.azure-app-configuration-task-push.custom-build-release-task.AzureAppConfigurationPush@3\n            displayName: 'Azure App Configuration'\n            inputs:\n              azureSubscription: ${{variables.azureSubscription}}\n              AppConfigurationEndpoint: ${{variables.AppConfigurationEndpoint}}\n              ConfigurationFile: $(Pipeline.Workspace)/drop/configuration.yml\n              Separator: .\n              Depth: '1'\n</code></pre> <p>Note</p> <p>The <code>azureSubscription</code> and <code>AppConfigurationEndpoint</code> parameters correspond respectively to the service connection configured on your Azure DevOps project and to the url of your Azure App Configuration service. </p> <p>Now we have our repo. git and our CI/CD pipeline which allows us to deploy the configuration.</p> <p>END !</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#conclusion","title":"Conclusion","text":"<p>Attendez un peu...</p> <p>Our configurations will certainly be different depending on our environments. How to manage these distinct configurations? Modifying the configuration of the acceptance environment does not have to impact the configuration of the integration or production environment. Does that mean I have to put this in separate files? in separate repositories? or even elsewhere?</p> <p>We will discuss in the third part the configuration management by environment.</p> <p>To be continued...</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#references","title":"References","text":"<ul> <li>Microsoft : Azure App Configuration</li> <li>Azure DevOps : Create a service connection</li> <li>GitVersion</li> <li>Push settings to App Configuration with Azure Pipelines</li> </ul>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/02.gitops.AzureAppConfiguration/#thanks","title":"Thanks","text":"<ul> <li>Oussama Mouchrit : for proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on May 3, 2022.</p>","tags":["DevOps","GitOps","CI/CD","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/","title":"Adopt a GitOps approach with Azure App Configuration (Part 3)","text":"<p>In Part 2 we saw how to use git repositories and Azure DevOps pipelines to manage and push configuration to Azure App Configuration. But our configurations will certainly be different depending on our environments. How to manage these distinct configurations? Modifying the configuration of the acceptance environment does not have to impact the configuration of the integration or production environment. Does that mean I have to put this in separate files? in separate repositories? or even elsewhere?</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#manage-your-environment-configuration","title":"Manage your environment configuration","text":"<p>First, you need to ask yourself a few questions:</p> <ul> <li>Do you need to have a configuration history specific to each of your environments?</li> <li>How many environment parameters (apart from sensitive parameters) you will have to manage?</li> <li>What is the frequency of your environment updates?</li> </ul> <p>If you have many environment settings, using one configuration file per environment in your repo. git is probably the solution.</p> <p>If you plan to change your environment configuration regularly, maybe repos per environment is a good solution.</p> <p>It's really going to depend on your situation. I will still offer you to describe some solutions that can be implemented with Azure DevOps.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#manage-your-environment-configuration-with-azure-devops-libraries","title":"Manage your environment configuration with Azure DevOps libraries.","text":"<p>If you don't need the history of your environment configurations, the Azure DevOps libraries are sufficient.</p> <p></p> <p>Used jointly in your CD pipeline with a task of the <code>replacetokens</code> type, you can then overload your common configuration with the specificities of your environments.</p> <p>For example, if you define in an Azure DevOps library the parameters:</p> <ul> <li>NB_NODES: Number of nodes in your cluster,</li> <li>ALLOW_ANONYMOUS_ACCESS: Top indicating if the WebApp is accessible without authentication,</li> <li>SUPER_ADMIN_USER: Identity of the super administrator of the cluster.</li> </ul> <p>Using the <code>replacetokens</code> task, you will have a configuration file in your git repository like this:</p> <pre><code>TestApp:Settings:Param1: ValueOfParam1\nTestApp:Settings:Param2: ValueOfParam2\nAll:Settings:Param3: ValueOfParam3\nCluster:Settings:NbNodes: #{NB_NODES}#\nWebApp:Settings:AllowAnonymousAccess: #{ALLOW_ANONYMOUS_ACCESS}#\nCluster:Settings:SuperAdmin: #{SUPER_ADMIN_USER}#\n</code></pre> <p>The downside is that you will have another configuration repository to manage. This is not ideal in terms of maintainability.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#manage-your-environment-configuration-in-separate-folders","title":"Manage your environment configuration in separate folders.","text":"<p>In this case, if you have many environment settings, using one configuration file per environment in your repository git might be the solution.</p> <p></p> <p>Let's go back to our example with the parameters:</p> <ul> <li>NB_NODES: Number of nodes in your cluster,</li> <li>ALLOW_ANONYMOUS_ACCESS: Top indicating if the WebApp is accessible without authentication,</li> <li>SUPER_ADMIN_USER: Identity of the super administrator of the cluster.</li> </ul> <p>You will have :</p> <ul> <li>a config.json file containing the common configuration parameters containing:     <pre><code>{\n    \"TestApp:Settings:Param1\": \"ValueOfParam1\",\n    \"TestApp:Settings:Param2\": \"ValueOfParam2\",\n    \"All:Settings:Param3\": \"ValueOfParam3\",\n    \"Cluster:Settings:NbNodes\": 2,\n    \"WebApp:Settings:AllowAnonymousAccess\": true,\n    \"Cluster:Settings:SuperAdmin\": null\n}\n</code></pre></li> <li>a config.dev.json file containing the configuration parameters specific to the DEV environment,     <pre><code>{\n    \"Cluster:Settings:SuperAdmin\": \"admin_dev@test.fr\"\n}    \n</code></pre></li> <li>a config.uat.json file containing the configuration parameters specific to the UAT environment,     <pre><code>{\n    \"WebApp:Settings:AllowAnonymousAccess\": false,\n    \"Cluster:Settings:SuperAdmin\": \"admin_uat@test.fr\"\n}\n</code></pre></li> <li>a config.prd.json file containing configuration parameters specific to the PROD environment.     <pre><code>{  \n    \"Cluster:Settings:NbNodes\": 5,\n    \"WebApp:Settings:AllowAnonymousAccess\": false,\n    \"Cluster:Settings:SuperAdmin\": \"admin_prd@test.fr\"\n}\n</code></pre></li> </ul> <p>Then using this powershell script you can merge the files in order to have a complete configuration file:</p> <pre><code># Arguments that get passed to the script when running it\nparam (\n    [Parameter(Position=1)]\n    $jsonSrcFile,\n    [Parameter(Position=2)]\n    $jsonEnvFile\n)\n\nInstall-Module -Name JoinModule -Force -Verbose -Scope CurrentUser\n\n# LoadJson function that will read Json file and deserialize it\nfunction LoadJson {\n    param (\n        $FileName\n    )\n    # Load file content to a string array containing all Json file lines\n    [string[]]$fileContent = Get-Content $FileName\n    $content = ''\n    # Convert a string array to a string\n    foreach ($line in $fileContent) { $content = $content + \"`n\" + $line }\n    # Deserialize a string to the PowerShell object\n    $json = ConvertFrom-Json $content\n    # return the object\n    Write-Output $json\n}\n\n# WriteJson function that writes the Json content to a file\nfunction WriteJson {\n    param (\n        $FileName,\n        $Content\n    )\n    #Serialize a PowerShell object to string\n    $result = ConvertTo-Json $Content\n    #write to a file\n    Set-Content -Path $FileName -Value $result\n}\n\nfunction MergeObject {\n    param (\n        $1,\n        $2\n    )\n\n    $Merged = $1 | Merge $2\n\n    Write-Output $Merged;\n}\n\n# Loading json, setting new values and writing it back to disk\n$jsonSrc = LoadJson $jsonSrcFile\n$jsonEnv = LoadJson $jsonEnvFile\n$merged = MergeObject $jsonSrc $jsonEnv \nWriteJson $jsonEnvFile $merged\n</code></pre> <p>The downside is that if you make a change in one of the environment configuration files it will cause a version increment for all environments. For example, if your configuration is currently in version <code>1.0.0</code> and you make a change following a configuration problem on the UAT configuration, you will increment to version <code>1.0.1</code> for all your environments even if the configuration was correct in production.</p> <p>In addition, you will not be able to apply governance to limit the modification of your production environment to a restricted user population. We certainly want to allow our team to quickly modify the configuration in DEV but not do the same in PROD.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#manage-your-environment-setup-with-separate-repos","title":"Manage your environment setup with separate repos","text":"<p>If you want to independently track changes to your environments and limit access to your environments' configurations, you may need to distribute your environments' configuration across separate repos.</p> <p></p> <p>If we take the example above with 3 environments DEV, UAT and PROD, it will take 4 git repository of configuration.</p> <ul> <li>One for the configuration common to the environments,</li> <li>One for environment-specific configuration of DEV,</li> <li>One for the environment-specific configuration of UAT,</li> <li>One for environment-specific configuration of PROD.</li> </ul> <p>The big drawback of this solution is that this method quickly multiplies the number of repositories. This will bring complexity to your Azure DevOps project.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#deploy-your-environment-configuration","title":"Deploy your environment configuration","text":"<p>Now that we have a vague idea of \u200b\u200bhow we want to manage our configuration, we must be able to deploy it correctly and at the right time. You have to ask yourself the following question: When should I change the configuration on my environment?</p> <p>From my point of view there are 2 totally different cases that will require modifying your configuration:</p> <ul> <li> <p>When a modification is made to the application:</p> <ul> <li>Evolution of the application,</li> <li>Fixed app behavior</li> </ul> </li> <li> <p>When you make a change to your environment:</p> <ul> <li>Renewal of a certificate or password,</li> <li>Modification of a technical parameter,</li> <li>Activation of a feature already deployed (Feature flag),</li> <li>...</li> </ul> </li> </ul> <p>Your deployment pipeline of your configuration must be adapted to these 2 cases.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#deploy-your-environment-configuration-following-an-application-modification","title":"Deploy your environment configuration following an application modification.","text":"<p>In the event that you bring an application evolution, you will want to test/verify your configuration on non-production environments before deploying it in production. You have to model yourself on the pipelines of your application components.</p> <p>For example, if your application is hosted on three environments: DEV, UAT, and PROD, you should have a CI/CD pipeline that will look like this:</p> <p></p> <p>Your yaml Azure DevOps pipeline with a branching model TBD will look like this:</p> <pre><code>trigger:\n- main\n- release/*\n\nstages:\n- stage: Prepare\n  displayName: Prepare\n  jobs:  \n  - job: PrepareConfiguration\n    displayName: Prepare configuration\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    # \n    # Define steps to prepare configuration for each environnments\n    #\n    # Publie l'artefact\n    - task: PublishBuildArtifacts@1\n      displayName: 'Publish Artifact: drop'\n- stage: DeployDEV\n  displayName: Deploy DEV\n  dependsOn: Prepare  \n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: DEV\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for DEV environnment\n            #\n- stage: DeployUAT\n  displayName: Deploy UAT\n  dependsOn: DeployDEV\n  condition: and(succeeded(), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'))\n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: UAT\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for UAT environnment\n            #\n- stage: DeployPRD\n  displayName: Deploy PROD\n  dependsOn: DeployUAT\n  condition: and(succeeded(), startsWith(variables['Build.SourceBranch'], 'refs/heads/release/'))\n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: PRD\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for PROD environnment\n            #\n</code></pre> <p>Thus, you ensure that your configuration will be tested and validated on your non-production environments before deploying your configuration in production.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#deploy-your-configuration-to-modify-an-environment","title":"Deploy your configuration to modify an environment.","text":"<p>But when you want to modify your configuration after an event specific to your environment and not linked to a modification of your application, you do not need to validate your configuration on other environments. Your deployment need is specific to an environment. Why redeploy a configuration in DEV when you only need to modify the configuration in UAT or PROD?</p> <p>In this case, one solution is to create a specific pipeline for each environment in addition to the previous one.</p> <p></p> <p>Now, let's take our 3 methods to manage our configuration and see how to apply this approach to each of them.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#deployer-votre-configuration-en-utilisant-azure-devops-library","title":"D\u00e9ployer votre configuration en utilisant Azure DevOps Library","text":"<p>Unfortunately, today with Azure DevOps, there is no easy and fully integrated way to trigger a pipeline following a library modification. If you still want to do it, you will have to go through the development box and use the different APIs of Azure DevOps. You will need to develop an Azure Function with a TimeTrigger to regularly check if there has been an update on the libraries and trigger your pipeline.</p> <p>You will agree that the use of Azure DevOps Libraries is not very suitable for use with specific pipelines per environment.</p> <p>Note</p> <p>If you are all the same motivated to do this, here are the Azure DevOps APIs that you will have to use:</p> <ul> <li>Azure DevOps API : Get Variables Groups,</li> <li>Azure DevOps API : Run Pipeline</li> </ul>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#deploy-your-configuration-using-folders-in-your-git-repository","title":"Deploy your configuration using folders in your git repository","text":"<p>If you have made the choice to use separate folders and files for each environment in your git repository, the implementation will be much easier. Indeed, you can specify in your pipeline the folders to include or exclude from the trigger. Therefore, if you modify your configuration for a single environment, only the files in the folder corresponding to your environment will be modified.</p> <p>Your environment-specific pipeline will look like this:</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n  paths :\n    include :\n    - YOUR_ENV/*\n\nstages:\n- stage: Prepare\n  displayName: Prepare\n  jobs:  \n  - job: PrepareConfiguration\n    displayName: Prepare configuration\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    # \n    # Define steps to prepare configuration for each environnments\n    #\n    # Publie l'artefact\n    - task: PublishBuildArtifacts@1\n      displayName: 'Publish Artifact: drop'\n- stage: Deploy\n  displayName: Deploy YOUR_ENV\n  dependsOn: Prepare  \n  jobs:\n  - deployment: DeployConfig\n    pool: \n      vmImage: 'ubuntu-latest'\n    environment: YOUR_ENV\n    workspace:\n      clean: all\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n            # \n            # Define steps to publish configuration for DEV environnment\n            #\n</code></pre> <p>And in order not to trigger the configuration pipeline common to the environments, it will be necessary to modify this one to exclude the triggering at the time of a modification specific to an environment. That is :</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n  paths :\n    exclude :\n    - YOUR_ENV/*\n</code></pre>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#deploy-your-configuration-using-git-repositories","title":"Deploy your configuration using git repositories","text":"<p>If you have chosen to use separate git repositories to manage the configuration of each environment, the solution is even simpler, you will only have to define your specific pipeline in each of your repositories.</p> <p></p> <p>For each of the specific pipelines, remember to reference the repository containing your common configuration. To do this, you will need to add in your yaml pipeline:</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n\nresources:\n  repositories:\n  - repository: common\n    type: git\n    name: YOUR_COMMON_REPOSITORY_NAME\n</code></pre> <p>And for your common pipeline, you will have to think about referencing the repos containing the environment-specific configurations. For instance :</p> <pre><code>trigger:\n  branches :\n    include :\n    - main\n    - release/*\n\nresources:\n  repositories:\n  - repository: DEV\n    type: git\n    name: YOUR_DEV_REPOSITORY_NAME\n  - repository: UAT\n    type: git\n    name: YOUR_UAT_REPOSITORY_NAME\n  - repository: PROD\n    type: git\n    name: YOUR_PROD_REPOSITORY_NAME\n</code></pre>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#conclusion","title":"Conclusion","text":"<p>Here is the proof that you can easily adopt a GitOps approach with Azure App Configuration and Azure DevOps. You have seen that not everything is perfect. It would have been nice to be able to trigger a pipeline following the modification of an Azure DevOps library. Maybe this feature will be available in future releases of Azure DevOps. By the way, how is it with the other competing product of Azure DevOps but also owned by Microsoft: Github?</p> <p>We will see this in the fourth part.</p> <p>To be continued...</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#references","title":"References","text":"<ul> <li>Azure DevOps : YAML schema reference for Azure Pipelines</li> </ul>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/gitops/03.gitops.AzureAppConfiguration/#thanks","title":"Thanks","text":"<p>Written by Philippe MORISSEAU, Published on May 25, 2022.</p>","tags":["DevOps","GitOps","CI/CD","d\u00e9veloppement","Azure","PaaS"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/","title":"Enabling Adoption of Fabric with Lemniscat (Part 1)","text":"<p>In my company, I am responsible, among other things, for providing Azure spaces (resource groups) for my colleagues to explore various Azure services, test Azure configurations, etc. Recently, with the release of Microsoft Fabric, I noticed an increasing demand for providing Azure spaces with Microsoft Fabric.</p> <p>The problem is that in my company, we have a dedicated tenant for all these experiments. My colleagues are therefore invited to this tenant to access Azure resources. And for the moment, Microsoft Fabric does not allow invited users to use the service.</p> <p>So I had to systematically create a specific account for them in the tenant to allow them to test Microsoft Fabric. This took me time and I didn't find it very practical.</p> <p>In parallel, I initiated a new open-source framework called Lemniscat. This framework allows creating and maintaining products oriented towards DevOps. In simple terms, this framework is a kind of \"Terraform for Terraform\" that allows building products that take into account the various aspects of a DevOps approach, oriented from a consumer point of view of the service.</p> <p>Back to our case of Microsoft Fabric. This service is very interesting because it offers a unified experience for data-related professions, from ingestion to presentation through transformation, machine learning, etc. It is a service that allows data engineering, data science, BI, etc. In short, it is a service that can interest many people.</p> <p>But as a user of this service, what do I need, finally?</p> <ul> <li>A Fabric capacity that I can instantiate on Azure.</li> <li>Access to this capacity to be able to use it.</li> <li>A working environment to be able to use this capacity (the Fabric Workspace).</li> <li>A Git repository to store my work artifacts (my notebooks, for example).</li> </ul> <p>In short, to offer a worthy experience to my colleagues, I must make all this available to them. And that's where Lemniscat comes in.</p> <p>In this article, I will show you how I was able to set up a Fabric capacity on Azure and give rights to this capacity to my colleagues using Lemniscat.</p> <p>Note</p> <p>In this article, I will not go into details about Lemniscat. If you want to learn more about Lemniscat, I invite you to check the documentation.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#using-terraform-to-deploy-fabric-capacity","title":"Using Terraform to Deploy Fabric Capacity","text":"<p>Because it's simple and it's a tool that everyone knows, I decided to use Terraform to deploy a Fabric capacity on Azure. However, I quickly encountered a problem: there is not yet a Terraform module to deploy a Fabric capacity on Azure. Fortunately, I found an example of Terraform that allows doing it. It's not ideal, as it is based on <code>azapi</code>, but it will do for now.</p> <p>In this example, I see that it is only planned to allow a single administrator per Fabric capacity. However, now it is possible to define multiple administrators per capacity. It's okay, we'll make a small modification to allow several of my colleagues to use the same Fabric capacity.</p> <p>main.tf <pre><code>resource \"azapi_resource\" \"fab_capacity\" {\n  type                      = \"Microsoft.Fabric/capacities@2022-07-01-preview\"\n  name                      = var.basename\n  parent_id                 = var.resource_group_id\n  location                  = var.location\n  schema_validation_enabled = false\n\n  body = jsonencode({\n    properties = {\n      administration = {\n        members = var.admins_email\n      }\n    }\n    sku = {\n      name = var.sku,\n      tier = \"Fabric\"\n    }\n  })\n  tags = var.tags\n}\n</code></pre></p> <p>variables.tf <pre><code>variable \"location\" {\n  type        = string\n  description = \"Location of the resource group.\"\n}\n\nvariable \"tags\" {\n  type        = map(string)\n  default     = {}\n  description = \"A mapping of tags which should be assigned to the deployed resource.\"\n}\n\nvariable \"sku\" {\n  type        = string\n  default     = \"F2\"\n  description = \"SKU name\"\n}\n\nvariable \"admins_email\" {\n  type        = list(string)\n  description = \"Fabric administrators email\"\n}\n</code></pre></p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#adding-user-account-creation","title":"Adding User Account Creation","text":"<p>Now that we have our Fabric capacity, we need to create user accounts that can use it.</p> <p>Note</p> <p>Currently, Microsoft Fabric does not allow the use of guest users. Thus, users must be in the Azure tenant to be able to access it.</p> <p>So I have to create accounts on the fly for my colleagues. Once again, I will use Terraform for this.</p> <p>Additionally, I need to generate a temporary password for each user. To do this, I will use a Terraform module that will allow me to generate a random password.</p> <pre><code>resource \"random_password\" \"password\" {\n  length             = var.length\n  special            = var.special\n  override_special   = var.overrideSpecial \n}\n</code></pre> <p>Once I have generated the password, I will create a user account for each user. <pre><code>resource \"azuread_user\" \"account\" {\n  for_each              = { for u in var.users : u.login =&gt; u }\n  user_principal_name   = \"${each.key}.${var.FABRICNAME}@${var.domainName}\"\n  display_name          = each.value.name\n  mail_nickname         = each.key\n  force_password_change = true\n  password              = module.adminPassword[each.key].password\n\n  lifecycle {\n    ignore_changes      = [usage_location]\n  }\n}\n</code></pre></p> <p>When creating a user account, it is necessary for the user to change their password at the first login. That's why I added <code>force_password_change = true</code>.</p> <p>Warning</p> <p>As soon as our user connects to Fabric, the <code>usage_location</code> attribute will be updated. That's why I added <code>ignore_changes = [usage_location]</code> in the <code>lifecycle</code> block. Indeed, this attribute cannot be set back to <code>null</code> (see: https://registry.terraform.io/providers/hashicorp/azuread/latest/docs/resources/user#usage_location?WT.mc_id=AZ-MVP-5004832).</p> <p>So now we have our Fabric capacity and our users.</p> <p>However, if we want to offer an optimal experience to our colleagues, we also need to create a working environment for them (the Fabric Workspace) and a Git repository to store their work.</p> <p>Unfortunately, there is no Terraform module available, and <code>azapi</code> cannot help us. We need to find another solution.</p> <p>This is a realization I have had many times. There are things that can be done with Terraform and others that cannot. That's where Lemniscat comes in.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#using-lemniscat-to-orchestrate-all-this","title":"Using Lemniscat to Orchestrate All This","text":"<p>Lemniscat is a framework that allows creating and maintaining products oriented towards DevOps. It allows designing products that take into account the various aspects of a DevOps approach, oriented from the consumer's point of view of the service.</p> <p>Lemniscat works from a manifest that describes the product. This manifest describes how the product should be instantiated, but also how it should be destroyed. This last point is particularly handy in my case. Indeed, I want to allow my colleagues to discover Microsoft Fabric, but I don't want them to leave their capacity indefinitely active. We still have a limited budget, and it is important that as many of my colleagues as possible can benefit from Azure. With Lemniscat, I can define the product destruction procedure.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#initializing-the-lemniscat-manifest","title":"Initializing the Lemniscat Manifest","text":"<p>We will focus in this article on the creation of the Fabric capacity and the users. We will address in a future article the creation of the Fabric Workspace and the Git repository. In the Lemniscat framework, this corresponds to the operate capability.</p> <p>Here is the Lemniscat manifest for the Fabric capacity and the users: <pre><code>capabilities:\n  code: null\n  build: null\n  test: null\n  release: null\n  deploy: null\n  operate:\n    solutions: \n    - solution: Azure\n      tasks:\n        &lt;here we will create the operations to create the user accounts and the Fabric capacity&gt;\n\nrequirements:\n  - name: lemniscat.plugin.terraform\n    version: 0.2.5\n  - name: lemniscat.plugin.filetransform\n    version: 0.2.1\n</code></pre></p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#configuration-of-the-tfvars-file","title":"Configuration of the Tfvars File","text":"<p>I use Backstage to offer an optimal experience. So I created a form that allows requesting a Fabric capacity. I ask my colleagues for some information:</p> <ul> <li>The name of the Fabric capacity: <code>appName</code></li> <li>The power of the Fabric capacity: <code>skuName</code></li> <li>The list of users to create who will be Administrators of the Fabric capacity: <code>users</code></li> <li>The lifespan of the Fabric capacity: <code>delayBeforeCleanUp</code></li> <li>These parameters will be filled in a tfvars file that I will then use with Terraform. To do this, I will use the <code>filetransform</code> task of Lemniscat to complete the tfvars file.</li> </ul> <pre><code>- task: filetransform\n  displayName: 'Set tfvars'\n  steps:\n    - pre\n    - pre-clean\n  parameters:\n    folderPath: ${{ product.tfVarsPath }}\n    fileType: json\n    targetFiles: \"*.tfvars.json\"\n</code></pre> <p>Once this task is executed, I have my tfvars file ready to be used by Terraform. For example:</p> <pre><code>{\n  \"appName\": \"myFabric\",\n  \"skuName\": \"F2\",\n  \"users\": [\n    {\n      \"name\": \"John Doe\",\n      \"login\": \"john.doe\",\n    },\n    {\n      \"name\": \"Jane Doe\",\n      \"login\": \"jane.doe\",\n    }\n  ],\n  \"delayBeforeCleanUp\": \"1h\"\n}\n</code></pre>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#creation-of-the-fabric-capacity-and-users","title":"Creation of the Fabric Capacity and Users","text":"<p>To create the Fabric capacity and users, I will use the Terraform plugin of Lemniscat. To initialize Terraform, I will use the <code>init</code> action.</p> <pre><code>- task: terraform\n  displayName: 'Terraform init'\n  steps:\n    - pre\n    - run\n    - pre-clean\n    - run-clean\n  parameters:\n    action: init\n    tfPath: ${{ product.tfPath }}\n    backend:\n      backend_type: azurerm\n      storage_account_name: ${{ nc.workspace.stName }}\n      container_name: tfstates\n      key: ${{ productInstanceName }}.${{ rgTags.product_name }}.tfstate\n</code></pre> <p>Then, I will use the <code>plan</code> action to check that everything is correct, and in particular to verify that the input parameters are correct.</p> <pre><code>- task: terraform\n  displayName: 'Terraform plan'\n  steps:\n    - pre\n  parameters:\n    action: plan\n    tfPath: ${{ product.tfPath }}\n    tfVarFile: ${{ product.tfVarsPath }}/${{ product.tfVarsFile }}\n    tfplanFile: ${{ product.tfPath }}/terrafom.tfplan\n</code></pre> <p>Finally, I will use the <code>apply</code> action to deploy the Fabric capacity and users. <pre><code>- task: terraform\n  displayName: 'Terraform apply'\n  steps:\n    - run\n  parameters:\n    action: apply\n    tfPath: ${{ product.tfPath }}\n    tfplanFile: ${{ product.tfPath }}/terrafom.tfplan\n</code></pre></p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#destruction-of-the-fabric-capacity-and-users","title":"Destruction of the Fabric Capacity and Users","text":"<p>Once the Fabric capacity and users have been created, it is necessary to think about destroying them (I remind you that my colleagues need this Fabric capacity temporarily). For this, I will use the <code>destroy</code> action of the Terraform plugin.</p> <pre><code>- task: terraform\n  displayName: 'Terraform destroy'\n  steps:\n    - run-clean\n  parameters:\n    action: destroy\n    tfPath: ${{ product.tfPath }}\n    tfVarFile: ${{ product.tfVarsPath }}/${{ product.tfVarsFile }}\n</code></pre>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#conclusion","title":"Conclusion","text":"<p>Of course, you will tell me that I am making my life complicated. I could have simply used Terraform for everything. And you're right.</p> <p>But as I mentioned at the beginning of this article, I also need to create a working environment (the Fabric Workspace) and a Git repository.</p> <p>In the next article, I will show you how I was able to create a working environment and a Git repository with Lemniscat to allow my colleagues to store their work.</p> <p>To be continued...</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/lemniscat/01.lemniscat.microsoftfabric/#references","title":"References","text":"<ul> <li>Sample Terraform for Microsoft Fabric</li> <li>Documentation terraform : azuread_user, limitation usage_location</li> <li>Lemniscat Framework Documentation</li> </ul> <p>Written by Philippe MORISSEAU, Published on March 30, 2024.</p>","tags":["DevOps","CI/CD","Azure","Microsoft Fabric"]},{"location":"en/articles/devops/vrille/","title":"Introduction","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>"},{"location":"en/articles/devops/vrille/#au-secours-le-devops-part-en-vrille","title":"Au secours, le DevOps part en vrille !","text":"<p>Cela fait maintenant des ann\u00e9es que je travaille avec la d\u00e9marche DevOps. Je parle bien de la d\u00e9marche, car tout comme l'agilit\u00e9, le DevOps ne se limite pas \u00e0 de l'outillage ou \u00e0 des m\u00e9thodes. L'objectif du DevOps est de faire sauter les silos entre le Build et le Run des applications. Il s'agit d'une solution permettant \u00e0 l'agilit\u00e9 d'\u00eatre plus efficace.</p> <p>Mais dans le cas d'un projet d'application microservice complexe, la mise en place et surtout le maintient d'une d\u00e9marche DevOps est bien plus complexe. On arrive aux limites du DevOps tel que l'on peut l'apprendre dans la literrature. </p> <p>Mais alors, le DevOps a ses limites et ne peut donc pas s'appliquer partout ? NON. Il faut juste reprendre un peu de hauteur, comprendre la d\u00e9marche et trouver les solutions qui permettent de passer au-del\u00e0 des limites.</p> <p>Dans cette s\u00e9rie nous aborderons :</p> <ul> <li>le pourquoi arrive-t-on aux limites, </li> <li>le comment passe-t-on au-del\u00e0 des limites,</li> <li>et enfin, pour que cela ne reste pas que de la th\u00e9orie, une preuve que l'on peut aller plus loin.</li> </ul>"},{"location":"en/articles/devops/vrille/#partie-1-pourquoi-arrive-t-on-aux-limites-du-devops","title":"Partie 1 : Pourquoi arrive-t-on aux limites du DevOps ?","text":"<ul> <li>Chapitre 1 : L'agilit\u00e9</li> <li>Chapitre 2 : Le DevOps</li> <li>Chapitre 3 : L'entropie</li> </ul>"},{"location":"en/articles/devops/vrille/#partie-2-comment-passe-t-on-au-dela-des-limites","title":"Partie 2 : Comment passe-t-on au-del\u00e0 des limites ?","text":"<ul> <li>Chapitre 1 : La machine \u00e0 \u00e9tat</li> <li>Chapitre 2 : Le build</li> <li>Chapitre 3 : Le d\u00e9ploiement</li> </ul>"},{"location":"en/articles/devops/vrille/#partie-3-cest-possible-la-preuve","title":"Partie 3 : C'est possible, la preuve !","text":"<ul> <li>La preuve, conclusion</li> </ul>"},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/","title":"Chapitre 1 : L'agilit\u00e9","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/#lagilite","title":"L'agilit\u00e9","text":"<p>Bien que l'agilit\u00e9 ne soit pas un pr\u00e9-requis au DevOps et vice-versa, l'un et l'autre sont bien plus efficaces s'ils sont utilis\u00e9s conjointement.</p> <p>Imaginons que nous avons un nouveau projet d'application bas\u00e9 sur une architecture microservice plut\u00f4t complexe. Ce projet est conduit avec la m\u00e9thode agile. Nous d\u00e9finissons les r\u00e8gles suivantes :</p> <ol> <li>Les it\u00e9rations ont une dur\u00e9e de 3 semaines,</li> <li>La recette fonctionnelle doit \u00eatre faite par une \u00e9quipe m\u00e9tier ind\u00e9pendante de l'\u00e9quipe de r\u00e9alisation,</li> <li>Les tests d\u2019int\u00e9gration sont inclus dans le Definition Of Done de l\u2019\u00e9quipe de r\u00e9alisation,</li> <li>Les d\u00e9lais doivent \u00eatre r\u00e9duit au maximum.</li> </ol> <p>Les 2 derniers points pouvant \u00eatre r\u00e9solus par le DevOps, cette d\u00e9marche apparait comme \u00e9vidente. Mais dans le cas o\u00f9 nous avons plusieurs dizaines de microservices, le DevOps n'est pas si simple que cela \u00e0 mettre en oeuvre.</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/#lagilite-et-le-devops","title":"L'agilit\u00e9 et le DevOps","text":"<p>Reprenons notre exemple avec des it\u00e9rations de 3 semaines et imaginons le cycle de vie de nos UserStory.</p> <p>La premi\u00e8re \u00e9tape consiste \u00e0 Groomer nos UserStory afin que l'\u00e9quipe puisse engager sereinement celles-ci dans le sprint.</p> <p></p> <p>Cela veut aussi dire que nos UserStory doivent \u00e0 minima \u00eatre Groom\u00e9es un sprint avant d'\u00eatre engag\u00e9es par l'\u00e9quipe de r\u00e9alisation.</p> <p></p> <p>Les tests d'int\u00e9gration \u00e9tant inclus dans le Definition Of Done de l'\u00e9quipe de r\u00e9alisation, cela veut donc dire que durant l'it\u00e9ration l'\u00e9quipe devra \u00e0 minima d\u00e9ployer une fois sur un environnement d'int\u00e9gration (dans notre cas, nomm\u00e9 DEV) pour chaque UserStory.</p> <p></p> <p>A la fin de l'it\u00e9ration l'\u00e9quipe de r\u00e9alisation va pr\u00e9senter son travail ; l'ensemble des UserStory r\u00e9alis\u00e9es (la d\u00e9mo.). Suite \u00e0 cette pr\u00e9sentation et apr\u00e8s validation des UserStory, l'\u00e9quipe va pouvoir proc\u00e9der au d\u00e9ploiement sur l'environnement de recette fonctionnelle (dans notre cas, nomm\u00e9 UAT).</p> <p></p> <p>Si durant la recette m\u00e9tier de notre UserStory un bug bloquant est d\u00e9tect\u00e9, alors il faudra proc\u00e9der \u00e0 un hotfix. Donc \u00e0 minima nous aurons un d\u00e9ploiement en UAT par sprint. Une fois la recette m\u00e9tier r\u00e9alis\u00e9e et l'ensemble des UserStory valid\u00e9es par notre \u00e9quipe m\u00e9tier, l'\u00e9quipe peut donc proc\u00e9der au d\u00e9ploiement en production.</p> <p></p> <p>Ainsi on peut constater :</p> <ul> <li>qu'il nous faut environ 9 semaines entre le moment ou l'on a groom\u00e9 notre UserStory et le moment ou celle-ci est disponible en production. Certes, en imaginant un grooming efficace et une recette m\u00e9tier rapide, on peut r\u00e9duire \u00e0 4 ou 5 semaines. Cela reste fictionnel !</li> <li>qu'il faudra multiplier les d\u00e9ploiements durant tout le cycle. Et pour peu que nos UserStory impactent plusieurs microservices, c'est autant de d\u00e9ploiements de microservices qu'il faudra r\u00e9aliser une ou plusieurs fois pour chaque environnement.</li> </ul>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/#les-features-flags","title":"Les features flags","text":"<p>L'utilisation de feature flag peut \u00eatre un tr\u00e8s bon moyen pour r\u00e9soudre notre probl\u00e9matique de d\u00e9lai. En effet, on peut imaginer que les UserStory soient d\u00e9ploy\u00e9es au fil de l'eau de leurs r\u00e9alisations et sans attendre la fin de l'it\u00e9ration sur les environnements de recette m\u00e9tier (UAT) et de production.</p> <p></p> <p>On peut m\u00eame imaginer de se passer de nos environnements de recette int\u00e9gration (DEV) et m\u00e9tier (UAT) et de d\u00e9ployer directement en production en mode partiellement cach\u00e9 (limit\u00e9 \u00e0 l'\u00e9quipe de r\u00e9alisation et de recette m\u00e9tier). </p> <p>L'utilisation de feature flag implique que nos microservices qui impl\u00e9mentent nos UserStory doivent permettre d'activer ou de d\u00e9sactiver \u00e0 tout moment la nouvelle fonctionnalit\u00e9 (ou de permettre d'\u00e9xecuter en m\u00eame temps plusieurs versions d'un m\u00eame microservice). Cela entraine plus de complexit\u00e9 au niveau de l'impl\u00e9mentation et/ou de l'infractructure. Certes, il existe des frameworks permettant de simplifier l'impl\u00e9mentation et des services PaaS permettant de simplifier l'infrastructure.  Mais dans certains cas, l'utilisation de features flags est presque impossible \u00e0 mettre en place ou entra\u00eene une complexit\u00e9 technique et architecturale accrue. Par exemple :</p> <ul> <li>Les Workflows : Comment passer d'une version \u00e0 l'autre d'un design de workflow pour une m\u00eame instance ?</li> <li>Les ETL : Comment maintenir plusieurs versions d'une m\u00eame transformation de donn\u00e9es ? En multipliant les destinations ?</li> <li>Les Infrastructures : Comment maintenir plusieurs versions d'une infrastructure sur un m\u00eame environnement ? En multipliant les environnements ?</li> </ul>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/#en-resume","title":"En r\u00e9sum\u00e9","text":"<p>Bien que les feature flag permettent en partie de r\u00e9soudre nos probl\u00e9matiques, elles ne sont pas \u00e0 elles seules la r\u00e9ponse \u00e0 notre probl\u00e9matique de mise en place du DevOps dans une architecture microservice complexe. Tr\u00e8s souvent, pour des raisons \u00e9conomiques \u00e9videntes, les feature flags sont mises de cot\u00e9.</p> <p>Ne pouvant pas forc\u00e9ment r\u00e9duire encore plus nos d\u00e9lais, il faudra donc se concentrer sur la multitude des d\u00e9ploiements \u00e0 r\u00e9aliser (en automatique) en veillant \u00e0 ne pas oublier une partie !</p> <p>Nous verrons dans le prochain chapitre que la d\u00e9marche DevOps peut elle aussi apporter au projet son lot de probl\u00e9matiques.</p> <p>A suivre...</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Martin Fowler - Feature Toggles (aka Feature Flags)</li> </ul>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/01.pourquoi.agilite/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 04 Octobre 2021</p>","tags":["DevOps","Agile","feature flag","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/","title":"Chapitre 2 : Le DevOps","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#le-devops","title":"Le DevOps","text":"<p>La d\u00e9marche DevOps, comme on peut la comprendre dans la litt\u00e9rature trouve ses limites dans des projets microservices complexes.</p> <p>Imaginons que nous avons un nouveau projet d'application bas\u00e9 sur une architecture microservice plut\u00f4t complexe. Ce projet souhaite avoir une d\u00e9marche Full DevOps.</p> <p>Info</p> <p>J'utilise r\u00e9guli\u00e8rement le terme Full DevOps pour indiquer qu'il n'y a aucun livrable du projet qui ne soit pas int\u00e9gr\u00e9 enti\u00e8rement dans la d\u00e9marche DevOps. Cela inclus donc les d\u00e9marches GitOps, DevSecOps, Dev{andMore}Ops, MLOps, DataOps, xOps, ...</p> <p>Note</p> <p>Dans la suite de cet article, je vais utiliser r\u00e9guli\u00e8rement le terme de composant pour repr\u00e9senter l'ensemble des \u00e9l\u00e9ments \u00e0 d\u00e9ployer (infrastructure, microservices, ...).</p> <p>Nous d\u00e9finissons les r\u00e8gles suivantes :</p> <ol> <li>L\u2019infrastructure, le code, la documentation : Tout doit \u00eatre d\u00e9ploy\u00e9 automatiquement =&gt; Full DevOps</li> <li>En cas de souci lors du d\u00e9ploiement d\u2019un composant, ceux d\u00e9pendants doivent \u00eatre bloqu\u00e9s.</li> <li>Ne d\u00e9ployer en UAT que ce qui a \u00e9t\u00e9 valid\u00e9 en DEV.</li> <li>Ne d\u00e9ployer en PROD que ce qui a \u00e9t\u00e9 valid\u00e9 en UAT.</li> <li>Utiliser le branching model Trunk-Based Development.</li> </ol>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#linfrastructure-le-code-la-documentation-tout-doit-etre-deploye-automatiquement","title":"L\u2019infrastructure, le code, la documentation : Tout doit \u00eatre d\u00e9ploy\u00e9 automatiquement.","text":"<p>Comme je suis un \"fana.\" d'Azure, on va imaginer que notre projet de microservices doit \u00eatre d\u00e9ploy\u00e9 sur des services manag\u00e9s Azure. Il faudra donc d\u00e9ployer cette infrastructure pour pouvoir ensuite d\u00e9ployer nos microservices. Notre \u00e9quipe produisant aussi de la documentation (sp\u00e9cifications, sch\u00e9ma d'architecture, ...), on souhaite avoir une d\u00e9marche DevOps pour mettre \u00e0 jour notre documentation sur un portail.</p> <p></p> <p>Pour arriver \u00e0 cette fin nous allons nous appuyer sur les repository git.</p> <ul> <li>Notre infrastructure sera d\u00e9crite en InfraAsCode avec Terraform, Bicep ou ARM json.</li> <li>Le code de nos librairies sera r\u00e9parti dans des repository en fonction de son utilisation. Il n'est pas pertinent de mettre dans un repository \u00e0 part le code d'une librairie qui n'est destin\u00e9e qu'\u00e0 un seul microservice.</li> <li>Le code de nos microservices (application web, batch, services, ...) sera r\u00e9parti dans des repository.</li> </ul> <p>Dans chacun de ces repository nous aurons le code (InfraAsCode ou code \"classique\"), mais aussi la documentation d\u00e9crite en DocAsCode avec Markdown, AsciiDoc ou reStructuredText.</p> <p>Enfin pour chaque repository nous allons mettre en place un pipeline de CI/CD afin d'automatiser la compilation, la validation et le d\u00e9ploiement \u00e0 chaque commit.</p> <p></p> <p>Note</p> <p>Je ne parle pas ici de PipelineAsCode. Cette pratique que je recommande fortement dans la d\u00e9marche DevOps permet de d\u00e9crire le fonctionnement de notre pipeline de CI/CD. Personnellement, je conseille de n'avoir qu'un seul pipeline par repository et que celui-ci soit d\u00e9pos\u00e9 \u00e0 la racine. Cela permet de rapidement comprendre ce qui va \u00eatre d\u00e9clench\u00e9 lors d'un commit-push sans avoir la mauvaise surprise d'avoir d\u00e9clench\u00e9 un pipeline non d\u00e9sir\u00e9.</p> <p>Jusqu'ici, tout va bien.</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#les-dependances","title":"Les d\u00e9pendances","text":"<p>Le premier souci que l'on peut rencontrer se trouve au niveau du build. En effet, une librairie cr\u00e9\u00e9e dans le cadre d'un projet et pens\u00e9e pour \u00eatre utilis\u00e9e par plusieurs microservices ou par d'autres librairies aura son propre repository. Ce qui implique que des microservices et des librairies peuvent d\u00e9pendre de librairies. On ne pourra pas compiler un microservice si les librairies qui sont utilis\u00e9es par celui-ci ne sont pas disponibles.</p> <p>C'est ce que j'appelle : la d\u00e9pendance de compilation. </p> <p>Example</p> <ul> <li>La Lib2 utilise la Lib1,</li> <li>Le Batch1 utilise la Lib1,</li> <li>Les WebService1, WebService2 et Batch2 utilisent la Lib2 </li> </ul> <p>Afin de garantir la robustesse de la solution, je veux m'assurer qu'une \u00e9volution sur une librairie ne va pas provoquer une r\u00e9gression sur les librairies et les microservices qui d\u00e9pendent d'elle. Dans les pipelines de mes microservices je vais donc mettre en place un trigger sur le succ\u00e8s du build de ma librairie.</p> <p>Example</p> <p>La Lib2 est mise \u00e0 jour. Les WebService1, WebService2 et Batch2 qui utilisent la Lib2 doivent \u00eatre recompil\u00e9s et test\u00e9s afin de v\u00e9rifier la non-r\u00e9gression. </p> <p>Le second souci que l'on peut rencontrer se trouve au niveau du d\u00e9ploiement. En effet, pour d\u00e9ployer un microservice il parait \u00e9vident que son infrastructure doit \u00eatre d\u00e9ploy\u00e9 avant. Il peut aussi \u00eatre n\u00e9cessaire qu'un autre microservice soit d\u00e9ploy\u00e9 pour qu'un microservice soit op\u00e9rationnel (dans le cas des workflows par exemple).</p> <p>C'est ce que j'appelle : la d\u00e9pendance de d\u00e9ploiement.</p> <p>Example</p> <ul> <li>Les batchs et les webservices n\u00e9cessitent que l'infrastructure soit d\u00e9ploy\u00e9e.</li> <li>Le WebService2 pour fonctionner n\u00e9cessite que le WebService1 soit d\u00e9ploy\u00e9.  </li> </ul> <p>Encore une fois, afin de garantir la robustesse de la solution, je veux m'assurer que s'il y a un souci lors de d\u00e9ploiement d'un composant, que l'ensemble des composants qui en d\u00e9pendent et qui n\u00e9cessites d'\u00eatre d\u00e9ploy\u00e9s ne le soient pas.</p> <p>Example</p> <p>Le d\u00e9ploiement du WebService1 est en erreur, le WebService2 qui n\u00e9cessite d'\u00eatre d\u00e9ploy\u00e9 doit \u00eatre bloqu\u00e9.  </p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#le-cycle-de-mise-en-production","title":"Le cycle de mise en production","text":"<p>J'aime \u00e0 penser que les cr\u00e9ateurs du logo DevOps, le fameux symbole infini ou le 8 allong\u00e9 n'ont pas choisi ce logo de fa\u00e7on anodine. En effet, ils auraient pu choisir un cercle. Mais non...</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#la-boucle-de-rejet","title":"La boucle de rejet","text":"<p>La boucle de rejet consiste \u00e0 rejeter tous d\u00e9veloppements r\u00e9alis\u00e9s qui ne correspondent pas aux standards de qualit\u00e9 d\u00e9finis par l'\u00e9quipe. Ce qui veut dire qu'\u00e0 la sortie de la phase Test de notre boucle DevOps, en cas d'\u00e9chec, il faut passer directement \u00e0 la phase Plan pour corriger l'anomalie.</p> <p></p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#la-boucle-de-succes","title":"La boucle de succ\u00e8s","text":"<p>La boucle de succ\u00e8s consiste \u00e0 d\u00e9ployer sur l'environnement suivant le composant valid\u00e9 sur l'environnement actuel. Ce qui implique qu'\u00e0 la sortie de la phase Monitor de notre boucle DevOps en cas de succ\u00e8s (les tests d'int\u00e9gration, de performance ou fonctionnel sont concluant), on peut passer directement \u00e0 la phase Deploy pour proc\u00e9der au d\u00e9ploiement du composant sur l'environnement suivant.</p> <p></p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#ne-deployer-que-ce-qui-a-ete-valide","title":"Ne d\u00e9ployer que ce qui a \u00e9t\u00e9 valid\u00e9","text":"<p>Reprenons notre cycle Agile avec les diff\u00e9rentes phases de validation sur les environnements d'int\u00e9gration puis de recette m\u00e9tier.</p> <ul> <li>Pendant le sprint, chaque UserStory sera d\u00e9ploy\u00e9 sur l'environnement d'int\u00e9gration (DEV) afin de valider en continue les tests d'int\u00e9gration.</li> </ul> <p></p> <ul> <li>En fin de sprint, \u00e0 la suite de la d\u00e9mo. et de la validation des UserStory, les d\u00e9veloppements sont d\u00e9ploy\u00e9s sur l'environnement de recette m\u00e9tier (UAT).</li> </ul> <p></p> <ul> <li>A la fin de la recette m\u00e9tier, les d\u00e9veloppements sont d\u00e9ploy\u00e9s sur l'environnement de production.</li> </ul> <p></p> <p>On constate ainsi que l'on ne d\u00e9ploie que ce qui a \u00e9t\u00e9 valid\u00e9 sans pour autant repasser par les phases Plan, Code, Build et Test. On utilise \"la boucle de succ\u00e8s\". </p> <p>Note</p> <p>L'utilisation de feature flag nous permettra dans certain cas d'\u00e9viter un d\u00e9ploiement, mais ce n'est pas pour autant qu'il n'y aura pas de phase dans notre pipeline. Il faudra pr\u00e9voir \u00e0 la place du d\u00e9ploiement l'activation ou la d\u00e9sactivation de telle ou telle feature.</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#le-trunk-based-development","title":"Le Trunk-Based Development","text":"<p>Le Trunk-Based Development est un branching model git tr\u00e8s pl\u00e9biscit\u00e9 dans la communaut\u00e9 DevOps. Il a l'int\u00e9r\u00eat d'\u00eatre simple \u00e0 g\u00e9rer gr\u00e2ce \u00e0 son unique branche de d\u00e9veloppement et compatible avec le maintien op\u00e9rationnel de plusieurs versions techniques d'un composant, du fait de ses branches de release.</p> <p>Note</p> <p>Les branches de feature sont autoris\u00e9es mais doivent \u00eatre tr\u00e8s courtes dans le temps.</p> <p>Dans le cadre de notre cycle Agile, \u00e0 la fin de chaque sprint, nous allons tirer une branche de release pour chacune des librairies et chacun des composants qui ont \u00e9volu\u00e9 durant le sprint et qui ont \u00e9t\u00e9 valid\u00e9s durant la d\u00e9mo.</p> <p>Rappel des r\u00e8gles Agile du chapitre 1</p> <ol> <li>Les it\u00e9rations ont une dur\u00e9e de 3 semaines,</li> <li>La recette fonctionnelle doit \u00eatre faite par une \u00e9quipe m\u00e9tier ind\u00e9pendante de l'\u00e9quipe de r\u00e9alisation,</li> <li>Les tests d\u2019int\u00e9gration sont inclus dans le Definition Of Done de l\u2019\u00e9quipe de r\u00e9alisation,</li> <li>Les d\u00e9lais doivent \u00eatre r\u00e9duits au maximum.</li> </ol> <p>Ces branches de release vont contenir le code \"sanctuaris\u00e9\". Le code contenu dans ces branches a pass\u00e9 l'int\u00e9gralit\u00e9 des tests, des mesures de qualit\u00e9s et de s\u00e9curit\u00e9 impos\u00e9s par l'\u00e9quipe. Le code est stable.</p> <p></p> <p>C'est depuis la branche master, main ou trunk contenant le code en cours de d\u00e9veloppement que nos d\u00e9ploiements sur l'environnement d'int\u00e9gration (DEV) seront r\u00e9alis\u00e9s. Comme ce qui est en cours de d\u00e9veloppement est potentiellement instable, nous devons emp\u00eacher que ce qui est produit sur cette branche puisse \u00eatre d\u00e9ploy\u00e9 sur les environnements de recette m\u00e9tier ou de production.</p> <p>Et c'est depuis les branches de release que le code qui a \u00e9t\u00e9 pr\u00e9alablement valid\u00e9 (qualit\u00e9, s\u00e9curit\u00e9, fiabilit\u00e9, int\u00e9grit\u00e9, maintenabilit\u00e9, ...) et dit stable va pouvoir \u00eatre d\u00e9ploy\u00e9 sur les environnements de recette m\u00e9tier (UAT), puis de production. Si durant la recette m\u00e9tier (ou pire, en production), nous constatons une anomalie, celle-ci pourra \u00eatre corrig\u00e9e avec un Hotfix en utilisant des cherry-pick. Et pour garantir que ce qui est d\u00e9ploy\u00e9 en production est toujours fiable, \u00e0 chaque fois, le composant doit \u00eatre d\u00e9ploy\u00e9 et test\u00e9 auparavant sur les environnements d'int\u00e9gration, puis de recette m\u00e9tier.</p> <p></p> <p>Nous devons appliquer cette m\u00e9thodologie pour chaque repository (et donc chaque composant) de notre solution.</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#en-resume","title":"En r\u00e9sum\u00e9","text":"<p>Les d\u00e9pendances de compilations ou de d\u00e9ploiement, le cycle de mise en production et le branching model sont des facteurs cl\u00e9s de la mise en place d'une d\u00e9marche DevOps. Il est tr\u00e8s important lors de l'initialisation de votre projet de bien cadrer ces \u00e9l\u00e9ments qui peuvent parfois \u00eatre tr\u00e8s complexes \u00e0 r\u00e9ajuster en cours de route.</p> <p>Nous verrons dans le prochain chapitre un sujet que j'affectionne tout particuli\u00e8rement : \"L'entropie des syst\u00e8mes\". Et nous verrons que la d\u00e9marche DevOps n'\u00e9chappe pas \u00e0 la formule de Boltzmann.</p> <p>A suivre...</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/02.pourquoi.devops/#remerciements","title":"Remerciements","text":"<ul> <li>Samy Mameri : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 13 Octobre 2021</p>","tags":["DevOps","Agile","Infra as Code","Doc as Code","Branching model","CI/CD"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/","title":"Chapitre 3 : L'entropie","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#lentropie","title":"L'entropie","text":"<p>Comme pour tout, le temps fait son \u0153uvre. La d\u00e9marche DevOps n'y \u00e9chappe pas. Vous pouvez avoir une d\u00e9marche tr\u00e8s aboutie, au bout de plusieurs mois ou plusieurs ann\u00e9es, celle-ci aura naturellement du plomb dans l'aile.</p> <p>Reprenons notre projet d'application bas\u00e9 sur une architecture microservice plut\u00f4t complexe. Ce type d'application (souvent c\u0153ur m\u00e9tier) est vou\u00e9 \u00e0 \u00e9voluer r\u00e9guli\u00e8rement avec des nouvelles fonctionnalit\u00e9s, mais aussi des plus anciennes qu'il faut d\u00e9commissionner. Le choix d'une architecture microservice permet de simplifier l'ajout et le d\u00e9commissionnement de fonctionnalit\u00e9s en r\u00e9duisant le p\u00e9rim\u00e8tre de l'impact. Mais avec le temps, cela peut s'av\u00e9rer complexe \u00e0 g\u00e9rer au niveau de la d\u00e9marche DevOps.</p> <p>Sprint 0 \u00e0 3</p> <ol> <li>Durant le Sprint 0 l'\u00e9quipe initialise l'infrastructure permettant d'h\u00e9berger notre solution. A la fin de ce sprint, elle livre l'Infra (v1.0). </li> <li>Ensuite, au Sprint 1 l'\u00e9quipe r\u00e9alise les 2 premiers microservices web Web1 (v1.0) et Web2 (v1.0) et apporte d\u00e9j\u00e0 une petite \u00e9volution \u00e0 l'infrastructure Infra (v1.1). </li> <li>Puis, au Sprint 2 l'\u00e9quipe r\u00e9alise un microservice batch Batch1 (v1.0). Elle constate que certains d\u00e9veloppements r\u00e9alis\u00e9s pour le microservice Web1 peuvent \u00eatre r\u00e9utilis\u00e9s pour le Batch1. L'\u00e9quipe d\u00e9cide de cr\u00e9er une libraire contenant le code commun et de faire \u00e9voluer le microservice Web1 pour utiliser cette librairie. A la fin du sprint l'\u00e9quipe livre : Lib1 (v1.0), Batch1 (v1.0) et Web1 (v1.1). </li> <li>Et, au Sprint 3 avec le feedback des premiers utilisateurs, l'\u00e9quipe constate que le microservice Web2 n'est pas utilis\u00e9 et n'apporte rien \u00e0 la solution. Elle d\u00e9cide de d\u00e9commissionner celui-ci et de le remplacer par un autre microservice Batch2 (v1.0). Une faille de s\u00e9curit\u00e9 web ayant \u00e9t\u00e9 identifi\u00e9e sur la solution, l'\u00e9quipe d\u00e9cide de corriger celle-ci en modifiant l'infrastructure Infra (v1.2) et le microservice Web1 (v1.2). </li> </ol> <p>Vous pouvez constater que l'agilit\u00e9 et la d\u00e9marche DevOps permettent une tr\u00e8s grande flexibilit\u00e9-\u00e9volutivit\u00e9. Mais lorsque notre projet s'\u00e9tale sur des dizaines de sprints, cela peut vite d\u00e9router l'\u00e9quipe qui a besoin d'un minimum de stabilit\u00e9 pour maitriser l'int\u00e9gralit\u00e9 du code de la solution.</p> <p>Imaginons que notre \u00e9quipe arrive au Sprint 63 (Oui ! Pour le vivre actuellement chez un client, cela arrive). Il n'est pas compliqu\u00e9 d'imaginer qu'au bout de 63 it\u00e9rations notre application qui est maintenant compos\u00e9 d'une trentaines de microservices, a v\u00e9cue des milliers de builds et de d\u00e9ploiements. A chaque fin de sprint, il y a eu un nombre variables mais globalement croissant d'ajouts, d'\u00e9volutions ou de d\u00e9commissionements de microservices. Ces changements successifs vont avoir un impact d\u00e9l\u00e9t\u00e8re sur la d\u00e9marche DevOps. C'es l'entropie du DevOps !</p> <p></p> <p>Posez-vous la question</p> <p>Est-ce que je suis capable de red\u00e9ployer from scratch mon application \u00e0 l'\u00e9tat ou elle \u00e9tait il y a 4 ou 5 it\u00e9rations ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#le-cocktail-agilite-devops-entropie","title":"Le cocktail Agilit\u00e9 + DevOps + Entropie !","text":"<p>On constate que l'agilit\u00e9, la d\u00e9marche DevOps et le temps (l'entropie) apportent chacun leur lot de probl\u00e9matiques. Mais si l'on additionne tout cela, on obtient un cocktail difficile \u00e0 dig\u00e9rer.</p> <p>Sprint X</p> <p>La UserStory X dans le Sprint X impacte la librairie Lib2. L'\u00e9quipe proc\u00e9de \u00e0 l'\u00e9volution sur le tronc (on est en TBD). Suite \u00e0 la d\u00e9mo. celle-ci cr\u00e9e une nouvelle branche de release pour relivrer la librairie. </p> <p>Pour assurer la r\u00e9silience de la solution, on veut reconstruire l'ensemble des microservices utilisant cette librairie : Web1 et Web2 (d\u00e9pendance de build). L'\u00e9quipe doit relancer le pipeline de CI/CD des microservices \u00e0 partir de leur derni\u00e8re branche de release. </p> <p>Finalement, la UserStory X d\u00e9clenche la cr\u00e9ation d'une nouvelle version de la Lib2, mais aussi le red\u00e9ploiement de l'ensemble des microservices utilisant la libairie : Web1 et Web2. </p> <p>Sprint X+1</p> <p>Durant le Sprint suivant, la UserStory Y consiste \u00e0 cr\u00e9er un nouveau microservice Web3. Et pour h\u00e9berger ce nouveau microservice nous allons devoir mettre \u00e0 jour notre infrastructure (par exemple, instancier une nouvelle Azure WebApp). L'\u00e9quipe : </p> <ul> <li>cr\u00e9e une nouveau repository qui contiendra le code de notre microservice Web3.</li> <li>r\u00e9alise une \u00e9volution sur le tronc du repository de l'infrastructure.</li> </ul> <p>Apr\u00e8s la d\u00e9mo., l'\u00e9quipe cr\u00e9e une nouvelle branche de release pour livrer le microservice Web3 et l'\u00e9volution de l'infrastructure. Afin de pouvoir d\u00e9ployer le nouveau microservice elle doit aussi avoir au pr\u00e9alable d\u00e9ployer la mise \u00e0 jour de l'infrastructure (d\u00e9pendance de d\u00e9ploiement).</p> <p>Durant ce Sprint, l'\u00e9quipe de recette m\u00e9tier d\u00e9tecte une anomalie sur le service Web1 li\u00e9 \u00e0 la derni\u00e8re \u00e9volution de la Lib2, l'\u00e9quipe doit donc faire un hotfix sur le Web1. Elle proc\u00e8de \u00e0 la correction sur le tronc du repository. Puis une fois valid\u00e9e sur l'environnement d'int\u00e9gration, l'\u00e9quipe proc\u00e8de \u00e0 un cherry-pick des commits de correction sur la branche de release correspondant \u00e0 la version \u00e0 relivrer. Encore une fois il faut proc\u00e9der \u00e0 une validation sur l'environnement d'int\u00e9gration afin de s'assurer qu'il n'y a pas eu de regression, avant de pouvoir d\u00e9ployer sur l'environnement de recette m\u00e9tier. </p> <p>Suis-je capable de red\u00e9ployer from scratch mon application \u00e0 l'\u00e9tat du Sprint X ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#le-phenomene-daccumulation","title":"Le ph\u00e9nom\u00e8ne d'accumulation","text":"<p>Il y a pire encore... Reprenons l'exemple au-dessus de l'anomalie d\u00e9tect\u00e9e. L'\u00e9quipe de r\u00e9alisation ayant beaucoup de repository \u00e0 g\u00e9rer (Et m\u00eame si celle-ci maitrise parfaitement tout son code et sa d\u00e9marche) met plusieurs jours pour relivrer le hotfix en recette m\u00e9tier. L'\u00e9quipe m\u00e9tier va vouloir proc\u00e9der \u00e0 nouveau \u00e0 la recette, puis constate qu'elle arrive en fin de Sprint et d\u00e9cide donc de d\u00e9caler la recette de cette UserStory au Sprint suivant. On arrive l\u00e0 devant un dilemme : </p> <ol> <li>Doit-on livrer tous nos composants sauf celui-ci en production ? Ou, </li> <li>Doit-on conditionner la mise en production \u00e0 la validation de cette UserStory et donc d\u00e9caler la mise en production au Sprint suivant ?</li> </ol> <p>Dans certains cas, vous pourrez choisir l'option 1 et donc limiter le ph\u00e9nom\u00e8ne d'accumulation \u00e0 un seul composant. Mais dans d'autres cas, vous serez oblig\u00e9 de choisir l'option 2.</p> <p></p> <p>Les features flags</p> <p>L'utilisation de feature flags vous permet d'\u00e9viter ce ph\u00e9nom\u00e8ne.</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#conclusion","title":"Conclusion","text":"","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#1-le-nombre-de-deploiements","title":"1. Le nombre de d\u00e9ploiements","text":"<p>Plus l\u2019\u00e9quipe a la capacit\u00e9\u00a0de produire des UserStory dans un sprint plus le nombre de d\u00e9ploiement est important. Lorsque l\u2019on a plusieurs dizaines de microservices, comment s\u2019assurer qu\u2019aucune mise \u00e0 jour n\u2019a \u00e9t\u00e9 oubli\u00e9e ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#2-les-dependances","title":"2. Les d\u00e9pendances","text":"<p>Les composants d\u2019une architecture microservice pr\u00e9sentent des d\u00e9pendances. Mais lorsque l'on a des dizaines de d\u00e9pendances de builds, comment s\u2019assurer que chaque composant utilise la bonne version de celles-ci ? Lorsque l'on a des dizaines de d\u00e9pendances de d\u00e9ploiements, comment stopper tous les processus de mise \u00e0 jour des d\u00e9pendances en cas d\u2019\u00e9chec de d\u00e9ploiement d\u2019un composant ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#3-la-gestion-des-repository-git","title":"3. La gestion des repository Git","text":"<p>Si chaque composant et chaque libraire a son propre repository git, le projet d'application peut rapidement cumuler plusieurs dizaines de repository. Lors d'une mise en recette m\u00e9tier, comment s\u2019assurer que toutes les \u00e9volutions et corrections apport\u00e9es dans le Sprint vont \u00eatre embarqu\u00e9es par la cr\u00e9ation d'une branche sur les repository impact\u00e9s et uniquement ces derniers ? Comment maintenir le model branching sur tous les repository ? Comment maintenir le semantic versioning ?</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#4-les-cycles-de-recette","title":"4. Les cycles de recette","text":"<p>Les recettes m\u00e9tiers sont r\u00e9alis\u00e9es apr\u00e8s la d\u00e9mo. du sprint sur un environnement de validation par une \u00e9quipe de test. Comment s\u2019assurer que les r\u00e9alisations sont pouss\u00e9es rapidement et correctement (les points 1, 2 et 3) afin de permettre \u00e0 la recette de se passer dans les meilleures conditions ? En cas d'anomalie d\u00e9tect\u00e9es par l'\u00e9quipe de recette, comment relivrer rapidement le correctif afin de ne pas bloquer le cycle des recettes ?</p> <p>Mais alors, comment lutter contre l\u2019entropie tout en maintenant une m\u00e9thodologie agile soutenable ?</p> <p>Dans la prochaine partie, je vous pr\u00e9senterais une solution que j'ai \u00e9labor\u00e9 pour r\u00e9pondre \u00e0 ces probl\u00e9matiques en mettant en place des techniques, bas\u00e9es sur des concepts simples et \u00e9prouv\u00e9s tel que la machine \u00e0 \u00e9tat et les manifestes.</p> <p>A suivre...</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/03.pourquoi.entropie/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 26 Octobre 2021</p>","tags":["DevOps","Agile","Entropie"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/","title":"Chapitre 1 : La machine \u00e0 \u00e9tat","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Nous avons pu constater dans la premi\u00e8re partie qu'il y avait de multiples moyens pour faire \"partir en vrille\" la d\u00e9marche DevOps. Pour avoir \u00e9t\u00e9 confront\u00e9 \u00e0 ces probl\u00e9matiques, j'ai cherch\u00e9 un bon moment quel serait le meilleur moyen pour r\u00e9soudre ces diff\u00e9rents probl\u00e8mes. </p> <p>La solution est arriv\u00e9e lors d'une discussion en voiture avec un de mes coll\u00e8gues de travail. Je lui parlais de mes soucis de mise en UAT et de mise en PROD. Que j'avais pourtant mis en place une d\u00e9marche DevOps dans les r\u00e8gles de l'art mais que pourtant il me fallait facilement une journ\u00e9e pour r\u00e9aliser mes mises en UAT ou en PROD. </p> <p>Mon coll\u00e8gue me r\u00e9pond : \"T'as essay\u00e9 d'utiliser une machine \u00e0 \u00e9tat ?\"</p> <p>EUREKA !</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/#la-machine-a-etat","title":"La machine \u00e0 \u00e9tat","text":"<p>Voici un bref exemple d'une machine \u00e0 \u00e9tat :</p> <p>Imaginons que nous souhaitions d\u00e9finir le fonctionnement d'un film sur notre lecteur BluRay.  Le film \u00e0 3 \u00e9tats :</p> <ul> <li>Arr\u00eat\u00e9</li> <li>En cours (de lecture)</li> <li>En pause</li> </ul> <p>Pour passer d'un \u00e9tat \u00e0 un autre nous avons des actions :</p> <ul> <li>Lancer le film</li> <li>Stopper le film</li> <li>Mettre en pause</li> <li>Reprendre le film</li> </ul> <p>Nous repr\u00e9senterons alors notre machine \u00e0 \u00e9tat sous la forme du sch\u00e9ma ci-dessous.</p> <p></p> <p>La mod\u00e9lisation d'un syst\u00e8me sous forme d'une machine \u00e0 \u00e9tat permet de simplifier la compr\u00e9hension des diff\u00e9rents moyens possibles pour passer d'un \u00e9tat \u00e0 un autre.</p> <p>Ce que l'on n'a pas repr\u00e9sent\u00e9 ici mais qui est essentiel, c'est le d\u00e9clencheur. Dans le cas de notre film BluRay, ce sera le fait que l'utilisateur appuie sur tel ou tel bouton de sa t\u00e9l\u00e9commande.  Pour notre lecteur BluRay, nous aurons les d\u00e9clencheurs :</p> <ul> <li>Appuie sur Play</li> <li>Appuie sur Pause</li> <li>Appuie sur Stop</li> </ul> <p></p> <p>Appliquons maintenant cette mod\u00e9lisation \u00e0 notre d\u00e9marche DevOps. Ind\u00e9pendamment des microservices qui composent notre application, celle-ci \u00e0 ses propres \u00e9tats :</p> <ul> <li>Build\u00e9 : l'application est compil\u00e9e et livr\u00e9e mais pas encore d\u00e9ploy\u00e9e,</li> <li>D\u00e9ploy\u00e9 en DEV : l'application est d\u00e9ploy\u00e9e sur l'environnement d'int\u00e9gration,</li> <li>D\u00e9ploy\u00e9 en UAT : l'application est d\u00e9ploy\u00e9e sur l'environnement de recette m\u00e9tier,</li> <li>D\u00e9ploy\u00e9 en PROD : l'application est d\u00e9ploy\u00e9e en PROD</li> </ul> <p>Pour passer d'un \u00e9tat \u00e0 l'autre nous aurons les actions suivantes :</p> <ul> <li>Ex\u00e9cuter le build</li> <li>D\u00e9ployer en DEV</li> <li>D\u00e9ployer en UAT</li> <li>D\u00e9ployer en PROD</li> </ul> <p></p> <p>Certes l'exemple ci-dessus nous montre une machine \u00e0 \u00e9tat tr\u00e8s lin\u00e9aire. Mais ce qui va nous int\u00e9resser particuli\u00e8rement dans la notre ce sont les d\u00e9clencheurs et les conditions.</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/#letat-builde","title":"L'\u00e9tat \"Build\u00e9\"","text":"<p>Chaque composant \u00e0 son propre cycle DevOps et chacun peut influer sur le comportement global de l'application. Si l'\u00e9quipe d\u00e9cide de r\u00e9aliser une modification sur une librairie utilis\u00e9 par plusieurs composants, son build doit d\u00e9clencher le re-build de composants d\u00e9pendants (d\u00e9pendance de compilation). Ce qui veut dire que l'\u00e9v\u00e8nement d\u00e9clencheur au niveau du pipeline DevOps de la librairie sera le commit-push et en cas de succ\u00e8s du build de la librairie, ce sera celui-ci l'\u00e9v\u00e8nement d\u00e9clencheur des composants.</p> <p>Au niveau de l'application on consid\u00e9rera que l'application est build\u00e9e \u00e0 partir du moment o\u00f9 la librairie et tous les composants d\u00e9pendants seront build\u00e9s. Pour passer \u00e0 l'\u00e9tat \"Build\u00e9\", on a :</p> <ul> <li>Un \u00e9v\u00e8nement d\u00e9clencheur : Le commit sur le repo de la librairie,</li> <li>Une condition : Le succ\u00e8s du build de la librairie et des composants d\u00e9pendants.</li> </ul> <p>Evolution sur une librairie</p> <p>Au cours de mon sprint l'\u00e9quipe r\u00e9alise une \u00e9volution sur la libraire Lib1. Celle-ci est utilis\u00e9e par le composant Batch1. </p> <p>L'\u00e9v\u00e8nement d\u00e9clencheur est le commit sur le repo et la condition est le succ\u00e8s du build de notre librairie et de notre batch. </p> <p>Notre librairie \u00e9tant embarqu\u00e9e dans notre batch au moment de la compilation, celle-ci ne sera pas un livrable \u00e0 d\u00e9ployer.</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/#les-etats-deploye","title":"Les \u00e9tats \"D\u00e9ploy\u00e9\"","text":"<p>Pour pouvoir d\u00e9ployer notre composant sur un environnement, il faut au pr\u00e9alable s'assurer que l'environnement soit pr\u00eat \u00e0 l'accueillir (d\u00e9pendance de d\u00e9ploiement) :</p> <ul> <li>l'infra. est disponible, </li> <li>les composants avec lesquels il va communiquer sont op\u00e9rationnels.</li> </ul> <p>Il peut y avoir de multiples \u00e9v\u00e8nements d\u00e9clencheurs pour passer de notre \u00e9tat \"Build\u00e9\" \u00e0 notre \u00e9tat \"D\u00e9ploy\u00e9\" :</p> <ul> <li>Le fait d'\u00eatre dans l'\u00e9tat \"Build\u00e9\" : On parlera ici de d\u00e9ploiement automatique ou de continuous deployment.</li> <li>L'approbation par une ou plusieurs personnes.</li> <li> <p>La validation d'un ou plusieurs crit\u00e8res :</p> <ul> <li>UserStory \u00e0 l'\u00e9tat livr\u00e9e,</li> <li>Health Check,</li> <li>...</li> </ul> </li> </ul> <p>En termes de condition, on veillera \u00e0 s'assurer que les d\u00e9pendances de d\u00e9ploiement sont respect\u00e9es.</p> <p>Evolution sur une librairie et d\u00e9ploiement en DEV</p> <p>Reprenons notre exemple pr\u00e9c\u00e9dent. </p> <p>Notre composant Batch1 pour pouvoir fonctionner n\u00e9cessite que l'infrastructure soit d\u00e9ploy\u00e9e.</p> <p>Le fait que notre application soit \u00e0 l'\u00e9tat \"Build\u00e9\" est l'\u00e9v\u00e8nement d\u00e9clencheur pour proc\u00e9der au d\u00e9ploiement de notre Batch1 (D\u00e9ploiement continu). </p> <p>Les conditions pour passer d'un \u00e9tat \"D\u00e9ploy\u00e9\" \u00e0 un autre identique seront les m\u00eames peu importe l'environnement.</p> <p>Evolution sur une librairie et d\u00e9ploiement en UAT et en PROD</p> <p>Notre composant Batch1 pour pouvoir fonctionner en UAT ou en PROD n\u00e9cessite que l'infrastructure soit d\u00e9ploy\u00e9e (notre condition).</p> <p>L'\u00e9v\u00e8nement d\u00e9clencheur pour passer \u00e0 l'\u00e9tat d\u00e9ploy\u00e9 en UAT est la validation de notre d\u00e9mo. en fin de sprint.</p> <p>L'\u00e9v\u00e8nement d\u00e9clencheur pour passer \u00e0 l'\u00e9tat d\u00e9ploy\u00e9 en PROD est la validation de notre application \u00e0 la fin de la recette m\u00e9tier. </p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/#conclusion","title":"Conclusion","text":"<p>En prenant un peu de recul on s'aper\u00e7oit que notre machine \u00e0 \u00e9tat reprend les codes de notre cycle DevOps.</p> <p></p> <p>Ce qui veut dire que l'on a un cycle DevOps au niveau de notre application. Ce cycle doit pouvoir piloter les pipelines DevOps de tous nos composants et librairies. Il doit aussi s'assurer que les conditions (d\u00e9pendances de build et de d\u00e9ploiement) sont respect\u00e9es.</p> <p>Dans le prochain article nous verrons en d\u00e9tail comment mettre en place les conditions et les actions n\u00e9cessaires au pilotage des builds.</p> <p>A suivre... </p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/04.comment.machineetat/#remerciements","title":"Remerciements","text":"<ul> <li>Nicolas Giraud : pour l'id\u00e9e de la machine \u00e0 \u00e9tat</li> <li>Michael Maillot : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 08 Novembre 2021</p>","tags":["DevOps","Agile","machine \u00e0 \u00e9tat","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/","title":"Chapitre 2 : Le build","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Maintenant que nous avons conceptualis\u00e9 le principe de machine \u00e0 \u00e9tat dans un \"meta\" pipeline CI/CD, comment faire pour que le build de nos diff\u00e9rents composants puisse \u00eatre g\u00e9r\u00e9 de fa\u00e7on harmonieuse ?</p> <p>Comment faire pour s'assurer qu'une \u00e9volution sur une librairie va entrainer syst\u00e9matiquement la recompilation de composants utilisant cette librairie ?</p> <p>Comment faire pour ne recompiler que ce qu'il y a besoin de recompiler ?</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#la-conceptualisation-du-processus-de-build","title":"La conceptualisation du processus de build","text":"<p>Pour commencer, il nous faut un r\u00e9f\u00e9rentiel de build. </p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#le-referentiel-de-build","title":"Le r\u00e9f\u00e9rentiel de build","text":"<p>Ce r\u00e9f\u00e9rentiel aura pour unique but d'identifier chaque composant de notre application, avec :</p> <ul> <li>le nom du repository Git</li> <li>la derni\u00e8re version,</li> <li>l'id du commit Git li\u00e9 \u00e0 la derni\u00e8re version,</li> <li>les d\u00e9pendances du composant</li> </ul> <p>exemple</p> <p>Imaginons 2 librairies : Lib1 et Lib2. Lib2 d\u00e9pend de Lib1.</p> <p>Voici ce que pourrait donner notre r\u00e9f\u00e9rentiel au format yaml :</p> <pre><code>components:\n- name: lib1\n  version: 1.0\n  commit: 0123456789ab\n- name: lib2\n  version: 1.0\n  commit: 123456789abc\n  dependencies: \n  - lib1\n</code></pre> <p>Ce r\u00e9f\u00e9rentiel va \u00e9voluer au fur et \u00e0 mesure des it\u00e9rations pour correspondre exactement \u00e0 l'\u00e9tat souhait\u00e9 de tous les composants de l'application. Et pour permettre une historisation des \u00e9volutions au fur et \u00e0 mesure des it\u00e9rations, quoi de mieux qu'un repository Git. On va donc mettre notre r\u00e9f\u00e9rentiel de build dans un repo. que l'on va nommer \"meta\".</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#le-processus-de-build","title":"Le processus de build","text":"<p>Imaginons que j'apporte une modification sur mon r\u00e9f\u00e9rentiel de build, cela implique que j'ai ajout\u00e9, modifi\u00e9 ou supprim\u00e9 un ou plusieurs composants de mon application. Pour ne pas prendre de risque je vais donc parcourir chaque composant d\u00e9clar\u00e9 dans mon r\u00e9f\u00e9rentiel et pour chacun, v\u00e9rifier :</p> <ul> <li>s'il a d\u00e9j\u00e0 \u00e9t\u00e9 build\u00e9 : il n'y aura donc rien \u00e0 faire,</li> <li>s'il y a une mise \u00e0 jour : il faudra d\u00e9clencher le build du composant,</li> <li>s'il y a eu une mise \u00e0 jour d'une des d\u00e9pendances : il faudra red\u00e9clencher le build du composant,</li> <li>s'il y a eu un \u00e9chec d'une d\u00e9pendance : il ne faudra pas lancer le build.</li> </ul> <p>C'est comme un arbre o\u00f9 chaque composant correspond \u00e0 un noeud.</p> <p>exemple</p> <p>Imaginons que durant notre sprint nous ayons fait \u00e9voluer nos composants B, D, G et H.  Ci-dessous l'arbre de d\u00e9pendances correspondant : </p> <p>Lors de l'ex\u00e9cution de notre \"meta\" pipeline pour passer notre application \u00e0 l'\u00e9tat build\u00e9, il faudra :</p> <ul> <li>Ignorer les composants A et C,</li> <li>Compiler les composant B, D, G et H,</li> <li>Recompiler les composants E, F, I, J et K qui ont vu leurs d\u00e9pendances \u00e9voluer (v\u00e9rification de la non-r\u00e9gression)</li> </ul> <p>Si durant le processus, le composant H est en \u00e9chec (erreur remont\u00e9e lors de la compilation ou de l'ex\u00e9cution des tests unitaires), alors il faudra veiller \u00e0 stopper le processus et ne pas builder les composants d\u00e9pendants. Le composant K est donc bloqu\u00e9 par son pr\u00e9d\u00e9cesseur le composant H.</p> <p>Notre build applicatif peut se repr\u00e9senter sous la forme du processus ci-dessous : </p> <p></p> <p>Le processus va parcourir le r\u00e9f\u00e9rentiel de build en commen\u00e7ant par ceux qui n'ont pas de d\u00e9pendance, puis par ceux qui d\u00e9pendent de ces premiers, et ainsi de suite. </p> <p>Note</p> <p>Je vous recommande d'utiliser des processus parall\u00e8les pour parcourir l'arbre.</p> <p>exemple</p> <p>Si on reprend notre exemple ci-dessus, on aura par ordre de passage :</p> <ol> <li>A</li> <li>B et C</li> <li>D, E, F, G et H</li> <li>I, J, K</li> </ol> <p>Pour chaque composant,</p> <ol> <li>on v\u00e9rifie si celui-ci a d\u00e9j\u00e0 \u00e9t\u00e9 correctement build\u00e9 (commit d\u00e9j\u00e0 build\u00e9).</li> </ol> <p>Note</p> <p>Il existe une multitude de raisons, autres que le code en lui-m\u00eame, d'\u00e9chec d'un build. Par exemple : </p> <ul> <li>La saturation du disque dur de l'agent de build, </li> <li>L'indisponibilit\u00e9 d'un service utilis\u00e9 durant le build (sonarqube, artifactory, ...).</li> </ul> <p>Il faut pr\u00e9voir la possibilit\u00e9 de relancer le build en \u00e9chec ult\u00e9rieurement.</p> <ol> <li>si oui, on v\u00e9rifie que ses d\u00e9pendances n'ont pas \u00e9volu\u00e9.</li> <li>si c'est le cas, on passe au composant suivant. Sinon, on d\u00e9clenche le build.</li> <li>si celui-ci n'a pas d\u00e9j\u00e0 \u00e9t\u00e9 correctement build\u00e9, on d\u00e9clenche le build.</li> <li>on attend la fin du build et on r\u00e9cup\u00e8re le r\u00e9sultat.</li> <li>si le build est OK, on passe au composant suivant.</li> <li>si le build est KO, on stoppe le build des composants d\u00e9pendants.</li> </ol> <p>Une fois le r\u00e9f\u00e9rentiel totalement parcouru, on peut d\u00e9terminer l'\u00e9tat de notre application. Si tous les composants ont \u00e9t\u00e9 correctement build\u00e9s, alors on peut consid\u00e9rer que notre application est correctement build\u00e9e.</p> <p>Ainsi nous pouvons passer l'\u00e9tat de notre application \u00e0 \"Build\u00e9\".</p> <p></p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#le-pilotage-des-repositories-git","title":"Le pilotage des repositories Git","text":"<p>Cependant, pour pouvoir d\u00e9clencher le build de nos diff\u00e9rents composants, il va falloir piloter les repositories Git de chacun des composants.</p> <p>Par exemple, en fin de sprint et suite \u00e0 la validation par le client de la d\u00e9mo., je vais vouloir builder une version stable de l'ensemble des composants de l'application avec pour objectif de d\u00e9ployer les \u00e9volutions de l'application jusqu'en production. </p> <ul> <li>Si je suis en Trunk Based Developement, je vais vouloir cr\u00e9er des branches de release et poser des tags sur les repositories de mes composants.</li> <li>Si je suis en Github Flow, je vais vouloir poser des tags sur la branche main sur les repositories de mes composants.</li> </ul> <p>Dans le d\u00e9tail, l'\u00e9tape de d\u00e9clenchement du build va se d\u00e9composer comme ceci :</p> <p></p> <p>Nous devons d\u00e9clencher le pipeline CI/CD de nos composants pour pouvoir d\u00e9clencher nos builds !</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#le-pilotage-des-pipelines-de-cicd","title":"Le pilotage des pipelines de CI/CD","text":"<p>Mais pour pouvoir ensuite faire avancer les pipelines CI/CD de nos diff\u00e9rents composants, il va falloir identifier exactement les pipelines correspondants aux builds de ces derniers. Notre phase de Build doit donc g\u00e9n\u00e9rer un fichier manifeste permettant d'identifier les pipelines de chaque composant.</p> <p></p> <p>exemple</p> <p>Voici notre manifeste au format yaml :</p> <pre><code>components:\n  - name: web1\n    pipelineId: id1\n  - name: web2\n    pipelineId: id2\n  - name: infra\n    pipelineId: id3\n  - name: batch1\n    pipelineId: id4\n</code></pre>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#conclusion","title":"Conclusion","text":"<p>Nous avons vu dans ce chapitre comment g\u00e9rer le build des composants d'une application. Cette phase de notre \"meta\" pipeline va nous mettre \u00e0 disposition un manifeste qui nous permettra dans un second temps de piloter le d\u00e9ploiement de nos diff\u00e9rents composants. Nous verrons cela dans le prochain chapitre.</p> <p>A suivre... </p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/05.comment.build/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 08 D\u00e9cembre 2021</p>","tags":["DevOps","Agile","Continuous Integration","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/","title":"Chapitre 3 : Le d\u00e9ploiement","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Maintenant que nous avons r\u00e9ussi \u00e0 builder notre application, comment faire pour d\u00e9ployer tous ses composants (infra., microservices,...) correctement ?</p> <p>Comment faire pour stopper le processus de d\u00e9ploiement applicatif si le d\u00e9ploiement d'un des composants \u00e9choue ?</p> <p>Comment s'assurer de pouvoir faire un rollback de l'application avec seulement les composants impact\u00e9s ?</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#la-conceptualisation-du-processus-de-deploiement","title":"La conceptualisation du processus de d\u00e9ploiement","text":"<p>Pour commencer, il nous faut un r\u00e9f\u00e9rentiel de d\u00e9ploiement. </p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#le-referentiel-de-deploiement","title":"Le r\u00e9f\u00e9rentiel de d\u00e9ploiement","text":"<p>Ce r\u00e9f\u00e9rentiel aura pour but d'identifier chacun des composants \u00e0 d\u00e9ployer de notre application, avec :</p> <ul> <li>le nom du composant (du repository Git)</li> <li>les d\u00e9pendances du composant</li> </ul> <p>exemple</p> <p>Imaginons 2 applications web : WebFront et WebBack. WebFront d\u00e9pend de WebBack. Et tous les deux d\u00e9pendent de l'infra qui va les h\u00e9berger. </p> <p>Voici ce que pourrait donner notre r\u00e9f\u00e9rentiel au format yaml :</p> <pre><code>components:\n- name: webfront\n  dependencies:\n  - webback\n- name: webback\n  dependencies: \n  - infra\n</code></pre> <p>Ce r\u00e9f\u00e9rentiel va \u00e9voluer au fur et \u00e0 mesure des it\u00e9rations pour d\u00e9ployer ou d\u00e9commissionner les composants de l'application. Et donc nous allons mettre notre r\u00e9f\u00e9rentiel de d\u00e9ploiement dans le m\u00eame repository que notre r\u00e9f\u00e9rentiel de build.</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#le-processus-de-deploiement","title":"Le processus de d\u00e9ploiement","text":"<p>Imaginons qu'il y ai une mise \u00e0 jour du r\u00e9f\u00e9rentiel de build. Cela implique qu'il y a eu une mise \u00e0 jour d'un composant. Le processus de build va g\u00e9n\u00e9rer un nouveau manifeste avec l'ensemble des pipelines de CI/CD de chaque composant. A partir de ce manifeste, pour chaque environnement et chaque composant, il faut d\u00e9terminer :</p> <ul> <li>s'il n'est pas n\u00e9cessaire de le d\u00e9ployer (dans le cas d'une librairie par exemple) : il n'y aura donc rien \u00e0 faire,</li> <li>s'il a d\u00e9j\u00e0 \u00e9t\u00e9 d\u00e9ploy\u00e9 : il n'y aura rien \u00e0 faire aussi,</li> <li>s'il y a une mise \u00e0 jour \u00e0 d\u00e9ployer : il faudra d\u00e9clencher le d\u00e9ploiement du composant,</li> <li>s'il y a eu une erreur lors du d\u00e9ploiement d'une d\u00e9pendance : il ne faudra pas lancer le d\u00e9ploiement.</li> </ul> <p>Encore une fois, comme pour le processus de build, c'est comme un arbre o\u00f9 chaque composant correspond \u00e0 un n\u0153ud.</p> <p>exemple</p> <p>Imaginons que durant notre sprint nous ayons fait \u00e9voluer nos composants B, D, G.  Ci-dessous les arbres de d\u00e9pendances correspondants : </p> <p>Lors de l'ex\u00e9cution de notre meta-pipeline pour passer notre application \u00e0 l'\u00e9tat build\u00e9, le manifeste indique que des pipelines CI/CD ont \u00e9t\u00e9 d\u00e9clench\u00e9s pour les composants B, D, G mais aussi pour les composants E, F, I, J et K. Ensuite pour passer notre application \u00e0 l'\u00e9tat d\u00e9ploy\u00e9e sur notre environnement, il faudra :</p> <ul> <li>Ignorer les composants A, B, C, D, E, F, G et H qui n'ont pas besoin d'\u00eatre d\u00e9ploy\u00e9s,</li> <li>Ignorer les composants L et M qui ont \u00e9t\u00e9 d\u00e9j\u00e0 d\u00e9ploy\u00e9s,</li> <li>D\u00e9ployer les composants D, I, K et J.</li> </ul> <p>Si le d\u00e9ploiement du composant K est en \u00e9chec, alors il faudra veiller \u00e0 stopper le processus et ne pas d\u00e9ployer les composants d\u00e9pendants. Le composant J sera donc bloqu\u00e9 par son pr\u00e9d\u00e9cesseur le composant K.</p> <p>Notre d\u00e9ploiement applicatif peut se repr\u00e9senter sous la forme du processus ci-dessous : </p> <p></p> <p>Le processus va parcourir le r\u00e9f\u00e9rentiel de d\u00e9ploiement en commen\u00e7ant par ceux qui n'ont pas de d\u00e9pendance, puis par ceux qui d\u00e9pendent de ces premiers, et ainsi de suite. </p> <p>Note</p> <p>Je vous recommande d'utiliser des processus parall\u00e8les pour parcourir l'arbre.</p> <p>exemple</p> <p>Si on reprend notre exemple ci-dessus, on aura par ordre de passage :</p> <ol> <li>L</li> <li>D, I et K</li> <li>M et J</li> </ol> <p>Pour chaque composant,</p> <ol> <li>on recherche le composant dans le manifeste pour obtenir le pipeline associ\u00e9,</li> <li>on v\u00e9rifie si celui-ci a d\u00e9j\u00e0 \u00e9t\u00e9 correctement d\u00e9ploy\u00e9 (d\u00e9termin\u00e9 par l'\u00e9tat du pipeline).</li> </ol> <p>Note</p> <p>Comme il est possible que le d\u00e9ploiement du composant ne se passe pas correctement, il faut pr\u00e9voir la possibilit\u00e9 de relancer le d\u00e9ploiement en \u00e9chec ult\u00e9rieurement.</p> <ol> <li>si oui, on passe au composant suivant,</li> <li>si non, on d\u00e9clenche le d\u00e9ploiement du composant.</li> <li>on attend la fin du d\u00e9ploiement et on r\u00e9cup\u00e8re le r\u00e9sultat.</li> <li>si le d\u00e9ploiement est OK, on passe au composant suivant.</li> <li>si le d\u00e9ploiement est KO, on stoppe le d\u00e9ploiement des composants d\u00e9pendants.</li> </ol> <p>Une fois le r\u00e9f\u00e9rentiel totalement parcouru, on peut d\u00e9terminer l'\u00e9tat de notre application. Si tous les composants ont \u00e9t\u00e9 correctement d\u00e9ploy\u00e9s, alors on peut consid\u00e9rer que notre application est correctement d\u00e9ploy\u00e9e.</p> <p>Imaginons que nous ayons 3 environnements : DEV, UAT et PROD. Avec ce processus, nous pourrons passer notre application de l'\u00e9tat \"Build\u00e9\" \u00e0 \"D\u00e9ploy\u00e9 en DEV\".</p> <p></p> <p>Et le passage aux \u00e9tats \"D\u00e9ploy\u00e9 en UAT\" et \"D\u00e9ploy\u00e9 en PROD\" suivront le m\u00eame processus.</p> <p></p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#leffet-inattendu","title":"L'effet inattendu","text":"<p>Afin de pouvoir d\u00e9ployer nos composants, nous devons en plus des r\u00e9f\u00e9rentiels de build et de d\u00e9ploiement g\u00e9n\u00e9rer un manifeste afin d'identifier de fa\u00e7on unique les instances de pipeline de chacun des composants.</p> <p>A chaque fois que nous ex\u00e9cutons notre meta-pipeline, nous avons un nouveau manifeste qui est g\u00e9n\u00e9r\u00e9 au passage \u00e0 l'\u00e9tat build\u00e9 de notre application. </p> <p></p> <p>Le manifeste est une image exacte de notre application avec pour chacun des pipelines de CI/CD des composants :</p> <ul> <li>l'artifact contenant le code,</li> <li>la configuration pour chaque environnement.</li> </ul> <p>Coupl\u00e9 \u00e0 nos 2 r\u00e9f\u00e9rentiels qui d\u00e9crivent :</p> <ul> <li>la fa\u00e7on dont on doit builder les composants (r\u00e9f\u00e9rentiel de build),</li> <li>la fa\u00e7on dont on doit d\u00e9ployer tous les composants (r\u00e9f\u00e9rentiel de d\u00e9ploiement),</li> </ul> <p>Cela revient \u00e0 dire que l'on est en capacit\u00e9 de reconstruire notre application from scratch en d\u00e9ployant les composants dans le bon ordre et avec les bons param\u00e8tres d'environnement. Cela va simplifier et s\u00e9curiser grandement les op\u00e9rations de rollback.</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#conclusion","title":"Conclusion","text":"<p>L'utilisation conjointe du manifeste et du r\u00e9f\u00e9rentiel de d\u00e9pendance de d\u00e9ploiement, nous permet d'assurer le d\u00e9ploiment de tous les composants de notre architecture micro-service en limitant les risques d'oublis ou d'\u00e9checs en cascade. </p> <p>De plus, le manifeste g\u00e9n\u00e9r\u00e9 durant la phase de build de notre meta-pipeline nous permet aussi de red\u00e9ployer rapidement notre architecture micro-service \u00e0 l'\u00e9tat exacte d'une version pr\u00e9c\u00e9dente de notre application.</p> <p>Tout \u00e7a est beau mais reste purement th\u00e9orique. Pour prouver la valeur de notre id\u00e9e, je vous pr\u00e9senterais dans la prochaine et derni\u00e8re partie :</p> <ul> <li>notre impl\u00e9mentation,</li> <li>notre exp\u00e9rimentation et </li> <li>nos retours d'exp\u00e9riences. </li> </ul> <p>A suivre...</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#references","title":"R\u00e9f\u00e9rences","text":"","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/06.comment.deploy/#remerciements","title":"Remerciements","text":"<ul> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 04 Janvier 2022</p>","tags":["DevOps","Agile","Continuous Deployment","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/","title":"It is possible, the proof!","text":"<p>During the first part we detailed how we could reach the limits of DevOps and spin our approach. Then, in the second part, I explained to you an idea that would allow you to go beyond the limits. In this third part of a single chapter, I will present the concrete implementation of our idea.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#implementation","title":"Implementation","text":"","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#our-goals-through-the-implementation-of-our-idea","title":"Our goals through the implementation of our idea","text":"<p>Before rushing headlong into the realization of our idea, we must take a step back and ask ourselves the right questions. What should our solution bring?</p> <p>Our solution must allow the project team to:</p> <ul> <li>maintain an agile rhythm and ceremonies,</li> <li>simplify the deployment process,</li> <li>guarantee the quality of components over time.</li> </ul> <p>Our solution must offer the customer the possibility of:</p> <ul> <li>reduce the time between approval and Go Live,</li> <li>intervene quickly in the event of a breakdown,</li> <li>guarantee the quality of the application over time.</li> </ul>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#what-we-dont-want","title":"What we don't want","text":"<p>It is obvious that each client, each company, each project has its own organization. Our solution should not impose a specific organization. This would go against agility and the DevOps approach.</p> <p>Our solution should not constrain:</p> <ul> <li>to a branching model. Our solution must be compatible with Gitflow, GithubFlow, Trunk Based Development or custom processes.</li> <li>a production process. Each company having its own application delivery process with its own non-production environments, our solution must adapt to the organization and not the other way around.</li> <li>to a semantic versioning. Our solution must allow any type of semantic versioning: SemVer1.0, SemVer2.0, ...</li> <li>to a technical environment. Each business IS has its own ecosystem with its OS, its frameworks, its hosting solutions (cloud, on premise, etc.). Our solution should not impose a cloud host for example.</li> </ul> <p>In the end, our solution must be as \"agnostic\" as possible.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#the-choice-of-the-software-production-platform","title":"The choice of the software production platform","text":"<p>Having said that, our solution must still be anchored to a software production solution. Having a great affinity and a good knowledge of Microsoft's stack, my choice quickly fell on Azure DevOps Services, Microsoft's SaaS software factory.</p> <p>Azure DevOps Services offers the advantage of being able to integrate your own extensions (or those already available on the marketplace). You can :</p> <ul> <li>create your web extensions to increase the functionality of Azure DevOps interfaces in react,</li> <li>develop in powershell or in node.js your task extensions to increase the functionality of your CI/CD pipelines,</li> <li>define your own connections in order to secure and simplify communications between Azure DevOps and your services.</li> </ul> <p>In our case, we made 2 extensions:</p> <ul> <li> <p>A web extension to simplify updating the build repositories (cf. Part 2 - Chapter 2) and deployment (cf. Part 2 - Chapter 3) in:</p> <ul> <li>going through all the repositories,</li> <li>identifying the repositories that have evolved at a glance,</li> <li>selecting the integrated front repositories,</li> <li>defining the version of each component</li> </ul> </li> <li> <p>A task extension to simplify the orchestration of builds and deployments in our meta-pipeline by:</p> <ul> <li>integrating into a CI/CD pipeline,</li> <li>managing the semantic versioning defined in our build repository,</li> <li>taking into account the branching model of the project,</li> <li>managing build dependencies,</li> <li>managing manual or automatic approvals,</li> <li>managing deployment dependencies.</li> </ul> </li> </ul>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#the-web-extension","title":"The web extension","text":"<p>Here is the cinematic imagined in Azure DevOps for our user:</p> <p></p> <p>When arriving on the web extension, 2 tabs allow him to:</p> <ul> <li>to visualize all the git repositories of the project,</li> <li>to access the solution parameters.</li> </ul> <p>The settings tab will allow our user to be able to configure the solution in order to respond to the different project organizations.</p> <p></p> <ol> <li>Selection of the git repository containing the build and deployment repositories,</li> <li>Selection of the branch used to update the build and deployment repositories,</li> <li>Full path of the yaml file containing the build repository,</li> <li>Full path of the yaml file containing the deployment repository,</li> <li>Name of the application component branches from which the pipelines will be triggered,</li> <li>Indicates whether to identify the commits that have been cherrypicked to exclude them from the evolution search for a component (for example, in the case of Trunk Based Development , cherrypick are used to make hotfixes),</li> <li>Indicates whether you want to create a tag when you upgrade your component. If so, you can customize your tag, the \"{v}\" instruction corresponding to your version number. For example, if you define \"v{v}\" and the version number is \"1.0.1\" then your tag will be \"v1.0.1\".</li> <li>Indicates whether you want to create a branch when you upgrade your component. If so, you will be able to customize your branch. For example, if you enter release/{v}, then the version number will be prefixed with \"release/\" in your branch.</li> <li>Indicates whether you want to perform a merge on a branch when you upgrade your component. If yes, indicate the name of the branch towards which you wish to carry out your merge.</li> </ol> <p>Sample</p> <p>If the team uses the gitflow, then it will be necessary to carry out the following configuration: <pre><code>Pick commit from : \"main\"\nFind cherrypick : unchecked\nAutomatically create a new tag : checked\nAutomatically create a new branch : unchecked\nAutomatically merge with branch : unchecked\n</code></pre></p> <p>The git repositories visualization tab allows you to visualize all the repositories of your application and to have an instant overview of the components requiring a version upgrade.</p> <p></p> <p>Depending on the settings, the system will automatically determine if there have been updates (new commits) on the component's repository.</p> <p>The user has the final say and can decide to embed the component by checking the box and entering a version number.</p> <p>By default, the extension will take the last commit of the branch, but it is possible to select it by going to the details of commits.</p> <p></p> <p>Finally, the dependency management interface will allow you to define build and deployment dependencies.</p> <p></p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#the-task-extension","title":"The task extension","text":"<p>For the task extension, it must be as simple as possible to allow quick and easy integration.</p> <p>The number of parameters is therefore limited to the strict minimum:</p> <ul> <li>a selector to indicate whether you want to use the extension for the build or for the deployment,</li> <li>in order to avoid requisitioning all available build or deployment agents, a parameter to indicate the maximum number of agents to use in parallel,</li> <li>a parameter indicating the location of the build or release repository,</li> <li>a parameter indicating the location of the build manifest.</li> </ul> <p>Sample</p> <p>Here is an example of our build task in the meta-pipeline: <pre><code>steps:\n  - task: meta-pipeline-build-deploy-task@0\n    displayName: 'Meta-pipeline Task : Build'\n    inputs:\n        EnvironmentStage: Build\n        NbAgents: 3\n        Referential: '$(System.DefaultWorkingDirectory)\\build.yml'\n        BuildManifest: '$(Build.ArtifactStagingDirectory)\\manifest.yml'\n</code></pre></p> <p>Sample</p> <p>Here is an example of our meta-pipeline deployment task: <pre><code>steps:\n  - task: meta-pipeline-build-deploy-task@0\n    displayName: 'Meta-pipeline Task : Deploy'\n    inputs:\n        EnvironmentStage: Deploy   \n        NbAgents: 3\n        Referential: '$(System.DefaultWorkingDirectory)\\deploy.yml'  \n        BuildManifest: '$(Build.ArtifactStagingDirectory)\\manifest.yml'\n</code></pre></p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#choices","title":"Choices","text":"<p>Unfortunately, due to a lack of time and resources, we had to deprioritize features, particularly the web extension. For example, we haven't yet implemented the dependency configuration interface. However, this has less impact for experimentation. Indeed, the dependencies between the components are rarely modified. Editing the Yaml files (build and release) initially makes it possible to overcome this lack.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#the-experiment-the-first-feedback","title":"The experiment / The first feedback","text":"<p>Our solution has now been running for 18 months to manage a solution of more than 40 git repositories, as many CI pipelines and around 30 CI/CD pipelines. And the feedback is positive on several aspects.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#facilitation","title":"Facilitation","text":"<p>The facilitation lies in the existence of the meta-pipeline. This one plays the role of orchestra conductor by making sure to build and to deploy the components for us. The team and especially the tech. lead finds themselves relieved to have a new member who takes care of this for them. The team can now focus fully on implementing the components.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#speed","title":"Speed","text":"<p>The orchestration and parallelization of builds and deployments make it possible to optimize the CI/CD process as much as possible. As soon as a component is finished being built or deployed, our orchestrator automatically moves on to the next component. The team no longer needs to monitor notifications to trigger the deployment of the next component.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#reliability","title":"Reliability","text":"<p>The use of build and deployment repositories makes it possible to systematize the orchestration. Our conductor plays the score to the letter! In addition, automation reduces manual operations and therefore the risk of errors or omissions.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#traceability","title":"Traceability","text":"<p>The commits made at each repository modification, the meta-pipeline logs and the generation of the manifesto are all elements that allow for traceability:</p> <ul> <li>on all updates of components and their dependencies from commits made on the git repository,</li> <li>on what really happened during the execution of our meta-pipeline (which component failed and when?) from the logs,</li> <li>on all versions of each component at each execution of the meta-pipeline from the manifest.</li> </ul>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#reproductivity","title":"Reproductivity","text":"<p>Thanks to the manifest, it is possible to redeploy with less effort all the components of the application even to its previous state (several sprints before).</p> <p>Warning</p> <p>This does not mean that the solution allows you to manage all the rollback of your application, and in particular of your data. But if you are careful to take into account the scalability of your data models in the design of your components with or without tools (entity framework, liquibase, ...) you shouldn't have too many problems at the time of the rollback.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#conclusion","title":"Conclusion","text":"<p>For the moment, the solution we have put in place is still green. Admittedly, we have tested it for a long time with a client and many times on proof of concept, but from my point of view it still requires a certain number of adjustments and improvements to be brought up to date. available to everyone. If you wish to participate, contribute or react, I invite you to contact me privately via LinkedIn. I will be delighted to discuss with you.</p> <p>I think I have said everything on the subject during the 7 articles that make up this series. What should be remembered above all is that it is possible in all circumstances to apply a DevOps approach, whether for a very small monolithic application or a huge distributed application.</p> <p>The DevOps approach does not stop at setting up the CI/CD pipeline. This is an approach that will inevitably impact your organization: developers, architects, integrators, testers, operators, but also business representatives (Product Owner, Business Analyst). And for the latter, the Agility + DevOps couple takes on its full meaning.</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/devops/vrille/07.lapreuve/#thanks","title":"Thanks","text":"<ul> <li>Michael Maillot : for proofreading</li> <li>Laurent Mondeil : for proofreading</li> <li>Samy Mameri : for proofreading</li> <li>Oussama Mouchrit : for proofreading</li> <li>Nicolas Giraud : for the idea of \u200b\u200bthe state machine</li> <li>Fabrice Weinling : for proofreading</li> <li>Etienne Louise : for proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on February 08, 2022</p>","tags":["DevOps","Agile","Azure DevOps","CI/CD"]},{"location":"en/articles/exceptions/","title":"Introduction","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>"},{"location":"en/articles/exceptions/#azure-les-exceptions-qui-font-mal","title":"Azure, Les exceptions qui font mal !","text":"<p>Voici le premier volet d'une s\u00e9rie d'articles bas\u00e9 sur des retours d'exp\u00e9riences malheureux avec Azure. Il ne faut pas y voir une critique de la plateforme cloud, mais plut\u00f4t comprendre cette s\u00e9rie comme une occasion manqu\u00e9e et une possibilit\u00e9 pour Microsoft d'am\u00e9liorer encore son cloud Azure. Rien n'est parfait ! J'esp\u00e8re que cette s\u00e9rie vous permettra d'\u00e9viter les pi\u00e8ges dans lesquels nous sommes tomb\u00e9s, moi et mon \u00e9quipe.</p> <ul> <li>Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet</li> <li>Chapitre 2 : Azure Container Instance et Windows dans votre Vnet</li> <li>Chapitre 3 : Les firewall et les r\u00e9gions Azure</li> </ul>"},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/","title":"Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#larchitecture","title":"L'architecture","text":"<p>Parlons un peu de l'architecture que nous avions envisag\u00e9 de r\u00e9aliser. L'objectif est d'instancier des conteneurs via des Azure Container Instance \u00e0 partir d'image d\u00e9ploy\u00e9 dans un Azure Container Registry. Tout cela doit \u00eatre s\u00e9curis\u00e9 au niveau reseau dans un Virtual Network.</p> <p>D'un cot\u00e9 le service Azure Container Registry permet d'utiliser les Private Endpoint pour restreindre l'acc\u00e8s de son service de registre de conteneur \u00e0 un r\u00e9seau priv\u00e9. De l'autre, les Azure Container Instance peuvent \u00eatre d\u00e9ploy\u00e9s dans un r\u00e9seau priv\u00e9 virtuel. Donc, sur le papier le sch\u00e9ma d'architecture ci-dessous fonctionne... Ce n'est pas le cas.</p> <p></p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#lexception","title":"L'exception","text":"<p>Apr\u00e8s quelques tests infructueux, nous avons fait une petite recherche et d\u00e9couvert rapidement que l'utilisation d'un Private Endpoint pour un Azure Container Registry comportait quelques exceptions et notamment celle-ci : </p> <p>Extrait docs.microsoft.com</p> <p>Les instances de services Azure, notamment Azure DevOps Services, Web Apps et Azure Container Instances, ne peuvent pas non plus acc\u00e9der \u00e0 un registre de conteneurs dont l\u2019acc\u00e8s r\u00e9seau est restreint.</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#contournement","title":"Contournement","text":"<p>Les 2 services Microsoft ne pouvant \u00eatre utilis\u00e9s conjointement dans un r\u00e9seau priv\u00e9, 3 solutions s'offrent \u00e0 nous :</p> <ol> <li>Ne plus restreindre l'acc\u00e8s r\u00e9seau de notre Azure Container Registry.</li> </ol> <p></p> <ol> <li>Remplacer notre Azure Container Registry par une solution Container Registry Self Hosted </li> </ol> <p></p> <ol> <li>Remplacer nos Azure Container Instance par un cluster Azure Kubernetes Services par exemple.</li> </ol> <p></p> <p>Et il ne faut pas compter sur l'utilisation d'un Service Endpoint (en preview) puisque celui-ci ne permet pas non plus de r\u00e9cup\u00e9rer l'image depuis un Azure Container Instance.</p> <p>Extrait de docs.microsoft.com</p> <p>Les instances de services Azure, notamment Azure DevOps Services, Web Apps et Azure Container Instances, ne peuvent pas non plus acc\u00e9der \u00e0 un registre de conteneurs dont l\u2019acc\u00e8s r\u00e9seau est restreint.</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#conclusion","title":"Conclusion","text":"<p>Il n'y a pour le moment pas de contournement id\u00e9al.  Cependant, bien que la documentation Microsoft indique le contraire, il semblerait qu'il soit possible de tirer (pull) une image Linux via une Azure Web App depuis un Azure Container Registry en ajoutant dans les appsettings :</p> <p>WEBSITE_PULL_IMAGE_OVER_VNET=true</p> <p>C'est un d\u00e9but.</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#dans-la-serie","title":"Dans la s\u00e9rie","text":"<ul> <li>Chapitre 2 : Azure Container Instance et Windows dans votre Vnet</li> <li>Chapitre 3 : Les firewall et les r\u00e9gions Azure</li> </ul>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>D\u00e9ployer des instance de conteneur dans un r\u00e9seau virtuel Azure</li> <li>Connexion priv\u00e9e \u00e0 un registre de conteneurs Azure \u00e0 l\u2019aide d\u2019Azure Private Link</li> <li>Restreindre l\u2019acc\u00e8s \u00e0 un registre de conteneurs \u00e0 l\u2019aide d\u2019un point de terminaison de service dans un r\u00e9seau virtuel Azure</li> <li>Deploying Linux custom container from private Azure Container Registry</li> <li>ACR with private endpoint - Web Apps</li> </ul>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/01.azureException.acrAndAciInYourVnet/#remerciements","title":"Remerciements","text":"<ul> <li>Etienne Louise : pour la relecture</li> <li>David Dubourg : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 06 Septembre 2021</p>","tags":["Azure","virtual network","container registry","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/","title":"Chapite 2 : Azure Container Instance et Windows dans votre Vnet","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#le-scenario","title":"Le sc\u00e9nario","text":"<p>Vous souhaitez proposer des services ayant une dur\u00e9e de vie limit\u00e9, executable sous Linux ou Windows et isol\u00e9 dans votre Virtual Network. Par exemple : Des runners self-hosted pour github.</p> <p>On imagine donc une architecture avec des Azure Container Instance du style :   </p> <p></p> <p>Cela fonctionne pour nos conteneurs Linux mais pas pour nos conteneurs Windows... </p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#lexception","title":"L'exception","text":"<p>Apr\u00e8s quelques tests infructueux, nous avons fait une petite recherche et d\u00e9couvert rapidement que l'utilisation d'Azure Container Instance dans un Virtual Network comportait quelques exceptions et notamment celle-ci : </p> <p>Extrait docs.microsoft.com</p> <p>Actuellement, seuls les conteneurs Linux sont pris en charge dans un groupe de conteneurs d\u00e9ploy\u00e9 sur un r\u00e9seau virtuel.</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#contournement","title":"Contournement","text":"<p>Les Azure Container Instance ne permettant pas d'int\u00e9grer des conteneurs Windows dans votre Vnet, il ne nous reste que peu d'options :</p> <ol> <li>Microsoft avait annonc\u00e9 fin 2020 que cette fonctionnalit\u00e9 serait disponible d\u00e9but 2021. Si l'on admet un retard pris, on peut esp\u00e9rer que cette fonctionnalit\u00e9 sera bient\u00f4t disponible. Donc, la premi\u00e8re option est d'attendre.</li> <li>La seconde option, consiste \u00e0 remplacer notre Azure Container Instance par Azure Batch avec un pool Windows.</li> </ol> <p></p> <p>Vous pouvez aussi utiliser un AKS ou un VM Scale Set, mais de mon point de vue, c'est un peu \"overkill\".  </p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#conclusion","title":"Conclusion","text":"<p>Si vous \u00eates vraiment press\u00e9 par le temps ou vous doutez que Microsoft propose l'integration Vnet des Azure Container Instance Windows rapidement, je serais tent\u00e9 de vous orienter vers Azure Batch. Un service manag\u00e9 d'Azure pas assez mis en valeur \u00e0 mon go\u00fbt !</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#dans-la-serie","title":"Dans la s\u00e9rie","text":"<ul> <li>Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet</li> <li>Chapitre 3 : Les firewall et les r\u00e9gions Azure</li> </ul>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Ressources et sc\u00e9narios relatifs aux r\u00e9seaux virtuels</li> <li>Azure Container Instances (ACI) under the hood - Azure Friday</li> <li>Ex\u00e9cuter des applications de conteneur sur Azure Batch</li> <li>Utiliser des conteneurs Windows Server</li> </ul>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/02.azureException.aciWindowsWithVnet/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Oussama Mouchrit : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Etienne Louise : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 20 Septembre 2021</p>","tags":["Azure","virtual network","windows","container instance","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/","title":"Chapitre 3 : Les firewall et les r\u00e9gions Azure","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#le-scenario","title":"Le sc\u00e9nario","text":"<p>Vous souhaitez connecter un service PaaS ou SaaS Azure avec un Storage Account. M\u00eame si votre service est accessible publiquement (pas d'isolation r\u00e9seau), vous ne souhaitez pas exposer publiquement votre Storage Account. Vous savez que Microsoft vous permet de limiter l'exposition r\u00e9seau via les r\u00e8gles firewall de votre Storage Account. Vous whitlistez donc les IP de votre service. </p> <p>Sur le papier cela fonctionne parfaitement. Dans la r\u00e9alit\u00e9, ce n'est pas le cas...</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#lexception","title":"L'exception","text":"<p>Ce ph\u00e9nom\u00e8ne, j'ai pu l'observer. Il y a certainement d'autres cas similaires avec d'autres services Azure. Je vais vous pr\u00e9senter les 2 cas que j'ai pu rencontrer.</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#logicapp-et-storage-account","title":"LogicApp et Storage Account","text":"<p>Nous souhaitions d\u00e9clencher un workflow lorsqu'un nouveau fichier est d\u00e9pos\u00e9 dans un container blob de notre Storage Account. Nous d\u00e9cidons d'utiliser le service Logic Apps pour notre workflow. Nous ne voulions pas investir dans un Integration Service Environment (environ 720 \u20ac / mois) ou dans un Workflow Standard WS1 (environ 150 \u20ac / mois) afin d'isoler notre workflow.</p> <p>Mais afin de ne pas exposer notre Storage Account publiquement, nous souhaitions mettre une r\u00e8gle firewall sur celui-ci afin de n'autoriser que le service Logic Apps. </p> <p>Note</p> <p>Microsoft fournit la liste des IP sortantes des connecteurs Logic Apps : ici</p> <p>Naturellement, nous avions mis nos 2 services dans la m\u00eame r\u00e9gion Azure.</p> <p></p> <p>Erreur fatale ! Lorsque les 2 ressources Azure sont sur la m\u00eame r\u00e9gion, Microsoft va tr\u00e8s r\u00e9guli\u00e8rement (pas toujours !) privil\u00e9gier son r\u00e9seau interne pour router la communication. Ainsi notre Logic Apps va contacter notre Storage Account avec une adresse IP priv\u00e9e. </p> <p>\"Ce n'est pas grave \u00e7a ! Il suffit juste de whitelister les adresses IP priv\u00e9es !\" </p> <p>Eh bien non ! Vous ne pouvez pas mettre de r\u00e8gles firewall sur des plages IP priv\u00e9es. </p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#azure-devops-services-et-storage-account","title":"Azure DevOps Services et Storage Account","text":"<p>Nous souhaitions notifier un \u00e9v\u00e8nement depuis une extension Azure DevOps Services Agentless vers une queue de notre Storage Account. Encore une fois, afin de ne pas exposer notre Storage Account publiquement, nous voulions mettre une r\u00e8gle firewall sur celui-ci afin de n'autoriser que le service Azure DevOps Services.</p> <p>Note</p> <p>Microsoft fournit la liste des IP sortantes de Azure DevOps Services : ici</p> <p>Encore une fois, nous avons mis nos 2 services dans la m\u00eame r\u00e9gion Azure.</p> <p></p> <p>Je vous le donne en mille, Emile ! Lorsque nos 2 services Azure sont sur la m\u00eame r\u00e9gion, Microsoft va tr\u00e8s r\u00e9guli\u00e8rement privil\u00e9gier son r\u00e9seau interne pour router la communication. Ainsi notre Azure DevOps Services va contacter notre Storage Account avec une adresse IP priv\u00e9e. </p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#contournement","title":"Contournement","text":"<p>On pourrait penser que le probl\u00e8me vient uniquement de notre Storage Account qui ne permet pas d'identifier l'origine du service appelant. On pourrait se dire qu'avec l'utilisation de Service Tag on pourrait r\u00e9soudre notre probl\u00e8me. Malheureusement, non ! </p> <p>Les Service Tag permettent de simplifier la gestion des IP publiques des services Azure. En ajoutant un Service Tag \u00e0 notre firewall on va whitlister uniquement les IP publiques de celui-ci.</p> <p>Finalement, la seule solution de contournement simple est de changer la r\u00e9gion d'un des 2 services.</p> <p></p> <p>En utlisant 2 r\u00e9gions, on force nos services \u00e0 utiliser les IP publiques. les r\u00e8gles firewall peuvent donc \u00eatre appliqu\u00e9es.</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#conclusion","title":"Conclusion","text":"<p>J'avoue qu'utiliser plusieurs r\u00e9gions Azure pour \u00e9viter une exposition r\u00e9seau trop large d'un service est un peu affligeant.  Dans le cas des Logic Apps, si l'on a un petit peu de budget, je vous conseillerais d'utiliser un Workflow Standard WS1 afin d'isoler d'un point de vue r\u00e9seau notre service. Dans le cas d'Azure DevOps Services, \u00e9tant pour le moment uniquement publique, vous n'aurez pas beaucoup d'autres solutions.</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#dans-la-serie","title":"Dans la s\u00e9rie","text":"<ul> <li>Chapitre 1 : Azure Container Registry et Azure Container Instance dans votre Vnet</li> <li>Chapitre 2 : Azure Container Instance et Windows dans votre Vnet</li> </ul>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Managed connectors outbound IP addresses</li> <li>Azure DevOps Services - Adresses IP et URL de domaine autoris\u00e9es</li> <li>Azure IP Ranges and Service Tags \u2013 Public Cloud</li> </ul>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/exceptions/03.azureException.firewallAndRegion/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>David Dubourg : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 17 Octobre 2021</p>","tags":["Azure","virtual network","region","storage account","exception"]},{"location":"en/articles/tips/01.finops.ftpslowcost/","title":"L'astuce FinOps : Un serveur FTPS Low Cost","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Il arrive encore que des clients souhaitent utiliser le protocole FTP(S) pour transmettre des fichiers sur Azure. Vous aurez beau chercher sur le marketplace Azure, Microsoft ne propose pas nativement ce service en manag\u00e9. Il vous reste donc 2 options :</p> <ol> <li>Se cr\u00e9er son propre serveur FTP \u00e0 partir d'une VM ou d'une ACI (\u00e0 tester).</li> <li>Passer par un tiers qui vous mettra \u00e0 disposition ce service.</li> </ol> <p>Cela n\u00e9cessitera dans tous les cas un co\u00fbt non n\u00e9gligeable pour un service tr\u00e8s basique. N'y a-t-il pas une autre solution ?</p> <p>J'ai une solution !</p> <p>Je vais certainement faire hurler tous les puristes, mais il s'av\u00e8re que cette solution \u00e0 fait ses preuves et fonctionne parfaitement chez les clients depuis plus de 2 ans. Il suffit d'utiliser 2 services manag\u00e9s Azure : Une FunctionApp + Un StorageAccount.</p> <p></p>","tags":["Azure","ftps","finops"]},{"location":"en/articles/tips/01.finops.ftpslowcost/#une-solution-une-functionapp-en-tant-que-serveur-ftps","title":"Une solution : Une FunctionApp en tant que serveur FTP(S).","text":"<p>Pour d\u00e9ployer votre code source sur vos FunctionApp, vous avez plusieurs possibilit\u00e9s. L'un d'elle utilise un service FTP(S). L'id\u00e9e est donc de r\u00e9utiliser ce service de la FunctionApp pour en faire la fonctionnalit\u00e9 principale.</p> <p>Pour cela rien de plus simple, il faut :</p> <ol> <li>Cr\u00e9er une FunctionApp avec un service plan \"Free\" (Sku : Y1),</li> <li>Cr\u00e9er un StorageAccount (si vous n'en avez pas d\u00e9j\u00e0) qui sera votre espace de stockage,</li> <li>Configurer votre FunctionApp pour utiliser le StorageAccount. Il faut ajouter les param\u00e8tres suivant dans la section Application Settings :</li> </ol> <p><pre><code>  {\n    \"name\": \"AzureWebJobsDashboard\",\n    \"value\": \"[Endpoint StorageAccount]\",\n    \"slotSetting\": false\n  },\n  {\n    \"name\": \"AzureWebJobsStorage\",\n    \"value\": \"[Endpoint StorageAccount]\",\n    \"slotSetting\": false\n  },\n  {\n    \"name\": \"WEBSITE_CONTENTAZUREFILECONNECTIONSTRING\",\n    \"value\": \"[Endpoint StorageAccount]\",\n    \"slotSetting\": false\n  },\n  {\n    \"name\": \"WEBSITE_CONTENTSHARE\",\n    \"value\": \"MyFtpsLowCost\",\n    \"slotSetting\": false\n  },\n</code></pre> 4. R\u00e9cup\u00e9rer les param\u00e8tres de connexions \u00e0 votre FTP(s) en t\u00e9l\u00e9chargeant le profil de publication. </p> <p>Enfin, il faudra activer les \u00e9l\u00e9ments de s\u00e9curit\u00e9 (\u00e7a reste un pr\u00e9conisation) en :</p> <ul> <li>Autorisant uniquement le FTPS.</li> <li>Activant la restriction d'IP et de Vnet.</li> </ul>","tags":["Azure","ftps","finops"]},{"location":"en/articles/tips/01.finops.ftpslowcost/#conclusion","title":"Conclusion","text":"<p>Certe cette solution ne permet pas de g\u00e9rer plusieurs compte d'acc\u00e8s. Si vous avez plusieurs partenaires souhaitant utiliser un service FTP pour consommer ou transmettre des fichiers, vous devrez multiplier les FunctionApp.</p> <p>Mais ce qu'il faut retenir, c'est que :</p> <ul> <li>d'une part, ce service ne vous coutera rien ou presque rien (juste les co\u00fbts du StorageAccount).</li> <li>d'autre part, ce sera l'occasion d'inciter vos partenaires \u00e0 changer de m\u00e9thode pour consommer ou pousser des fichiers (API Rest,...).</li> </ul> <p>Note</p> <p>Dans mon exemple j'utilise une FunctionApp mais cela fonctionne tout aussi bien avec un WebApp.</p>","tags":["Azure","ftps","finops"]},{"location":"en/articles/tips/01.finops.ftpslowcost/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Azure Function Deploiement</li> </ul>","tags":["Azure","ftps","finops"]},{"location":"en/articles/tips/01.finops.ftpslowcost/#remerciements","title":"Remerciements","text":"<ul> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 04 Novembre 2020</p>","tags":["Azure","ftps","finops"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/","title":"CosmosDB : En attendant le partial update","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Cela fait maintenant : </p> <ul> <li>6 ans que cette id\u00e9e a \u00e9t\u00e9 remont\u00e9 \u00e0 Microsoft, </li> <li>2 ans et demi que le sujet est dans la roadmap de Microsoft, </li> <li>1 ans et demi que celui-ci est commenc\u00e9 et... </li> </ul> <p>toujours rien.</p> <p>Pourtant, cette fonctionnalit\u00e9 pourrait tout changer ! J'ai eu l'occasion de rencontrer des clients qui pour cette unique raison pr\u00e9f\u00e9raient partir sur MongoDB Atlas.</p> <p>Mais pourquoi cette fonctionnalit\u00e9 change tout ?</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#constat-atomicite-des-mises-a-jour-documentdb","title":"Constat : Atomicit\u00e9 des mises \u00e0 jour DocumentDB","text":"<p>Via le m\u00e9canisme de contr\u00f4le d\u2019acc\u00e8s concurrentiel optimiste (etag - Transactions optimistic concurrency) de l'api SQL, Microsoft garanti que les transactions envoy\u00e9es vers un Conteneur CosmosDB sont ACID. Mais \u00e0 y regarder de plus pr\u00e8s on constate que le classique \"UPDATE\" SQL n'est pas dans la liste des op\u00e9rations pris en charge. Mais comment faire une mise \u00e0 jour alors ?</p> <p>Aujourd'hui, pour faire une mise \u00e0 jour dans un conteneur CosmosDB, il faut :</p> <ol> <li>r\u00e9cup\u00e9rer le document, </li> <li>le mettre \u00e0 jour (merge entre la donn\u00e9e re\u00e7u et celle exitant dans CosmosDB) et </li> <li>l'enregistrer dans le conteneur.</li> </ol> <p></p> <p>Mais lorsque plusieurs composants sont suceptibles de r\u00e9aliser cette mise \u00e0 jour ou que vous utilisez des m\u00e9canismes de scalabilit\u00e9s horizontal, il y'a un risque d'\u00e9crasement de la donn\u00e9e (et donc de perte de donn\u00e9e).</p> <p>En effet, prenons 2 composants A et B r\u00e9alisant une mise \u00e0 jour au m\u00eame moment sur la m\u00eame donn\u00e9e.</p> <ul> <li>L'identifiant est li\u00e9 \u00e0 la prori\u00e9t\u00e9 \"id\" (je mets de cot\u00e9 volontairement la notion de cl\u00e9 de partition),</li> <li>Le composant A met \u00e0 jour la date de naissance ainsi que l'adresse email,</li> <li>Le composant B met \u00e0 jour la date de naissance et le num\u00e9ro de t\u00e9l\u00e9phone. </li> </ul> Data Composant A Data Composant B Data CosmosDB {\u00a0\u00a0\"id\": \"99039816\",\u00a0\u00a0,\"birthdate\": \"1984-06-16T00:00:00Z\", \"email\": \"joe.doe@yopmail.com\"} {\u00a0\u00a0\"id\": \"99039816\",\u00a0\u00a0\"birthdate\": \"1984-07-16T00:00:00Z\", \"phone\": \"+33.8.76.54.32.10\"} {\u00a0\u00a0\"id\": \"99039816\",\u00a0\u00a0\"firstname\": \"joe\",\u00a0\u00a0\"lastname\": \"doe\",\u00a0\u00a0\"birthdate\": \"1984-05-16T00:00:00Z\",} <p>Dans un traitement classique suite \u00e0 la mise \u00e0 jour de la donn\u00e9e par les 2 composants nous devrions avoir :</p> <ul> <li>Si le composant A est pass\u00e9 avant le composant B : <pre><code>{\n    \"id\": \"99039816\",\n    \"firstname\": \"joe\",\n    \"lastname\": \"doe\",\n    \"birthdate\": \"1984-07-16T00:00:00Z\",\n    \"email\": \"joe.doe@yopmail.com\",\n    \"phone\": \"+33.8.76.54.32.10\"\n}\n</code></pre></li> <li>Si le composant B est pass\u00e9 avant le composant A : <pre><code>{\n    \"id\": \"99039816\",\n    \"firstname\": \"joe\",\n    \"lastname\": \"doe\",\n    \"birthdate\": \"1984-06-16T00:00:00Z\",\n    \"email\": \"joe.doe@yopmail.com\",\n    \"phone\": \"+33.8.76.54.32.10\"\n}\n</code></pre></li> </ul> <p>Imaginons maintenant le s\u00e9quencement suivant :</p> <ol> <li>Composant A : Fetch Data</li> <li>Composant B : Fetch Data</li> <li>Composant A : Merge data</li> <li>Composant A : Upsert data</li> <li>Composant B : Merge data</li> <li>Composant B : Upsert data</li> </ol> <p>Suite \u00e0 la mise \u00e0 jour de la donn\u00e9e par les 2 composants nous aurons dans CosmosDB : <pre><code>{\n    \"id\": \"99039816\",\n    \"firstname\": \"joe\",\n    \"lastname\": \"doe\",\n    \"birthdate\": \"1984-07-16T00:00:00Z\",\n    \"phone\": \"+33.8.76.54.32.10\"\n}\n</code></pre> L'information adresse email est PERDU ! </p> <p>Le probl\u00e8me, c'est que le composant A ne sait pas que le composant B r\u00e9alise une op\u00e9ration de mise \u00e0 jour au m\u00eame moment. Et chaque composant fait sa mise \u00e0 jour de son cot\u00e9 croyant qu'il est seul au monde !</p> <p>Mais comment r\u00e9soudre ce probl\u00e8me ?</p> <p>Il s'agit d'un probl\u00e8me d'atomicit\u00e9. Il va falloir s'assurer que les op\u00e9rations de r\u00e9cup\u00e9ration, de fusion et d'enregistrement soient r\u00e9alis\u00e9e de mani\u00e8re atomique. </p> <p>Je reprend mes vieux cours d'informatique et la solution est \"le verrou\".</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#une-solution-cosmosdb-redis","title":"Une solution : CosmosDB + Redis","text":"<p>Dans le cloud Azure, le service \"cache redis\" est bien pratique. Il ne sert pas qu'\u00e0 faire du cache ! Il peut aussi g\u00e9rer notre verrou.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#le-principe","title":"Le principe","text":"<p>Chaque composant voulant r\u00e9aliser une op\u00e9ration de mise \u00e0 jour doit syst\u00e9matiquement poser un verrou dans Redis avant de r\u00e9aliser la mise \u00e0 jour (fetch-merge-upsert). Si le cache contient d\u00e9j\u00e0 ce verrou, alors le composant sait qu'un autre composant est en train de r\u00e9aliser une op\u00e9ration de mise \u00e0 jour. Ainsi, grace au verrou l'atomicit\u00e9 de l'operation de mise \u00e0 jour est pr\u00e9serv\u00e9e. Il faudra bien entendu penser \u00e0 lib\u00e9rer le verrou une fois l'op\u00e9ration termin\u00e9e.</p> <p></p> <p>Il ne reste plus qu'\u00e0 l'encapsuler dans une petite couche technique (DAL) afin d'abstraire tout cela du traitement m\u00e9tier.</p> <p>Note</p> <p>Pour le verrou, il faut utiliser l'identifiant (la cl\u00e9 primaire) de la donn\u00e9e en tant que cl\u00e9. Par exemple pour notre exemple ci-dessus, on utilisera \"99039816\" comme cl\u00e9. </p> <p>Parfait !</p> <p>Mais que se passe-t-il s'il y a un verrou de pos\u00e9 ? </p> <p>On attends !</p> <p>Oui, mais imaginons que l'on ai une vague de mise \u00e0 jour sur la m\u00eame donn\u00e9e (c'est un cas extr\u00e8me), ou que le cache redis ou que le comosdb ne r\u00e9ponde pas ? Mon composant ne va pas attendre \u00e9ternellement ! </p> <p>C'est vrai. Pour cela, je conseille d'utiliser une file d'attente.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#larchitecture","title":"L'architecture","text":"<p>L'id\u00e9e est de d\u00e9couper le traitement de mise \u00e0 jour en 2. Le premier composant (Business) va pousser sa demande mise \u00e0 jour dans une file d'attente. Le second composant (DAL) va lui traiter cette file d'attente et r\u00e9aliser les mises \u00e0 jour. En cas d'impossibilit\u00e9 de r\u00e9aliser une mise \u00e0 jour par le second composant, celui-ci va remettre la demande en file d'attente (celle-ci sera trait\u00e9 ult\u00e9rieurement)  </p> <p> <pre><code>1 - Demande de mise \u00e0 jour\n2 - Mise en file d'attente de la mise \u00e0 jour par le composant m\u00e9tier\n3 - Consommation de la file d'attente par le composant DAL\n4 - V\u00e9rification du verrou\n5 - Upsert de la donn\u00e9e\n5'- Remise en file d'attente en cas d'\u00e9chec. \n</code></pre></p> <p>Note</p> <p>Je pr\u00e9conise de tenter 5 \u00e0 10 fois la mise \u00e0 jour par le composant avant de remettre la demande  en file d'attente.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#cas-au-limite","title":"Cas au limite","text":"<p>C'est bien cette histoire de file d'attente, mais du coup, j'ai un risque que les op\u00e9rations de mise \u00e0 jour soient r\u00e9alis\u00e9es dans le d\u00e9sordre.</p> <p>C'est vrai.</p> <p>Pour cela, on peut se baser sur le timestamp de la donn\u00e9e (il faudra alors stocker cette information en plus dans CosmosDB). Ainsi, si la mise \u00e0 jour \u00e0 traiter est ant\u00e9rieur \u00e0 la derni\u00e8re mise \u00e0 jour dans CosmosDB, l'op\u00e9ration peut-\u00eatre abandonn\u00e9e.</p> <p>Cela reste imparfait...</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#conclusion","title":"Conclusion","text":"<p>Il faut se doter de plusieurs ressources azure et r\u00e9aliser un peu de d\u00e9veloppement pour obtenir une solution capable de g\u00e9rer presque proprement les mises \u00e0 jour dans CosmosDB.</p> <p>Il existe d'autres solutions :</p> <ul> <li>Une qui pourrait sembler \u00eatre plus \"sexy\" serait d'utiliser les proc\u00e9dures stock\u00e9es JS de CosmosDB. En effet, les ProcStock permettent de garantir l'atomicit\u00e9 de l'op\u00e9ration. Mais \u00e0 mon avis, si vous devez g\u00e9rer des donn\u00e9es complexe dans votre conteneur CosmosDB, vous allez gal\u00e9rer \u00e0 impl\u00e9menter et maintenir celles-ci.</li> <li>Une autre, consiste \u00e0 utiliser les Azure Function Durable Entities. Mais je n'ai pas encore eu l'occassion de tester. </li> </ul> <p>Le partial update permettrait de se d\u00e9faire de cette probl\u00e8matique en n'envoyant dans CosmosDB que les propri\u00e9t\u00e9s \u00e0 mettre \u00e0 jour. Le CosmosDB ce chargeant de r\u00e9aliser les op\u00e9rations de fetch-merge-upsert lui m\u00eame. Cela simplifierait beaucoup de chose.</p> <p>Vivement le Partial Update !</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Feedback Azure</li> <li>Wikip\u00e9dia</li> <li>CosmosDB - Stored Procedures</li> <li>CosmosDB - Transactions optimistic concurrency</li> <li>Azure Function Durable Entities</li> </ul>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/02.cosmosdb.waiting_partialupdate/#remerciements","title":"Remerciements","text":"<ul> <li>Quentin Joseph : pour la relecture</li> <li>Benjamin Dufour : pour les  Azure Function Durable Entities ;-)</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 20 Novembre 2020</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/03.cosmosdb.calculatedPartitionKey/","title":"CosmosDB : Une cl\u00e9 de partition calcul\u00e9e !","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Dans CosmosDB, la notion de cl\u00e9 de partition est essentielle. En effet, contraitement \u00e0 d'autres syst\u00e8mes de stockage de donn\u00e9es classique (SQL par exemple), l'unicit\u00e9 d'une donn\u00e9e est bas\u00e9e sur le couple identifiant - cl\u00e9 de partition.</p> <p>Les conteneurs CosmosDB sont d\u00e9coup\u00e9s en partitions logiques. Chaque partition logique g\u00e8re ind\u00e9pendamment l'unicit\u00e9 de ses \u00e9l\u00e9ments en se basant sur l'identifiant id. </p> <p></p> <p>C'est un peu comme un dossier qui s'assure qu'\u00e0 l'int\u00e9rieur de lui, il n'y a pas 2 fois le m\u00eame nom de fichier.  Donc, dans un m\u00eame conteneur vous pouvez tr\u00e8s bien avoir le m\u00eame identifiant dans 2 partitions logiques diff\u00e9rentes.</p> <p>La cl\u00e9 de partition peut-\u00eatre d\u00e9finie \u00e0 partir de n'importe quelle propri\u00e9t\u00e9 de la donn\u00e9e. Mais il y a quelques contraintes \u00e0 respecter :</p> <ul> <li>Cette propri\u00e9t\u00e9 doit \u00eatre obligatoirement valu\u00e9e (tout comme l'identifiant).</li> <li>Cette propri\u00e9t\u00e9 doit \u00eatre immuable (tout comme l'identifiant).</li> <li>Le stockage sur une cl\u00e9 est limit\u00e9 \u00e0 20 Go. </li> <li>Le nombre de valeur possible de cette propri\u00e9t\u00e9 doit \u00eatre proportionnel au nombre d'\u00e9l\u00e9ments stock\u00e9s dans le conteneur (je conseille un rapport compris entre 1/1 000 et 1/10 000).</li> <li>La r\u00e9partition du stockage doit \u00eatre uniforme entre toutes les cl\u00e9s.</li> <li>La r\u00e9partition des requ\u00eates doit \u00eatre de pr\u00e9f\u00e9rence uniforme entre toutes les cl\u00e9s.</li> </ul> <p>Dans ces conditions il est parfois difficile de trouver la propri\u00e9t\u00e9 r\u00e9pondant \u00e0 tous ces crit\u00e8res !</p> <p>Pas de panique, j'ai une solution ! Elle consiste \u00e0 calculer la cl\u00e9 de partition.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/03.cosmosdb.calculatedPartitionKey/#la-fausse-bonne-idee","title":"La fausse bonne id\u00e9e !","text":"<p>Une solution simple serait de d\u00e9finir de fa\u00e7on al\u00e9atoire la cl\u00e9 de partition. Ainsi on maitrise le nombre de partition et on s'assure que la r\u00e9partition du stockage et des requ\u00eates est uniforme. </p> <p>Parfait ! Sauf que s'il on a 2 processus qui r\u00e9alise au m\u00eame moment l'ajout de la m\u00eame donn\u00e9e chacun va calculer sa propre cl\u00e9 de partition et les 2 ajouts seront enregistr\u00e9s. Nous aurons un doublon !</p> <p>Et ne croyez pas que j'exag\u00e8re et que mon exemple ne peux pas arriver ! J'aime souvent citer la loi de Murphy dans ce type de cas : \"Tout ce qui est susceptible d'aller mal, ira mal.\". Et personnellement, je d\u00e9teste les doublons !</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/03.cosmosdb.calculatedPartitionKey/#une-solution-un-crc-en-guise-de-cle-de-partition","title":"Une solution : Un CRC en guise de cl\u00e9 de partition.","text":"<p>Pourquoi ne pas d\u00e9duire la cl\u00e9 de partition \u00e0 partir de l'identifiant ! </p> <p>Un peu comme les 2 derniers chiffres de votre num\u00e9ro de s\u00e9curit\u00e9 sociale... </p> <p>L'id\u00e9e est d'utiliser le CRC (Contr\u00f4le de redondance cyclique) pour d\u00e9duire la cl\u00e9 de partition \u00e0 partir de l'identifiant. Le nombre de bits du CRC, va permettre de jouer sur le nombre de valeurs possible.</p> <p>Voici un petit tableau de correspondance :</p> Nombre de bits (CRC-x) Nombre de partition Volum\u00e9trie de donn\u00e9e 2 4 entre 4 000 et 40 000 3 8 entre 8 000 et 80 000 4 16 entre 16 000 et 160 000 5 32 entre 32 000 et 320 000 6 64 entre 64 000 et 640 000 7 128 entre 128 000 et 1 280 000 8 256 entre 256 000 et 2 560 000 <p>Ainsi, contrairement \u00e0 l'attribution al\u00e9atoire de la valeur de la cl\u00e9 de partition, on garantit que peu importe le processus r\u00e9alisant une op\u00e9ration sur le conteneur il n'y a aucun risque de se retrouver avec des doublons.</p> <p>L'autre avantage, est que si vous souhaitez r\u00e9cup\u00e9rer une donn\u00e9e \u00e0 partir de son identifiant, vous pouvez automatiquement d\u00e9duire sa cl\u00e9 de partition. Ainsi, lorsque vous interrogez votre conteneur cosmosdb vous pouvez pr\u00e9ciser la partition et ainsi vous r\u00e9cup\u00e9rez plus rapidement et/ou pour moins cher (moins de RU consomm\u00e9s) votre donn\u00e9e.</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/03.cosmosdb.calculatedPartitionKey/#conclusion","title":"Conclusion","text":"<p>En int\u00e9grant ce m\u00e9canisme de d\u00e9duction de la cl\u00e9 de partition directement dans votre mod\u00e8le de donn\u00e9es, vous faites abstraction de cette contrainte technique.</p> <p>Certe vous aurez dans votre conteneur une donn\u00e9e technique en plus qui ne sert pas \u00e0 grand chose fonctionnellement. Mais bon, c'est mieux que d'avoir des doublons en pagaille !</p> <p>Note</p> <p>Cette solution peut aussi s'appliquer pour les Table Storage Azure ;-).</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/03.cosmosdb.calculatedPartitionKey/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Partitions CosmosDB</li> <li>Jim Blackler CRCTool</li> </ul>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/03.cosmosdb.calculatedPartitionKey/#remerciements","title":"Remerciements","text":"<ul> <li>Quentin Joseph : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 27 Novembre 2020</p>","tags":["Azure","cosmos db","d\u00e9veloppement"]},{"location":"en/articles/tips/04.sonarqube.managed/","title":"D\u00e9ployer Sonarqube sur des services manag\u00e9s Azure.","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Dans le cadre de mes diff\u00e9rentes missions clients j'ai eu le besoin de d\u00e9ployer l'outil Sonarqube. Sonarqube propose ses images sur docker hub. En m\u00eame temps les Azure WebApp permettent d'ex\u00e9cuter des conteneurs docker. Pourquoi ne pas faire tourner Sonarqube sur une Azure WebApp ?</p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"en/articles/tips/04.sonarqube.managed/#pourquoi","title":"Pourquoi ?","text":"<p>Sonarqube est une plateforme web de reporting qualit\u00e9. Cette plateforme permet de collecter les rapports d'analyse de code et d'ex\u00e9cution de tests automatis\u00e9s (Couverture de code). A partir de ces \u00e9l\u00e9ments, elle est capable d'attribuer une note qualit\u00e9 \u00e0 votre code. Pour cela, Sonarqube a besoin d'une base de donn\u00e9es afin de stocker les r\u00e9sultats d'analyse.</p> <p>Dans un contexte professionnel nous allons souhaiter que : </p> <ul> <li>Sonarqube soit suffisamment disponible pour que chaque d\u00e9veloppeur et chaque tech-lead puisse observer la qualit\u00e9 du code.</li> <li>le code source accessible dans Sonarqube ne puisse pas \u00eatre exfiltr\u00e9.</li> <li>l'exploitation de cette plateforme soit la plus simple possible afin de limiter les co\u00fbts de maintenance.</li> </ul> <p>Les services manag\u00e9s Azure: Azure WebApp et Azure SQL database, offrent de tr\u00e8s bonnes SLA et permettent de r\u00e9duire les co\u00fbts d'exploitation en d\u00e9l\u00e8guant une bonne partie de celle-ci \u00e0 Microsoft. </p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"en/articles/tips/04.sonarqube.managed/#larchitecture","title":"L'architecture","text":"<p>Il existe d\u00e9j\u00e0 sur le github de microsoft un quickstart template ARM permettant de d\u00e9ployer Sonarqube sur une Azure WebApp avec une base de donn\u00e9es Azure SQL database. Les soucis de ce quickstart sont les suivants :</p> <ul> <li>il ne permet pas de d\u00e9ployer la derni\u00e8re version de Sonarqube (8.9 LTS),</li> <li>il n'isole pas au niveau r\u00e9seau. Il y a donc un risque d'exfiltration du code.</li> <li>il ne permet pas de conserver la configuration et les plugins de Sonarqube en cas d'incident sur l'Azure WebApp.</li> </ul> <p>Je vous propose donc de revoir un peu l'architecture afin de blinder tout cela : </p> <ul> <li> <p>On va ajouter un Storage Account qui contiendra les extensions et les donn\u00e9es de Sonarqube afin de garantir la r\u00e9silience de la solution. En cas de dysfonctionnement de l'Azure WebApp, les donn\u00e9es Sonarqube ne seront pas perdues. De plus, si l'on doit migrer la solution sur un autre cloud provider, nous serons en capacit\u00e9 de faire cette migration sereinement.</p> </li> <li> <p>Ensuite, on va cr\u00e9er un Virtual network et un Subnet dans lequel on va int\u00e9grer notre Azure WebApp. On va ajouter les services endpoints du Storage Account et du Sql Server \u00e0 notre Subnet. Ainsi notre Azure WebApp pourra communiquer avec les autres services manag\u00e9s sans passer sur internet et donc sans risque d'exposition \u00e0 une potentielle attaque.</p> </li> <li> <p>Enfin, on va mettre en place des r\u00e8gles firewall pour emp\u00e8cher tout acc\u00e8s en dehors de notre Virtual Network. </p> <ul> <li>on va restreindre le Storage Account au Subnet de notre Azure WebApp.</li> <li>on va faire de m\u00eame pour l'Azure Sql Server.</li> <li>on va restreindre l'Azure WebApp aux autres Subnet de notre Virtual Network.</li> </ul> </li> </ul>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"en/articles/tips/04.sonarqube.managed/#resultat","title":"R\u00e9sultat","text":"<p>Vous trouverez ci-dessous le template ARM permettant de d\u00e9ployer rapidement un Sonarqube isol\u00e9 et r\u00e9silient.  </p> <p> </p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"en/articles/tips/04.sonarqube.managed/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Deploy Sonarqube on a Linux web app with Azure SQL</li> <li>Sonarqube on Docker Hub</li> </ul>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"en/articles/tips/04.sonarqube.managed/#remerciements","title":"Remerciements","text":"<ul> <li>Michael Maillot : pour la relecture</li> <li>Marine Perroteau : pour la relecture</li> <li>Samy Mameri : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 27 Septembre 2021</p>","tags":["Azure","sonarqube","Infra as Code","PaaS"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/","title":"Azure DevOps : Cr\u00e9er sa propre task agentless","text":"<p>Important</p> <p>This article written in French will be translated into English in the next few days. stay tuned ;-).</p> <p>Cela fait maintenant des ann\u00e9es que j'utilise quotidiennement Azure DevOps. J'ai pu connaitre sa version On-Premise nomm\u00e9e Team Foundation Server, puis sa premi\u00e8re version SaaS nomm\u00e9e Visual Studio Team Services.</p> <p>Vous ne le savez peut-\u00eatre pas, mais il est possible d'\u00e9tendre les fonctionnalit\u00e9s d'Azure DevOps au travers d'extensions. Ces extensions vont vous permettre d'\u00e9tendre les capacit\u00e9s d'Azure DevOps pour r\u00e9pondre \u00e0 vos enjeux de productivit\u00e9. Vous allez pouvoir personnaliser vos boards Azure, la gestion de vos repositories Azure, vos pipelines CI/CD, ...</p> <p>Le marketplace d'Azure DevOps propose d\u00e9j\u00e0 de nombreuses extensions gratuites et payantes. Mais il est possible que vous ne trouviez pas votre bonheur. Dans ce cas, vous pouvez vous m\u00eame d\u00e9velopper vos propres extensions. </p> <p>Note</p> <p>Les possibilit\u00e9s d'extensions sont \u00e9normes mais sont malheureusement tr\u00e8s peu document\u00e9es. L'article Azure DevOps extensibility points liste en partie les extensions possibles.</p> <p>Je vous propose dans cet article d'\u00e9tendre les capacit\u00e9s de vos pipelines de CI/CD avec une agentless task ou server task.</p> <p>Note</p> <p>J'aurais pr\u00e9f\u00e9r\u00e9 vous faire un comparatif de ce type de t\u00e2che entre les extensions Azure DevOps et les Github Action, malheureusement Github ne propose pas encore ce type de fonctionnalit\u00e9. C'est bien dommage !</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#developper-sa-propre-tache-agentless","title":"D\u00e9velopper sa propre t\u00e2che agentless","text":"","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#une-tache-agentless-cest-quoi-et-pourquoi-jen-aurais-besoin","title":"Une t\u00e2che agentless, c'est quoi et pourquoi j'en aurais besoin ?","text":"<p>Lorsque vous ex\u00e9cutez un pipeline dans Azure DevOps pour compiler, analyser, tester ou d\u00e9ployer un composant vous utilisez un agent. Cet agent est une \"machine\" sur laquelle Azure DevOps va demander de r\u00e9aliser des actions (une compilation .NET par exemple). Mais il est possible de demander \u00e0 Azure DevOps d'ex\u00e9cuter lui-m\u00eame certaines t\u00e2ches. On parle alors d'agentless task ou de server task. </p> <p>Les possibilit\u00e9s de ce type de t\u00e2ches sont cependant limit\u00e9es. Vous ne pourrez r\u00e9aliser que 3 types d'op\u00e9rations :</p> <ul> <li>HttpRequest : pour r\u00e9aliser une requ\u00eate HTTP/S,</li> <li>ServiceBus : pour envoyer un message dans une file d'attente d'Azure Service Bus,</li> <li>HttpRequestChain : pour r\u00e9aliser une suite de requ\u00eates HTTP/S.</li> </ul> <p>Mais, dans de nombreux cas vous n'aurez besoin que de cela :</p> <ul> <li>Imaginons que vous souhaitez notifier automatiquement une application de votre SI d'une mise \u00e0 jour applicative sur un environnement depuis votre pipeline Azure DevOps. Vous n'avez peut-\u00eatre pas besoin de solliciter un agent pour cela ? Peut-\u00eatre qu'une ou plusieurs requ\u00eates HTTP/S seraient suffisantes.</li> <li>Imaginons que vous souhaitez provisionner vos propres agents Azure DevOps \u00e9ph\u00e9m\u00e8res (cf. mon article). Il serait pr\u00e9f\u00e9rable de se passer d'un agent pour en provisionner un autre !</li> </ul> <p>Note</p> <p>Les t\u00e2ches agentless sont execut\u00e9es depuis les serveurs Azure DevOps qui ont des plages d'IP bien d\u00e9finies (cf. documentation microsoft). Elles offrent donc l'avantage d'\u00eatre plus faciles \u00e0 whitelister aupr\u00e8s des firewalls que les agents Microsoft Hosted.  </p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#pas-besoin-de-savoir-coder-pour-cela","title":"Pas besoin de savoir coder pour cela !","text":"<p>Et oui, l'impl\u00e9mentation de ce type de t\u00e2che ne n\u00e9cessite aucune comp\u00e9tence dans un langage ou framework autre que le format \"json\".</p> <p>Pour commencer, il vous faudra installer localement Node.js puis installer tfx-cli via l'utilitaire npm install\u00e9 avec Node.js.</p> <p>Si vous \u00eates sur Linux/OSX :</p> <pre><code>sudo npm install -g tfx-cli\n</code></pre> <p>Si vous \u00eates sur Windows :</p> <pre><code>npm install -g tfx-cli\n</code></pre> <p>Ensuite dans votre r\u00e9pertoire de travail, vous allez cr\u00e9er 2 dossiers et 3 fichiers comme ceci :</p> <pre><code>  |--- images                        \n      |--- extension-icon.png         // l'ic\u00f4ne de votre extension\n  |--- buildandreleasetask            \n      |--- task.json                  // la t\u00e2che agentless \n  |--- vss-extension.json             // le manifeste de votre extension\n</code></pre> <p>Warning</p> <p>L'ic\u00f4ne de votre extension doit \u00eatre au format PNG et respecter une dimension bien pr\u00e9cise : 128x128 pixels. En dehors de cela, vous \u00eatre compl\u00e8tement libre.</p> <p>Note</p> <p>Il n'est pas obligatoire de respecter les noms des dossiers et des fichiers. Mais pour plus de compr\u00e9hension, je conseille de respecter une nomenclature proche de celle-ci.</p> <p>Commen\u00e7ons par l'impl\u00e9mentation du manifeste.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#le-fichier-vss-extensionjson","title":"Le fichier vss-extension.json","text":"<p>Le fichier manifeste est un descriptif de l'extension. L'extension pouvant contenir plusieurs \u00e9l\u00e9ments, ce fichier va permettre de les lister et de pr\u00e9ciser quelques informations obligatoires pour \u00eatre sur le marketplace Azure Devops.</p> <p>Ci-dessous un exemple de manifeste :</p> <pre><code>{\n    \"manifestVersion\": 1,\n    \"id\": \"test-push-to-storagequeue\",\n    \"publisher\": \"Pmorisseau\",\n    \"version\": \"1.0.7\",\n    \"name\": \"test-push-to-storagequeue\",\n    \"description\": \"test-push-to-storagequeue\",\n    \"public\": false,\n    \"categories\": [ \"Azure Pipelines\" ],\n    \"targets\": [\n        {\n            \"id\": \"Microsoft.VisualStudio.Services\"\n        }\n    ],\n    \"icons\": {\n        \"default\": \"images/icon.png\"\n    },\n    \"files\": [\n        {\n            \"path\": \"buildandreleasetask\"\n        }\n    ],\n    \"contributions\": [\n        {\n            \"id\": \"sendtostoagequeue1\",\n            \"description\": \"Agentless task that push a message to an azure queue\",\n            \"type\": \"ms.vss-distributed-task.task\",\n            \"targets\": [ \"ms.vss-distributed-task.tasks\" ],\n            \"properties\": {\n                \"name\": \"buildandreleasetask\"\n            }\n        }        \n    ]\n}\n</code></pre> <p>Ce qu'il est important de retenir \u00e0 propos des diff\u00e9rents attributs :</p> <ul> <li>id : doit \u00eatre constant au fil des \u00e9volutions de l'extension. C'est lui qui permet d'identifier de fa\u00e7on unique l'extension,</li> <li>version : doit toujours \u00eatre incr\u00e9ment\u00e9 avant d'\u00eatre publi\u00e9 sur le marketplace,</li> <li>public : permet de rendre publique ou non l'extension. Une version publique de l'extension le restera m\u00eame si ult\u00e9rieurement vous la repassez en priv\u00e9e,</li> <li>files : doit lister tous les dossiers qui devront \u00eatre int\u00e9gr\u00e9s dans l'extension,</li> <li> <p>contribution :</p> <ul> <li>id : est un identifiant unique et doit correspondre au nom de la t\u00e2che (attribut name dans le fichier task.json),</li> <li>type : doit \u00eatre <code>ms.vss-distributed-task.task</code> dans le cas d'une agentless task,</li> <li>targets : doit contenir <code>ms.vss-distributed-task.tasks</code> dans le cas d'une agentless task,</li> <li> <p>properties :</p> <ul> <li>name : doit correspondre au dossier contenant le fichier task.json.</li> </ul> </li> </ul> </li> </ul> <p>Note</p> <p>Microsoft met \u00e0 disposition une documentation d\u00e9taill\u00e9e ici</p> <p>Passons maintenant \u00e0 l'impl\u00e9mentation de la t\u00e2che.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#le-fichier-taskjson","title":"Le fichier task.json","text":"<p>Imaginons que nous souhaitons r\u00e9aliser une t\u00e2che permettant d'envoyer des messages dans une storage queue. Voici ce que pourrait donner le fichier task.json :</p> <pre><code>{\n    \"$schema\": \"https://raw.githubusercontent.com/Microsoft/azure-pipelines-task-lib/master/tasks.schema.json\",\n    \"id\": \"bee81c33-f056-4721-a4fd-7141e07c42ad\",\n    \"name\": \"sendtostoagequeue1\",\n    \"friendlyName\": \"Send to Storage Queue\",\n    \"description\": \"\",\n    \"helpMarkDown\": \"Send to Storage Queue\",\n    \"category\": \"Azure Pipelines\",\n    \"author\": \"Pmorisseau\",\n    \"visibility\": [\n        \"Build\",\n        \"Release\"\n    ],\n    \"runsOn\": [\n        \"Server\",\n        \"ServerGate\"\n    ],\n    \"version\": {\n        \"Major\": 0,\n        \"Minor\": 0,\n        \"Patch\": 1\n    },       \n    \"instanceNameFormat\": \"Send message to queue : $(queueName)\",\n    \"inputs\": [\n        {\n            \"name\": \"storageAccountUrl\",\n            \"type\": \"string\",\n            \"label\": \"Url du Storage Account\",\n            \"defaultValue\": \"\",\n            \"required\": true\n        },\n        {\n            \"name\": \"queueName\",\n            \"type\": \"string\",\n            \"label\": \"Nom de la file d'attente\",\n            \"defaultValue\": \"\",\n            \"required\": true\n        },\n        {\n            \"name\": \"storageAccountSasToken\",\n            \"type\": \"string\",\n            \"label\": \"Cl\u00e9 d'acc\u00e8s \u00e0 votre file d'attente\",\n            \"defaultValue\": \"\",\n            \"required\": true\n        }        \n    ],\n    \"execution\": {\n        \"HttpRequest\": {\n            \"Execute\": {\n                \"EndpointUrl\": \"{{storageAccountUrl}}/{{queueName}}/messages$(storageAccountSasToken)\",\n                \"Method\": \"POST\",\n                \"Body\": \"&lt;QueueMessage&gt;&lt;MessageText&gt;Lorem Ipsum dolor sit amet !&lt;/MessageText&gt;&lt;/QueueMessage&gt;\",\n                \"Headers\": \"{\\n\\\"Content-Type\\\":\\\"application/xml\\\"\\n}\"\n            }\n        }\n    } \n}    \n</code></pre> <p>Ce qu'il est important de retenir c'est que :</p> <ul> <li>l'attribut id doit \u00eatre unique et constant au fil des \u00e9volutions de la t\u00e2che,</li> <li>l'attribut name doit correspondre \u00e0 un id du n\u0153ud contributions dans le fichier vss-extension.json, </li> <li>l'attribut runsOn doit contenir Server et/ou ServerGate pour \u00eatre consid\u00e9r\u00e9 comme une t\u00e2che agentless, </li> <li>le n\u0153ud inputs doit contenir tous les param\u00e8tres de la t\u00e2che,</li> <li>le n\u0153ud execution doit contenir la commande agentless \u00e0 executer.  </li> </ul> <p>Note</p> <p>Le sch\u00e9ma complet est disponible ici</p> <p>Notre exemple ci-dessus, une fois d\u00e9ploy\u00e9 dans Azure DevOps, va mettre \u00e0 disposition une nouvelle t\u00e2che qui, dans un pipeline classique, ressemblera \u00e0 cela :</p> <p></p> <p>Et dans un pipeline yaml, \u00e0 cela :</p> <pre><code>- task: Pmorisseau.test-push-to-storagequeue.sendtostoagequeue1.sendtostoagequeue1@0\n  displayName: 'Send message to queue : [your queue name]'\n  inputs:\n    storageAccountUrl: 'https://[your storage account name].queue.core.windows.net'\n    queueName: '[your queue name]'\n    storageAccountSasToken: '?sv=2019-02-02&amp;st=2021-12-12T10%3A51%3A39Z&amp;se=2022-12-13T10%3A51%3A00Z&amp;sp=raup&amp;sig=JTDK%2BDc16YpMtGTKkoqtLw1QVDOL7mnzTxOGEKwvWtY%3D'\n</code></pre> <p>Cependant, on est oblig\u00e9 de renseigner dans notre pipeline des donn\u00e9es sensibles comme l'url ou la cl\u00e9 d'acc\u00e8s \u00e0 notre api. Cela peut \u00eatre consid\u00e9r\u00e9 comme une faille de s\u00e9curit\u00e9.</p> <p>Pas de souci, on peut aussi cr\u00e9er ses propres service connections.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#creer-son-service-connection","title":"Cr\u00e9er son service connection","text":"<p>Tout d'abord, il va falloir modifier le fichier manifeste (vss-extension.json) pour d\u00e9clarer le nouveau type de service connection. </p> <p>Dans le n\u0153ud contributions, on va rajouter :</p> <pre><code>        {\n            \"id\": \"storagequeue\",\n            \"description\": \"Storage Queue\",\n            \"type\": \"ms.vss-endpoint.service-endpoint-type\",\n            \"targets\": [\n                \"ms.vss-endpoint.endpoint-types\"\n            ],\n            \"properties\": {\n                \"name\": \"storagequeue\",\n                \"displayName\": \"Storage Queue\",\n                \"url\": {\n                    \"displayName\": \"Azure storage URL (without SAS token)\",\n                    \"required\": true\n                },\n                \"inputDescriptors\": [\n                    {\n                        \"id\": \"queueName\",\n                        \"name\": \"Queue Name\",\n                        \"description\": \"Azure storage queue name\",\n                        \"inputMode\": \"textbox\",\n                        \"isConfidential\": false,\n                        \"validation\": {\n                            \"isRequired\": true,\n                            \"dataType\": \"string\",\n                            \"maxLength\": 200\n                        }\n                    },   \n                    {\n                        \"id\": \"sasToken\",\n                        \"name\": \"SAS token\",\n                        \"description\": \"Azure storage queue SAS token\",\n                        \"inputMode\": \"passwordbox\",\n                        \"isConfidential\": false,\n                        \"validation\": {\n                            \"isRequired\": true,\n                            \"dataType\": \"string\",\n                            \"maxLength\": 500\n                        }\n                    }                                          \n                ],\n                \"dataSources\": [\n                    { \n                        \"name\": \"TestConnection\",\n                        \"endpointUrl\": \"{{endpoint.url}}/{{endpoint.queueName}}/messages$(endpoint.sasToken)\",\n                        \"resultSelector\": \"xpath://QueueMessagesList\"\n                    }\n                ],                                  \n                \"authenticationSchemes\": [\n                    {\n                        \"type\": \"ms.vss-endpoint.endpoint-auth-scheme-none\"\n                    }\n                ]\n            }\n        }\n</code></pre> <p>Ce qu'il est important de retenir \u00e0 propos des diff\u00e9rents attributs :</p> <ul> <li>id : est un identifiant unique,</li> <li>type : doit \u00eatre <code>ms.vss-endpoint.service-endpoint-type</code>,</li> <li>targets : doit contenir <code>ms.vss-endpoint.endpoint-types</code>,</li> <li> <p>properties :</p> <ul> <li>url : corresponde \u00e0 l'url du service,</li> <li>inputDescriptors : doit contenir l'ensemble des param\u00e8tres compl\u00e9mentaire \u00e0 l'url,</li> <li> <p>dataSource et l'item TestConnection (exactement orthographi\u00e9 comme cela) : permettent de d\u00e9finir le test de connexion du service connection,</p> <ul> <li>endpointUrl : corresponde \u00e0 l'url appel\u00e9e lors du test de connexion,</li> <li>resultSelector : correpond \u00e0 la v\u00e9rification \u00e0 r\u00e9aliser sur la r\u00e9ponse lors du test de connexion,</li> </ul> </li> <li> <p>authenticationSchemes : d\u00e9finit le mode d'authentification parmi :</p> <ul> <li>Authentification de base avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-basic</code> dans le cas d'une authentification avec un identifiant et un mot de passe encod\u00e9 en base 64 dans l'en-t\u00eate HTTP,</li> <li>Authentification bas\u00e9e sur un jeton avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-token</code> dans le cas d'une authentification avec un jeton dans l'en-t\u00eate HTTP,</li> <li>Authentification par certificat  avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-cert</code>  dans le cas d'une authentification avec certificat,</li> <li>Sans athentification avec le type <code>ms.vss-endpoint.endpoint-auth-scheme-none</code> lorsqu'il n'y a pas d'authentification.</li> </ul> </li> </ul> </li> </ul> <p>Note</p> <p>Les diff\u00e9rents types d'authentification sont d\u00e9crits ici</p> <p>Ensuite, il va falloir modifier le fichier task.json pour utiliser notre service connection en rempla\u00e7ant le contenu du n\u0153ud inputs par :</p> <pre><code>        {\n            \"name\": \"connectedServiceName\",\n            \"aliases\": [\n                \"serviceConnection\",\n                \"genericService\"\n            ],\n            \"type\": \"connectedService:storagequeue\",\n            \"label\": \"Storage queue service connection\",\n            \"defaultValue\": \"\",\n            \"required\": true,\n            \"helpMarkDown\": \"Select an storage queue service connection\"\n        }\n</code></pre> <p>Il faudra veiller \u00e0 ce que l'attribut type corresponde \u00e0 <code>connectedService:[id du service connection dans le fichier manifeste]</code>.</p> <p>Et modifier le contenu du n\u0153ud executions par :</p> <pre><code>        \"HttpRequest\": {\n            \"Execute\": {\n                \"EndpointId\": \"$(connectedServiceName)\",\n                \"EndpointUrl\": \"{{endpoint.url}}/{{endpoint.queueName}}/messages$(endpoint.sasToken)\",\n                \"Method\": \"POST\",\n                \"Body\": \"&lt;QueueMessage&gt;&lt;MessageText&gt;Lorem Ipsum dolor sit amet !&lt;/MessageText&gt;&lt;/QueueMessage&gt;\",\n                \"Headers\": \"{\\n\\\"Content-Type\\\":\\\"application/xml\\\"\\n}\"\n            }\n        }   \n</code></pre> <p>Il faudra veiller \u00e0 ce que :</p> <ul> <li>l'attribut EndpointId corresponde \u00e0 <code>$([l'attribut name dans le n\u0153ud inputs])</code>,</li> <li>les param\u00e8tres du service connection soient pr\u00e9fix\u00e9s par \"endpoint.\".</li> </ul> <p>Note</p> <p>Il y a 2 syntaxes possibles pour faire r\u00e9f\u00e9rence \u00e0 un param\u00e8tre :</p> <ul> <li><code>{{le_nom_de_l_attribut}}</code> : sera int\u00e9pr\u00e9t\u00e9 comme un texte devant \u00eatre converti en url (httpencode).</li> <li><code>$(le_nom_de_l_attribut)</code> : ne sera pas int\u00e9pr\u00e9t\u00e9 et donc sera utilis\u00e9 tel quel.</li> </ul> <p>Dans notre exemple, le sasToken contenant un ensemble de param\u00e8tres au format Http query, il ne doit donc pas \u00eatre converti.</p> <p>Notre exemple n\u00b02, une fois d\u00e9ploy\u00e9 dans Azure DevOps, va mettre \u00e0 disposition un nouveau service connection qui ressemblera \u00e0 cela :</p> <p></p> <p>Il modifiera aussi la t\u00e2che qui ressemblera \u00e0 cela :</p> <p></p> <p>Et dans un pipeline yaml, \u00e0 cela :</p> <pre><code>- task: Pmorisseau.test-push-to-storagequeue.sendtostoagequeue2.sendtostoagequeue2@0\n  displayName: 'Send to Storage Queue'\n  inputs:\n    serviceConnection: myqueue\n</code></pre> <p>Maintenant, le pipeline ne contient plus de donn\u00e9es \"sensibles\".</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#les-limitations","title":"Les limitations","text":"<p>Les limitations d'impl\u00e9mentation des service connections sont nombreuses et parfois un peu frustrantes :</p> <ul> <li>les param\u00e8tres d\u00e9crits dans le n\u0153ud inputDescriptors ne peuvent pas \u00eatre utilis\u00e9s si l'attribut isConfidential est d\u00e9finit \u00e0 \"true\",</li> <li>les modes d'authentification permis sont trop peu nombreux. Il aurait \u00e9t\u00e9 bienvenue de permettre les authentifications modernes comme l'oauth 2.0 et les authentifications simples comme l'apikey ou le sasToken dans l'url de la requ\u00eate HTTP,</li> <li>l'inputMode password ne sert \u00e0 rien dans le n\u0153ud inputDescriptors.</li> </ul> <p>Note</p> <p>Dans notre exemple le sasToken de notre storage queue restera toujours en clair. </p> <p>Maintenant que nous avons prepar\u00e9 notre extension avec notre nouvelle t\u00e2che agentless, il ne nous reste plus qu'\u00e0 la publier ! </p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#publier-sur-le-marketplace","title":"Publier sur le marketplace","text":"<p>Pour pouvoir utiliser nos extensions sur Azure DevOps, il faut pr\u00e9alablement publier celle-ci sur le marketplace d'Azure DevOps.</p> <p>Note</p> <p>Il vous faut obligatoirement un compte d\u00e9j\u00e0 enregistr\u00e9 dans une organisation Azure DevOps pour publier sur le marketplace.</p> <ol> <li>Connectez-vous \u00e0 votre organisation Azure DevOps : https://dev.azure.com/[votre organisation]</li> <li> <p>Une fois connect\u00e9, g\u00e9n\u00e9rez un personal acces token en cliquant sur User settings puis sur Personal access tokens.</p> <p></p> </li> <li> <p>Cr\u00e9ez un nouveau Personal access token en pr\u00e9cisant bien All accessible organisations et en cochant Manage sous Marketplace.</p> <p></p> </li> <li> <p>Cliquez sur Create et notez bien la cl\u00e9 retourn\u00e9e, c'est votre Personal access token.</p> </li> <li>Ex\u00e9cutez la commande ci-dessous pour packager l'extension :    <pre><code> tfx extension create --manifest-globs vss-extension.json\n</code></pre></li> <li>Ex\u00e9cutez la commande ci-dessous pour publier l'extension sur le marketplace :    <pre><code> tfx extension publish --manifest-globs vss-extension.json --share-with [liste des organisations avec qui vous voulez partager votre extension (s\u00e9par\u00e9 par une virgule)]\n</code></pre></li> <li>durant le processus de publication, il vous sera demand\u00e9 de saisir votre personal access token.</li> </ol> <p>Attention</p> <p>Votre personal access token a syst\u00e9matiquement une date d'expiration. Vous recevrez une notification par email (envoy\u00e9 par azuredevops@microsoft.com) 5 jours avant l'expiration.</p> <p></p> <p>Pensez \u00e0 renouveler votre token !</p> <p>Votre extension est maintenant publi\u00e9e. </p> <p>Vous pouvez consulter celle-ci directement sur le marketplace. Pour cela, une fois connect\u00e9, cliquez sur Publish extensions.</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#conclusion","title":"Conclusion","text":"<p>Bien que les capacit\u00e9s d'Azure DevOps peuvent \u00eatre \u00e9tendues sur de nombreux aspects, il s'av\u00e8re que la documentation Microsoft pour aider les d\u00e9veloppeurs est souvent \u00e9parpill\u00e9e et/ou incompl\u00e8te.</p> <p>Dans cet article, j'ai essay\u00e9 de vous montrer un exemple simple d'extension. Pour cela, bien que je connaisse le syst\u00e8me d'extension, j'ai d\u00fb m'y reprendre de nombreuses fois pour avoir une extension op\u00e9rationnelle. Les nombreuses limitations sont souvent des facteurs de frustration.</p> <p>Cependant, les github action ne permettant pas aujourd'hui ce type de t\u00e2che, nous n'avons pas vraiment le choix avec les outils Microsoft... Il reste encore beaucoup de choses \u00e0 am\u00e9liorer de ce point de vue !</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Azure DevOps extensibility points</li> <li>Server Task Authoring</li> <li>Tfx cli</li> <li>Ajouter une extension de t\u00e2che de pipeline personnalis\u00e9e</li> <li>Task Json Schema</li> <li>R\u00e9f\u00e9rence du manifeste de l\u2019extension</li> <li>Sch\u00e9mas d\u2019authentification du point de terminaison de service</li> </ul>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/05.azuredevops.extension.agentless/#remerciements","title":"Remerciements","text":"<ul> <li>Oussama Mouchrit : pour la relecture</li> <li>Laurent Mondeil : pour la relecture</li> <li>Michael Maillot : pour la relecture</li> <li>Fabrice Weinling : pour la relecture</li> </ul> <p>R\u00e9dig\u00e9 par Philippe MORISSEAU, Publi\u00e9 le 14 D\u00e9cembre 2021</p>","tags":["DevOps","Azure DevOps","CI/CD","d\u00e9veloppement"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/","title":"Azure DevOps: Your own on-demand agents in your corporate network","text":"<p>An end-to-end solution to run containerized Azure DevOps agents in your corporate network, anyone? You will be able to use Azure DevOps Services to manage the deployment of your applications and services even in secure areas of your corporate network.</p> <p>In my previous articles, i had touched on the subject (Azure DevOps: Creating your own agentless task and Azure Batch, the unloved). In this article i propose to detail how to put all this in place.</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#why-do-it","title":"Why do it?","text":"<ul> <li>If you want to use Azure DevOps Services to deploy your applications and services in your network-isolated corporate.</li> <li>If you want to use containers for your build and/or deployment operations to avoid side effects related to previous CI/CD pipeline executions.</li> <li>If you want to reduce the time of build and deployment of your pipelines by pre-installing your frameworks and legacy tools on your agents.</li> </ul>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#architecture","title":"Architecture","text":"<p>I suggest you orchestrate your Azure DevOps agents with Azure Batch. The entire architecture will therefore be on Azure. Of course, this is a proposal, it is certain that you can achieve an equivalent architecture on another cloud host or on your private cloud.</p> <p></p> <p>Concretely, here is the sequencing that will occur for the provision of an ephemeral agent:</p> <ol> <li>An agentless invoke Azure Function task from the build/deployment Azure DevOps pipeline calls the ProvideAzDOAgent function to request an ephemeral agent,</li> <li>For each call, the Azure Function creates a task in Azure Batch Account,</li> <li>The Azure Batch Account processes the tasks and assigns the task to the correct pool of nodes,</li> <li>The pool of nodes instantiates a container from the image present in the Azure Container Registry,</li> <li>Once the container is instantiated and started, it registers with Azure DevOps to let it know that it is available. Azure DevOps then assigns him a pending job.</li> <li>The Azure DevOps job runs in the Virtual Network A and can communicate with the On Premise network.</li> </ol> <p>We can see that the Azure Batch service (and its pools) as well as Azure Container Registry are completely isolated from a network point of view. Only the Azure Function is publicly accessible. However, the latter has a firewall rule limiting calls to public IP ranges of Azure DevOps Services.</p> <p>Note</p> <p>Microsoft provides the IP ranges of the Azure DevOps service for each of the regions: here</p> <p>Update of 05/02/2022</p> <p>When posting this article, i forgot an important part of securing this solution. Indeed, in the first version the nodes of the Azure Batch pools had a public IP address which allowed access through the RDP protocols for Windows and SSH for Linux. My colleague, Etienne Louise, pointed it out to me and pre-cheated me by giving me the solution directly. For it :</p> <ul> <li>When creating the pool, you must indicate that you do not want to create a public IP cf. Microsoft documentation,</li> <li>You must add the Azure NAT Gateway service connected to the pools subnet. This will allow our nodes to be able to access the internet to register with Azure DevOps.</li> </ul> <p>All that remains is to deploy our infrastructure on Azure.</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#infrastructure","title":"Infrastructure","text":"<p>You will find below the ARM template allowing to quickly deploy the infrastructure.</p> <p> </p> <p>This ARM template provides 2 pools of nodes: One for Azure DevOps agents on Windows and another for Linux agents.</p> <p>Note</p> <p>Since Windows containers can only run on Windows OS, we have no choice but to provision pools with separate OS.</p> <p>Update of 05/02/2022</p> <p>The infrastructure available above takes into account the remarks of Etienne Louise.</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#auto-scale","title":"Auto-scale","text":"<p>Azure Batch offers an auto-scaling system for nodes in a pool. In our case, we are going to use it to avoid running VMs on Azure for several hours without build or deployment operations. For each of these pools, I added the auto-scaling script below:</p> <pre><code>$nbTaskPerNodes = $TaskSlotsPerNode;\n$currentNodes = $TargetLowPriorityNodes;\n$nbPending5min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 5) &lt; 70 ? max($PendingTasks.GetSample(1)) : max($PendingTasks.GetSample(TimeInterval_Minute * 5));\n$nbPending60min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 60) &lt; 70 ? 1000 : max($PendingTasks.GetSample(TimeInterval_Minute * 60));\n$totalLowPriorityNodes = $nbPending5min &gt; max(0, $TaskSlotsPerNode * $currentNodes) ? $currentNodes + 1 : $currentNodes;\n$totalLowPriorityNodes = $nbPending60min &lt;= $TaskSlotsPerNode * max(0, $currentNodes - 1) \u00a0? $currentNodes - 1 : $totalLowPriorityNodes;\n$totalLowPriorityNodes = min(4, max($totalLowPriorityNodes, 0));\n$TargetLowPriorityNodes = $totalLowPriorityNodes;\n$NodeDeallocationOption = taskcompletion;\n</code></pre> <p>This script will evaluate the number of tasks in progress or pending:</p> <ul> <li>If this is greater than the number of nodes multiplied by the number of parallel tasks, a new node will be added.</li> <li>If this is less than the number of nodes - 1 multiplied by the number of parallel tasks, a node will be freed.</li> </ul> <p>The Scale-Out (addition of a node) is evaluated over the last 5 minutes in order to be as responsive as possible in the event of an increase in the number of tasks. The Scale-In (deletion of a node) is evaluated over the last hour in order to be able to manage occasional drops in tasks.</p> <p>Here is an example of what the activity could give on a day:</p> <p></p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#limitations","title":"Limitations","text":"<p>However, you should know that there are some small limitations:</p> <ol> <li>Although you can deploy your Azure Batch pools with ARM, it is not possible to increment the pool infrastructure. In other words, you cannot modify an existing pool. And, it's even worse since you'll get an error if your pool already exists when your ARM template runs. To compensate for this limitation, I added 2 parameters \"create_WindowsBatchPool\" and \"create_UbuntuBatchPool\".</li> <li>When creating your container registry, it does not contain any images. It will therefore be necessary to provide for the import of the images of your Azure DevOps agents.</li> </ol> <p>For this second limitation, I suggest you study the containerization of our Azure DevOps agent.</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#containerize-your-azure-devops-agent","title":"Containerize your Azure DevOps agent","text":"<p>Browsing through dockerhub looking for a docker image of my Azure DevOps agent, I found Czon. His project consists of automating the construction of docker images in order to systematically embed the latest version of the Azure DevOps agent. Thus on its repository dockerhub, Czon shares ubuntu images with the latest version of the Azure DevOps agent. That's class!</p> <p>So I took the liberty of forking his Github repository to make some small changes to the already excellent work of Czon and add the following features:</p> <ul> <li>Creation of containers on the bases <code>Windows ltsc2019</code>, <code>Ubuntu 18.04</code> and <code>Ubuntu 20.04</code>,</li> <li>And for each of these OS, addition of <code>dotnet core 3.1</code> and <code>dotnet 6.0</code> frameworks</li> </ul> <p>You can find my modifications on my repository Github, and the generated images on dockerhub.</p> <p>All that remains is to import the images from dockerhub to your Azure Container Registry with the following Azure CLI commands:</p> <pre><code>az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/azdo-agent:ubuntu-20.04-azdo -t azdo-agent:ubuntu-20.04-azdo\naz acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/azdo-agent:ubuntu-20.04-azdo -t azdo-agent:ubuntu-18.04-azdo\naz acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/azdo-agent:windows-core-ltsc2019-azdo -t azdo-agent:windows-core-ltsc2019-azdo\n</code></pre> <p>Now let's go to programming the function that will generate the tasks in Azure Batch.</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#an-azure-function-to-drive-azure-batch","title":"An Azure function to drive Azure Batch","text":"<p>Our goal is to allow the creation of a task running our containerized image in Azure Batch via the HTTP request of an Azure function.</p> <p>As a reminder, a task must be executed in a job. So if the job does not exist, it will have to be created. Our job will also allow us to define the environment variables of our containerized agent. In our case, we need to set as environment variables:</p> <ul> <li>The url of our organization Azure DevOps,</li> <li>The personal access token to allow our agent to authenticate on the organization,</li> <li>The name of the pool in which our agent will be added,</li> <li>The top indicating if the agent should run only one Azure DevOps job.</li> </ul> <p>We will use .net 6.0 to program our Azure Function. You will find here the source code created for the occasion.</p> <p>Today, only personal token authentication to add a Self-Hosted agent in a pool on Azure DevOps is possible. It's not ideal. In effect :</p> <ul> <li>This one having a validity period limited in time, this implies that you will have to intervene regularly to be able to renew it.</li> <li>This one being linked to an Azure DevOps user, if he leaves then his PAT will be revoked. A new token will then have to be generated.</li> </ul> <p>Note</p> <p>Microsoft provides the procedure for creating a PAT for your Azure DevOps agent: here</p> <p>Here is the necessary configuration for our Azure Function:</p> Name Description BatchAccountUrl Url of Azure Batch service BatchAccountName Name of Azure Batch service BatchAccountKey Access key of Azure Batch service ContainerRegistryServer full name of Azure Container Registry service AzDOUrl Url of our Azure DevOps organization AzDOToken Personal access token allowing our agent to authenticate on the organization AzDOUbuntuPool Pool name containing agents running on Ubuntu AzDOWindowsPool Pool name containing agents running on Windows","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#integration-with-azure-devops","title":"Integration with Azure DevOps","text":"<p>Now that we have our solution operational on Azure, we need to allow our Azure DevOps pipelines to request an agent and use it when available.</p> <p>First of all, you need to create the pools of agents on Azure DevOps. This document from Microsoft explains the procedure.</p> <p>Next, we will add in our pipeline an Agentless or Server-side job with an invoke Azure Function task. This task must perform an HTTP POST request.</p> <p>Below is an example yaml pipeline using this task.</p> <pre><code>  jobs:\n  - job: RequestAzDOAgent\n    pool: server\n    steps:\n    - task: AzureFunction@1\n      displayName: 'Request new ephemeral agent'\n      inputs:\n        function: 'https://[YOUR_FUNCTION_NAME].azurewebsites.net/api/ProvideAzDOAgent'\n        key: '[YOUR_FUNCTION_KEY]'\n        body: |\n        {\n            \"AgentOSType\":\"ubuntu-latest\"\n        }\n  - job: RunWithEphemeralAgent\n    dependsOn: RequestAzDOAgent\n    pool:\n      name: '[AzDOUbuntuPool]'\n    steps:\n    - bash: \n      displayName: 'Bash Script'\n</code></pre> <p>Note</p> <p>The <code>YOUR_FUNCTION_NAME</code> and <code>YOUR_FUNCTION_KEY</code> attributes will have been previously retrieved from your Azure Function. The <code>AzDOUbuntuPool</code> attribute corresponds to the name of the pool defined in Azure DevOps</p> <p>And There you go !!!</p> <p>Well no, almost...</p> <p>Indeed, when you launch your pipeline, it will result in a systematic failure indicating that there is no agent in your pool. Indeed, between the moment when you are going to make your agent request and the moment when it will be available, a few seconds or a few minutes may pass (if it is the first execution of the day for example). Either way, Azure DevOps will automatically launch the next job that is supposed to run on your ephemeral agent. Finding no agents, the Azure DevOps pipeline incorrectly assumes that there will never be any agents in this pool and fails.</p> <p>But then how do we tell our pipeline instance to wait?</p> <p>My solution is to register a \"dummy\" agent in the pool. To do this, nothing could be simpler, just follow the procedure for installing a Self-Hosted agent, then uninstall it without unregistering it. Thus, you keep an Offline agent in your pool. This will be enough to make Azure DevOps wait until your ephemeral agent is available.</p> <p> </p> <p>It's ugly, but it works!</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#conclusion","title":"Conclusion","text":"<p>Through this article I have tried to show you several points:</p> <ul> <li>That you can use managed services as an enabler of your software production platform,</li> <li>That you can secure your software deployments even with cloud solutions,</li> <li>That you can set up sober build and deployment solutions by containerizing the framework and tools you need,</li> <li>That you can easily integrate it with Azure DevOps.</li> </ul> <p>Not everything is perfect, and I would have preferred:</p> <ul> <li>That the pools of Azure Batch are better managed by Azure Resource Manager,</li> <li>That we can register Azure DevOps agents without using a Personal access token or,</li> <li>That we don't have to create a \"fictitious\" agent in Azure DevOps.</li> </ul> <p>But, I hope I have convinced you of my approach. And if you are interested, I invite you to appropriate what I have produced in the context of this article:</p> <ul> <li>The Czon Github fork allowing to build images with the AzDO agent</li> <li>My repository dockerhub containing the images with the latest version of the AzDO agent</li> <li>My repository Github containing the whole solution (Infra + Code + AzDO Pipeline)</li> </ul> <p>And what about Github runners? We will see that in a future article...</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#references","title":"References","text":"<ul> <li>Azure DevOps Services : Inbound connections</li> <li>Github Czon : Azure Pipelines Agent Docker Container</li> <li>Docker hub Czon : AzDO agent</li> <li>Azure DevOps : Authenticate with a personal access token (PAT)</li> <li>Azure DevOps : Create and manage agent pools</li> </ul>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/06.azuredevops.ephemeralagents/#thanks","title":"Thanks","text":"<ul> <li>David Dubourg : for proofreading</li> <li>Quentin Joseph : for proofreading</li> <li>Fabrice Weinling : for proofreading</li> <li>Etienne Louise : for the remark and the solution with the NAT Gateway</li> </ul> <p>Written by Philippe MORISSEAU, Published on January 25, 2022. Updated on February 5, 2022</p>","tags":["DevOps","Azure DevOps","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/","title":"GitHub : Your own on-demand runner in your corporate network","text":"<p>An end-to-end solution to run containerized GitHub Actions Runner in your corporate network, anyone? You will be able to use GitHub to manage the deployment of your applications and services even in the secure areas of your corporate network.</p> <p>In a previous article, I suggested that you set up a solution allowing you to provision your Azure DevOps agents on demand (see Azure DevOps: Your own on-demand agents in your corporate network). I suggest you do the same thing but with GitHub.</p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#why-do-it","title":"Why do it?","text":"<p>For the same reasons as with Azure DevOps Services, namely:</p> <ul> <li>If you want to use GitHub Actions to deploy your applications and services in your network-isolated corporate.</li> <li>If you want to use containers for your build and/or deploy operations to avoid side effects related to previous CI/CD pipeline executions.</li> <li>If you want to reduce the time of build and deployment of your pipelines by pre-installing your frameworks and legacy tools on your agents.</li> </ul>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#architecture","title":"Architecture","text":"<p>I suggest you orchestrate your GitHub Actions Runner with Azure Batch. The entire architecture will therefore be on Azure. Of course, this is a proposal, it is certain that you can achieve an equivalent architecture on another cloud host or on your private cloud.</p> <p></p> <p>Concretely, here is the sequencing that will occur for the provision of an ephemeral agent:</p> <ol> <li>GitHub calls the ProvideActionsRunner function to request an ephemeral runner,</li> <li>For each call, the Azure Function creates a task in Azure Batch Account,</li> <li>The Azure Batch Account processes the tasks and assigns the task to the correct pool of nodes,</li> <li>The pool of nodes instantiates a container from the image present in the Azure Container Registry,</li> <li>Once the container is instantiated and started, it registers with GitHub to let it know that it is available. GitHub then assigns it a pending job.</li> <li>The GitHub job runs in the Virtual Network A and can communicate with the On Premise network.</li> </ol> <p>We can see that the Azure Batch service (and its pools) as well as Azure Container Registry are completely isolated from a network point of view. Only the Azure Function is publicly accessible. However, the latter has a firewall rule limiting calls to GitHub public IP ranges.</p> <p>Note</p> <p>GitHub provides the IP ranges of its services from this api</p> <p>All that remains is to deploy our infrastructure on Azure.</p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#infrastructure","title":"Infrastructure","text":"<p>I updated the infrastructure previously set up for Azure DevOps Service with the few specificities of GitHub. Below is the ARM template to quickly deploy the infrastructure for GitHub (and for Azure DevOps).</p> <p> </p> <p>This ARM template provides 2 pools of nodes : one pool for Actions Runner on Windows and another for Actions Runner on Linux.</p> <p>Note</p> <p>Since Windows containers can only run on Windows OS, we have no choice but to provision pools with separate OS.</p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#auto-scale","title":"Auto-scale","text":"<p>Azure Batch offers an auto scaling system for nodes in a pool. In our case, we are going to use it to avoid running VMs on Azure for several hours without a build or deployment operation. For each of these pools, I added the auto scaling script below:</p> <pre><code>$nbTaskPerNodes = $TaskSlotsPerNode;\n$currentNodes = $TargetLowPriorityNodes;\n$nbPending5min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 5) &lt; 70 ? max($PendingTasks.GetSample(1)) : max($PendingTasks.GetSample(TimeInterval_Minute * 5));\n$nbPending60min = $PendingTasks.GetSamplePercent(TimeInterval_Minute * 60) &lt; 70 ? 1000 : max($PendingTasks.GetSample(TimeInterval_Minute * 60));\n$totalLowPriorityNodes = $nbPending5min &gt; max(0, $TaskSlotsPerNode * $currentNodes) ? $currentNodes + 1 : $currentNodes;\n$totalLowPriorityNodes = $nbPending60min &lt;= $TaskSlotsPerNode * max(0, $currentNodes - 1) \u00a0? $currentNodes - 1 : $totalLowPriorityNodes;\n$totalLowPriorityNodes = min(4, max($totalLowPriorityNodes, 0));\n$TargetLowPriorityNodes = $totalLowPriorityNodes;\n$NodeDeallocationOption = taskcompletion;\n</code></pre> <p>This script will evaluate the number of tasks in progress or pending:</p> <ul> <li>If this is greater than the number of nodes multiplied by the number of parallel tasks, a new node will be added.</li> <li>If this is less than the number of nodes - 1 multiplied by the number of parallel tasks, a node will be released.</li> </ul> <p>The Scale-Out (addition of a node) is evaluated over the last 5 minutes in order to be as responsive as possible in the event of an increase in the number of tasks. The Scale-In (deletion of a node) is evaluated over the last hour in order to be able to manage occasional drops in tasks.</p> <p>Here is an example of what the activity could give on a day:</p> <p></p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#limitations","title":"Limitations","text":"<p>However, you should know that there are some small limitations:</p> <ol> <li>Although you can deploy your Azure Batch pools with ARM template, it is not possible to increment the pool infrastructure. In other words, you cannot modify an existing pool. And, it's even worse since you'll get an error if your pool already exists when your ARM template runs. To compensate for this limitation, I added 2 parameters \"create_WindowsBatchPool\" and \"create_UbuntuBatchPool\".</li> <li>When creating your container registry, it does not contain any images. It will therefore be necessary to provide for the import of the images of your Runner Actions.</li> </ol> <p>For this second limitation, I suggest you study the containerization of our Actions Runner. </p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#containerize-your-actions-runner","title":"Containerize your actions runner","text":"<p>I went back from my work for containerizing Azure DevOps agents to apply it to Runner Actions.</p> <p>You can find my adaptations on my repository GitHub, and the generated images on dockerhub.</p> <p>All that remains is to import the images from dockerhub to your Azure Container Registry with the following Azure CLI commands:</p> <pre><code>az acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner -t githubactions-runner:ubuntu-20.04-actionsrunner\naz acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner -t githubactions-runner:ubuntu-18.04-actionsrunner\naz acr import -n [YOUR_ACR_NAME] --source docker.io/pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner -t githubactions-runner:windows-core-ltsc2019-actionsrunner\n</code></pre> <p>Now let's go to programming the function that will generate the tasks in Azure Batch.</p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#an-azure-function-to-drive-azure-batch","title":"An Azure function to drive Azure Batch","text":"<p>Our goal is to allow the creation of a task running our containerized image in Azure Batch via the HTTPS call of an Azure function.</p> <p>As a reminder, a task must be executed in a job. So if the job does not exist, it will have to be created. Our job will also allow us to define the environment variables of our containerized agent. In our case, we need to set as environment variables:</p> <ul> <li>The url of the GitHub organization or the url of the personal repo,</li> <li>The token to allow our agent to register,</li> <li>The tags that will allow you to assign the correct runner to the correct GitHub job,</li> <li>The top indicating if the agent should run only one GitHub Actions job.</li> </ul> <p>We will use .NET 6.0 to program our Azure Function. You can find here the improved source code to handle both Azure Devops and GitHub.</p> <p>On GitHub the token used to register our runner is valid for one hour. It is therefore necessary to plan to systematically request a new token for each job. To do this, you must call the GitHub API.</p> <p>Note</p> <p>GitHub provides full api documentation to retrieve this token for:</p> <ul> <li>GitHub enterprise</li> <li>GitHub organization</li> <li>GitHub repository</li> </ul> <p>But to be able to call the API, you have to be authenticated! There are 3 methods:</p> <ul> <li>GitHub App: Allows you to create an application allowing your users to access through it the services of GitHub.</li> <li>OAuth App: Allows you to create an application allowing access on behalf of the user to GitHub services.</li> <li>Personal Access Token: Allows you to access GitHub services by pretending to be you.</li> </ul> <p>In my case, I opted for the simplest solution to implement: the Personal Access Token. But I strongly recommend you to opt for the OAuth App.</p> <p>To create your Personal Access Token:</p> <ol> <li>Click on <code>Settings</code> in your account tab,</li> <li>Click on <code>Developer settings</code> and then <code>Personal access tokens</code>,</li> <li>Then <code>Generate new token</code></li> <li>Enter a label and a validity period.</li> <li>Select scopes. In our case, if you want to create runners at the level of your organization, you will have to check <code>admin:org</code>. And if you want to create runners at the level of your repos, you will have to check <code>repo</code>.     </li> <li>Finally click on <code>Generate token</code>. Your token is displayed. Save it since it will no longer be visible!</li> </ol> <p>Here is the necessary configuration for the Azure Function:</p> Name Description BatchAccountUrl Url of Azure Batch service BatchAccountName Name of Azure Batch service BatchAccountKey Access key of Azure Batch service ContainerRegistryServer full name of Azure Container Registry service UbuntuPool Pool name containing agents running on Ubuntu WindowsPool Pool name containing agents running on Windows GithubToken Personal access token allowing to request a token for the registration of the runner","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#integration-with-github","title":"Integration with GitHub","text":"<p>Now that we have our solution running on Azure, we need to allow our GitHub workflows to request a runner and use it when available.</p> <p>What's great about GitHub unlike Azure DevOps Services is the multitude of webhooks. GitHub notably offers a webhook for jobs.</p> <p>Note</p> <p>GitHub provides full webhook and payload documentation here</p> <p>In our case, we will subscribe our Azure function to webhooks from GitHub.</p> <p>For it :</p> <ol> <li>in the <code>Settings</code> of your repository or your organization click on <code>Webhooks</code>,</li> <li>click on <code>Add Webhooks</code>,</li> <li>in <code>Payload URL</code> enter the full url of your function: https://<code>[YourAzureFunction]</code>.azurewebsites.net/api/ProvideActionsRunner?code=<code>[YourSecret]</code></li> <li>in <code>Content Type</code> select <code>application/json</code></li> <li>check <code>Let me select individual events.</code></li> <li>uncheck <code>Pushes</code></li> <li>check <code>Workflow jobs</code></li> <li>Finally click on <code>Add webhooks</code></li> </ol> <p>Now whenever you have a new GitHub job, your Azure function will receive a notification to create a runner.</p> <p>All that remains is to create the GitHub workflow!</p> <p>To indicate that you want a self-hosted agent you must specify for your jobs: <code>runs-on: [self-hosted]</code>. And to indicate the type of OS you want to use, you will need to add another label: <code>ubuntu-18.04</code>, <code>ubuntu-latest</code> or <code>windows-latest</code>.</p> <p>For example :</p> <pre><code>name: Test Agent\non:\n  push:\n    branches: \n      - master\n      - main\n\njobs:\n  use-selfhosted-ubuntu1804:\n    runs-on: [self-hosted, ubuntu-18.04]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Fetch release version\n        run: |\n          echo \"Hello world !\"\n\n  use-selfhosted-ubuntu2004:\n    runs-on: [self-hosted, ubuntu-latest]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Fetch release version\n        run: |\n          echo \"Hello world !\"\n\n  use-selfhosted-windows:\n    runs-on: [self-hosted, windows-latest]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Fetch release version\n        run: |\n          echo \"Hello world !\"\n</code></pre>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#conclusion","title":"Conclusion","text":"<p>After showing you that it was possible to provision your own Azure DevOps Services agents in your corporate network, I repeat my demonstration on GitHub. The software factory changes but the concept still works.</p> <p>It is also an opportunity to compare the strengths and weaknesses of each.</p> <p>GitHub is unquestionably the big winner with:</p> <ul> <li>the multitude of webhooks available to implement interactive scenarios affecting the surrounding ecosystem.</li> <li>registration of runners with a temporary token which is much more secure than the Personal Access Token of Azure DevOps.</li> </ul> <p>But Azure DevOps has not said its last word!</p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#references","title":"References","text":"<ul> <li>GitHub : Api Meta</li> <li>GitHub : Api Actions</li> <li>GitHub : Basic Authentication</li> <li>GitHub : Webhook events and payloads</li> <li>Terraform module for scalable self hosted GitHub action runners</li> </ul>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/07.github.ephemeralactionsrunner/#thanks","title":"Thanks","text":"<ul> <li>Michael Maillot : for proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on February 21, 2022.</p>","tags":["DevOps","GitHub","CI/CD","development","Azure","Infra as Code","PaaS"]},{"location":"en/articles/tips/08.dockerhub.windowsServerCore2022/","title":"Dockerhub: Your Actions Runner and Azure DevOps Agent on Windows Server Core 2022","text":"<p>In recent weeks I have proposed solutions to host your Azure DevOps agents and your GitHub runners on your environments through docker containers. This weekend, I made a small change to additionally offer these same agents/runners on Windows Server Core 2022 (aka ltsc2022).</p> <p>Here is a summary of the different images available on my dockerhub repository:</p> Operating system Version Agent Installed framework installed docker image Ubuntu 18.04 GitHub Actions Runner None pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner Ubuntu 18.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-core-3.1 Ubuntu 18.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-6.0 Ubuntu 20.04 GitHub Actions Runner None pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner Ubuntu 20.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-core-3.1 Ubuntu 20.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-6.0 Ubuntu 18.04 Azure DevOps Agent None pmorisseau/azdo-agent:ubuntu-18.04-azdo Ubuntu 18.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-core-3.1 Ubuntu 18.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-6.0 Ubuntu 20.04 Azure DevOps Agent None pmorisseau/azdo-agent:ubuntu-20.04-azdo Ubuntu 20.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-core-3.1 Ubuntu 20.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-6.0 Windows Server 2019 GitHub Actions Runner None pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner Windows Server 2019 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-core-3.1 Windows Server 2019 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-6.0 Windows Server 2022 GitHub Actions Runner None pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner Windows Server 2022 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-core-3.1 Windows Server 2022 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-6.0 Windows Server 2019 Azure DevOps Agent None pmorisseau/azdo-agent:windows-core-ltsc2019-azdo Windows Server 2019 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-core-3.1 Windows Server 2019 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-6.0 Windows Server 2022 Azure DevOps Agent None pmorisseau/azdo-agent:windows-core-ltsc2022-azdo Windows Server 2022 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-core-3.1 Windows Server 2022 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-6.0 <p>Note</p> <p>Daily processing checks the version of Azure DevOps agents and Github Actions runners so that the docker images always include the latest version. The docker images are therefore regularly and automatically updated.</p> <p>Note</p> <p>If you want to use these images, I invite you to read my previous articles:</p> <ul> <li>Azure DevOps: Your own on-demand agents in your corporate network</li> <li>GitHub : Your own on-demand runner in your corporate network</li> </ul> <p>Written by Philippe MORISSEAU, Published on February 28, 2022.</p>","tags":["DevOps","GitHub","Azure DevOps","docker","Windows"]},{"location":"en/articles/tips/09.azurefunction.limitlogs/","title":"The FinOps tip: Limit the verbosity of your Azure Functions","text":"<p>Setting up the monitoring of your Azure Function is essential (especially for your applications in production). But it happens that these produce many more logs than necessary. In this case, you can have a significant financial impact on Application Insights/Log Analytics. Here are some tips to limit this.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"en/articles/tips/09.azurefunction.limitlogs/#monitor-log-volumes","title":"Monitor log volumes","text":"<p>In order to understand why your log ingestion costs are exploding on Application Insights/Log Analytics, you need to identify the most common types of logs. From Log Analytics run the following Kusto query:</p> <pre><code>union *\n| where timestamp &gt; ago(7d)\n| summarize sum(_BilledSize) by itemType\n| render piechart \n</code></pre> <p>This query generates a pie chart with the distribution of the volume of billable logs by type of logs.</p> <p></p> <p>In this example, we can see that <code>trace</code> type logs represent more than 74% of the volume of billable logs.</p> <p>Let's focus on these <code>trace</code> logs to now identify which sources are producing the most volume. Maybe a particular application generates too many logs. From Log Analytics now run the following Kusto query:</p> <pre><code>traces\n| where timestamp &gt; ago(7d)\n| summarize sum(_BilledSize) by cloud_RoleName\n| render piechart\n</code></pre> <p></p> <p>In the example above, we see that the sources of our logs are varied and rather distributed. This is not always the right track!</p> <p>If this is not one of the sources at the origin of our volume of logs, perhaps it is a library, an SDK used by our Azure Function which is the source of our misfortunes.</p> <p>Note</p> <p>The Azure Function runtime classifies logs by <code>category</code>. These <code>category</code> are accessible in the <code>customDimensions</code> of the <code>trace</code> logs.</p> <p>To do this, we will execute the following Kusto query:</p> <pre><code>traces\n| where timestamp &gt; ago(7d)\n| summarize sum(_BilledSize) by tostring(customDimensions.Category)\n| render piechart \n</code></pre> <p></p> <p>In the example above it appears that the category <code>Azure.Messaging.ServiceBus</code> represents 62% of the volume of <code>trace</code> logs. Reduced to the total volume of logs, this represents: 46.5%.</p> <p>Now that we have identified our origin. It is necessary to ensure the relevance of the logs. Maybe these logs are needed? A simple exploration of the logs over the last 30 minutes (or more depending on your context) allows you to quickly analyze the logs:</p> <pre><code>traces\n| where timestamp &gt; ago(30m) and customDimensions.Category == \"Azure.Messaging.ServiceBus\"\n</code></pre> <p></p> <p>In our case, we see that these are logs allowing us to trace the sending and reception of messages to and from Azure ServiceBus.</p> <p>We consider that these logs are not relevant (simple assumption, it is not a generality). These logs can be removed from Azure Application Insights/Log Analytics ingestion. But before intervening it is necessary to check the distribution of these logs by severity level.</p> <p>For this, the following Kusto query will help us:</p> <pre><code>traces\n| where timestamp &gt; ago(30m) and customDimensions.Category == \"Azure.Messaging.ServiceBus\"\n| summarize count() by tostring(customDimensions.LogLevel)\n| render piechart \n</code></pre> <p></p> <p>It can be seen that 99% of the logs are of the <code>Information</code> severity level.</p> <p>This analysis process shows that a simple remediation at the Azure Function configuration level will reduce the volume of logs by 46%. This remediation consists of raising the verbosity level to <code>Warning</code> for the logs of the <code>Azure.Messaging.ServiceBus</code> category.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"en/articles/tips/09.azurefunction.limitlogs/#remediation-at-the-azure-function-level","title":"Remediation at the Azure Function level","text":"<p>I won't explain how to configure your Azure function so that it can send its logs to Application Insights. This Microsoft article explains it very well.</p> <p>However, what this documentation does not explain well is that the list of categories described here is not exhaustive.</p> <p>Indeed, all the categories previously identified during the analysis can be configured.</p> <p>To raise the verbosity level to <code>Warning</code> for logs in the <code>Azure.Messaging.ServiceBus</code> category, simply modify the <code>host.json</code> file by adding <code>\"Azure.Messaging.ServiceBus\": \"Warning\"</code> .</p> <p>We will have a file that will look like this:</p> <pre><code>{\n  \"logging\": {\n    \"logLevel\": {\n      \"default\": \"Information\",\n      \"Azure.Messaging.ServiceBus\": \"Warning\"\n    }\n  }\n}\n</code></pre> <p>And that's all !</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"en/articles/tips/09.azurefunction.limitlogs/#conclusion","title":"Conclusion","text":"<p>It is important to take the time to analyze the nature of the logs. The Application Insights and Log Analytics services offer excellent means of analysis and research. In a FinOps approach, they can prove to be very practical tools. Indeed, through this example I managed to reduce by 46% the volume of logs ingested by Application Insights/Log Analytics. Assuming that we had 10 GB of logs ingested per day (in the France Central region), this would amount to a saving of \u20ac350 per month.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"en/articles/tips/09.azurefunction.limitlogs/#references","title":"References","text":"<ul> <li>Microsoft : How to configure monitoring for Azure Functions</li> <li>azure-sdk-for-net - issue : [QUERY] Service bus telemetry seems excessive</li> </ul>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"en/articles/tips/09.azurefunction.limitlogs/#thanks","title":"Thanks","text":"<ul> <li>Nicolas Bregent : for proofreading</li> <li>Fabrice Weinling : for proofreading</li> <li>Etienne Louise : for proofreading </li> <li>Samy Mameri : for proofreading</li> </ul> <p>Written by Philippe MORISSEAU, Published on June 27, 2022.</p>","tags":["Azure Function","Monitoring","Application Insights","Log Analytics","FinOps"]},{"location":"en/articles/tips/10.dockerhub.ubuntu22.04/","title":"Your Azure DevOps Agent and Github Runner with Jammy Jellyfish.","text":"<p>After several weeks of holidays, I decided to make a new small contribution by publishing the images of the Azure DevOps agents and the GitHub runners on the latest LTS distribution of the Ubuntu OS: Ubuntu 22.04 (Jammy Jellyfish).</p> <p>However, Microsoft does not propose the .net core 3.1 SDK on Ubuntu 22.04. So I only created the images with the .net 6.0 SDK. Also, I took the opportunity to upgrade the 2 SDK (.net core 3.1 and .net 6.0) in order to embed the latest patches. To know :</p> <ul> <li>For .NET 6 version 6.0.8</li> <li>For .NET core 3.1 version 3.1.28</li> </ul> <p></p> <p>Here is a summary of the different images available on my dockerhub repository :</p> Syst\u00e8me d'exploitation Version Agent install\u00e9 framework install\u00e9 image docker Ubuntu 18.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner Ubuntu 18.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-core-3.1 Ubuntu 18.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-18.04-actionsrunner-dotnet-6.0 Ubuntu 20.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner Ubuntu 20.04 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-core-3.1 Ubuntu 20.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-20.04-actionsrunner-dotnet-6.0 Ubuntu 18.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-18.04-azdo Ubuntu 18.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-core-3.1 Ubuntu 18.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-18.04-azdo-dotnet-6.0 Ubuntu 20.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-20.04-azdo Ubuntu 20.04 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-core-3.1 Ubuntu 20.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-20.04-azdo-dotnet-6.0 Windows Server 2019 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner Windows Server 2019 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-core-3.1 Windows Server 2019 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2019-actionsrunner-dotnet-6.0 Windows Server 2022 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner Windows Server 2022 GitHub Actions Runner .net core 3.1 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-core-3.1 Windows Server 2022 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:windows-core-ltsc2022-actionsrunner-dotnet-6.0 Windows Server 2019 Azure DevOps Agent Aucun pmorisseau/azdo-agent:windows-core-ltsc2019-azdo Windows Server 2019 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-core-3.1 Windows Server 2019 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2019-azdo-dotnet-6.0 Windows Server 2022 Azure DevOps Agent Aucun pmorisseau/azdo-agent:windows-core-ltsc2022-azdo Windows Server 2022 Azure DevOps Agent .net core 3.1 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-core-3.1 Windows Server 2022 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:windows-core-ltsc2022-azdo-dotnet-6.0 Ubuntu 22.04 GitHub Actions Runner Aucun pmorisseau/githubactions-runner:ubuntu-22.04-actionsrunner Ubuntu 22.04 GitHub Actions Runner .net 6.0 pmorisseau/githubactions-runner:ubuntu-22.04-actionsrunner-dotnet-6.0 Ubuntu 22.04 Azure DevOps Agent Aucun pmorisseau/azdo-agent:ubuntu-22.04-azdo Ubuntu 22.04 Azure DevOps Agent .net 6.0 pmorisseau/azdo-agent:ubuntu-22.04-azdo-dotnet-6.0 <p>In the case of Azure DevOps agents, I had to \"tinker\". Indeed, with version 22.04 (based on debian 11), the sources of the official packages only offer OpenSSL v3. However, Azure DevOps agents still need OpenSSL v1.1 to work. So I \"manually\" installed OpenSSL v1.1 when creating the image. If you want to know more, a ticket on Microsoft's Github is currently open.</p> <p>Note</p> <p>Daily processing checks the version of Azure DevOps agents and Github Actions runners so that the docker images always include the latest version. The docker images are therefore regularly and automatically updated.</p> <p>Note</p> <p>If you want to use these images, I invite you to read my previous articles:</p> <ul> <li>Azure DevOps: Your own on-demand agents in your corporate network</li> <li>GitHub : Your own on-demand runner in your corporate network</li> </ul>","tags":["DevOps","GitHub","Azure DevOps","docker","Linux"]},{"location":"en/articles/tips/10.dockerhub.ubuntu22.04/#references","title":"References","text":"<ul> <li>[VSTS Agent] Unable to install vsts agent on Ubuntu Server 22.04 LTS </li> <li>Fix installation on aarch64 / Ubuntu 22.04</li> <li>Supported distributions</li> <li>Download .NET Core 3.1</li> <li>Download .NET 6.0</li> </ul> <p>Written by Philippe MORISSEAU, Published on August 23, 2022.</p>","tags":["DevOps","GitHub","Azure DevOps","docker","Linux"]}]}